{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDl-jWkvFbbS",
        "outputId": "ed6f0116-0293-4920-8356-54278b7f99a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras.utils in /usr/local/lib/python3.7/dist-packages (1.0.13)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.7/dist-packages (from keras.utils) (2.7.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import glob\n",
        "import librosa\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "!pip install keras.utils\n",
        "import keras.utils\n",
        "!pip install tensorflow\n",
        "import tensorflow\n",
        "#from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aET96usNFlEJ",
        "outputId": "65f4c2d6-355a-451b-cf07-499f0596bf05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTFQ1lbXFnvQ"
      },
      "outputs": [],
      "source": [
        "#labels = [\"angry\", \"disgusted\", \"fearful\", \"happy\", \"neutral\", \"sad\"]\n",
        "emotions={\n",
        "  '01':'neutral',\n",
        "  '02':'calm',\n",
        "  '03':'happy',\n",
        "  '04':'sad',\n",
        "  '05':'angry',\n",
        "  '06':'fear',\n",
        "  '07':'disgust',\n",
        "  '08':'surprised'\n",
        "}\n",
        "\n",
        "\n",
        "observed_emotions = ['sad','angry','happy','disgust','neutral','fear']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL4A752NGB62"
      },
      "outputs": [],
      "source": [
        "#not used\n",
        "def extract_feature(file_name):\n",
        "    X, sample_rate = librosa.load(os.path.join(file_name), res_type='kaiser_fast')\n",
        "    mfccs = librosa.feature.melspectrogram(y=X, sr=sample_rate)\n",
        "    return mfccs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIq_hcwzIjwn"
      },
      "outputs": [],
      "source": [
        "#not used for training\n",
        "def load_data(test_size=0.2): \n",
        "    x,y=[],[]\n",
        "    \n",
        "    # feature to extract\n",
        "    mfcc = True\n",
        "\n",
        "    for file in os.listdir(\"/content/drive/MyDrive/ryerson\"):\n",
        "        path = \"/content/drive/MyDrive/ryerson/\"\n",
        "        file_name = path+file\n",
        "        for audio in os.listdir(file_name):\n",
        "            audio_file = file_name + \"/\" + audio\n",
        "            emotion=emotions[audio_file.split(\"-\")[2]] #to get emotion according to filename. dictionary emotions is defined above.\n",
        "            if emotion not in observed_emotions: #options observed_emotions - RAVDESS and TESS, ravdess_emotions for RAVDESS only\n",
        "                continue\n",
        "            feature=extract_feature(audio_file, mfcc)\n",
        "            x.append(feature)\n",
        "            y.append(emotion)\n",
        "        \n",
        "\n",
        "    for file in os.listdir(\"/content/drive/MyDrive/toronto/TESS Toronto emotional speech set data\"):\n",
        "        path = \"/content/drive/MyDrive/toronto/TESS Toronto emotional speech set data/\"\n",
        "        file_name = path+file\n",
        "        for audio in os.listdir(file_name):\n",
        "            audio_file = file_name + \"/\" + audio\n",
        "            emotion=audio.split(\"_\")[2][:-4] #split and remove .wav\n",
        "            if emotion not in observed_emotions: #options observed_emotions - RAVDESS and TESS, ravdess_emotions for RAVDESS only\n",
        "                continue\n",
        "            feature=extract_feature(audio_file, mfcc)\n",
        "            x.append(feature[0])\n",
        "            y.append(emotion)\n",
        "\n",
        "    return {\"X\":x,\"y\":y}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si3yT7tQIpAL"
      },
      "outputs": [],
      "source": [
        "#not used for training\n",
        "\n",
        "#Trial_dict = load_data(test_size = 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnF5nOKqJAO5"
      },
      "outputs": [],
      "source": [
        "#not used for training\n",
        "\n",
        "#X = pd.DataFrame(Trial_dict[\"X\"])\n",
        "#y = pd.DataFrame(Trial_dict[\"y\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaxge0ZiJFJT"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/CS464 Project/RAVTESS_MFCC_Observed.csv\")\n",
        "data = data.drop('Unnamed: 0',axis=1)\n",
        "X = data.drop('emotion', axis = 1).values\n",
        "y = data['emotion'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "pLFvtR0iJG8W",
        "outputId": "113e9a33-6812-43bf-9c7c-0a1e72f650f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-17e112f9-52cd-42f5-b0ae-e0ccd98a90d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-512.883911</td>\n",
              "      <td>57.364391</td>\n",
              "      <td>17.080887</td>\n",
              "      <td>22.461151</td>\n",
              "      <td>3.165413</td>\n",
              "      <td>17.127214</td>\n",
              "      <td>-19.047163</td>\n",
              "      <td>-8.554851</td>\n",
              "      <td>-18.021544</td>\n",
              "      <td>14.430445</td>\n",
              "      <td>-13.958061</td>\n",
              "      <td>11.447804</td>\n",
              "      <td>-6.984544</td>\n",
              "      <td>10.246264</td>\n",
              "      <td>-0.406156</td>\n",
              "      <td>-1.396502</td>\n",
              "      <td>1.733015</td>\n",
              "      <td>5.940756</td>\n",
              "      <td>5.089407</td>\n",
              "      <td>-3.323593</td>\n",
              "      <td>5.926631</td>\n",
              "      <td>1.124013</td>\n",
              "      <td>-4.221565</td>\n",
              "      <td>0.658900</td>\n",
              "      <td>-5.681535</td>\n",
              "      <td>0.940563</td>\n",
              "      <td>1.861816</td>\n",
              "      <td>4.236084</td>\n",
              "      <td>2.952379</td>\n",
              "      <td>5.638145</td>\n",
              "      <td>4.377983</td>\n",
              "      <td>5.327526</td>\n",
              "      <td>2.002077</td>\n",
              "      <td>4.345651</td>\n",
              "      <td>9.767968</td>\n",
              "      <td>10.746924</td>\n",
              "      <td>13.613222</td>\n",
              "      <td>14.245697</td>\n",
              "      <td>10.242604</td>\n",
              "      <td>8.848364</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-423.976929</td>\n",
              "      <td>72.107246</td>\n",
              "      <td>-8.895686</td>\n",
              "      <td>26.045773</td>\n",
              "      <td>-21.497879</td>\n",
              "      <td>7.961668</td>\n",
              "      <td>-8.941034</td>\n",
              "      <td>-2.356802</td>\n",
              "      <td>-12.499807</td>\n",
              "      <td>7.922379</td>\n",
              "      <td>-13.600839</td>\n",
              "      <td>8.333814</td>\n",
              "      <td>-10.043387</td>\n",
              "      <td>5.377828</td>\n",
              "      <td>-5.195395</td>\n",
              "      <td>-1.930755</td>\n",
              "      <td>-1.817102</td>\n",
              "      <td>-0.096166</td>\n",
              "      <td>-7.649230</td>\n",
              "      <td>0.021990</td>\n",
              "      <td>-6.319166</td>\n",
              "      <td>-1.288345</td>\n",
              "      <td>-3.448888</td>\n",
              "      <td>3.912460</td>\n",
              "      <td>-1.243477</td>\n",
              "      <td>0.390959</td>\n",
              "      <td>-0.573938</td>\n",
              "      <td>1.397245</td>\n",
              "      <td>1.396395</td>\n",
              "      <td>4.588929</td>\n",
              "      <td>-0.053272</td>\n",
              "      <td>2.795042</td>\n",
              "      <td>2.061146</td>\n",
              "      <td>1.395552</td>\n",
              "      <td>5.306121</td>\n",
              "      <td>2.917225</td>\n",
              "      <td>6.070544</td>\n",
              "      <td>3.351685</td>\n",
              "      <td>3.721366</td>\n",
              "      <td>2.546432</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-479.606476</td>\n",
              "      <td>60.020325</td>\n",
              "      <td>-22.544024</td>\n",
              "      <td>21.445721</td>\n",
              "      <td>0.215445</td>\n",
              "      <td>-4.377944</td>\n",
              "      <td>-6.196318</td>\n",
              "      <td>0.808999</td>\n",
              "      <td>-16.222569</td>\n",
              "      <td>5.685111</td>\n",
              "      <td>-5.890694</td>\n",
              "      <td>1.174196</td>\n",
              "      <td>-1.360554</td>\n",
              "      <td>0.574834</td>\n",
              "      <td>-0.721523</td>\n",
              "      <td>3.440356</td>\n",
              "      <td>-5.116458</td>\n",
              "      <td>-0.102093</td>\n",
              "      <td>-3.947001</td>\n",
              "      <td>-0.314869</td>\n",
              "      <td>-4.875519</td>\n",
              "      <td>0.778866</td>\n",
              "      <td>-1.585237</td>\n",
              "      <td>-1.849678</td>\n",
              "      <td>-1.847233</td>\n",
              "      <td>1.092521</td>\n",
              "      <td>-3.564824</td>\n",
              "      <td>-0.000438</td>\n",
              "      <td>-4.550419</td>\n",
              "      <td>2.057372</td>\n",
              "      <td>2.670676</td>\n",
              "      <td>2.381834</td>\n",
              "      <td>5.468719</td>\n",
              "      <td>1.215846</td>\n",
              "      <td>1.305446</td>\n",
              "      <td>2.757224</td>\n",
              "      <td>4.803069</td>\n",
              "      <td>8.149659</td>\n",
              "      <td>13.111974</td>\n",
              "      <td>10.990307</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-377.455566</td>\n",
              "      <td>73.082817</td>\n",
              "      <td>-10.737463</td>\n",
              "      <td>-7.462482</td>\n",
              "      <td>-23.641148</td>\n",
              "      <td>-4.974933</td>\n",
              "      <td>-23.276512</td>\n",
              "      <td>8.385411</td>\n",
              "      <td>-23.189186</td>\n",
              "      <td>-0.063893</td>\n",
              "      <td>-9.823548</td>\n",
              "      <td>6.005100</td>\n",
              "      <td>-5.702047</td>\n",
              "      <td>8.406502</td>\n",
              "      <td>-1.954097</td>\n",
              "      <td>-0.765503</td>\n",
              "      <td>2.988822</td>\n",
              "      <td>-7.720791</td>\n",
              "      <td>-3.357804</td>\n",
              "      <td>-14.964339</td>\n",
              "      <td>-7.857167</td>\n",
              "      <td>4.007063</td>\n",
              "      <td>2.325056</td>\n",
              "      <td>24.812960</td>\n",
              "      <td>32.682426</td>\n",
              "      <td>29.723614</td>\n",
              "      <td>24.545841</td>\n",
              "      <td>11.989907</td>\n",
              "      <td>-3.940581</td>\n",
              "      <td>1.062329</td>\n",
              "      <td>6.382897</td>\n",
              "      <td>6.879652</td>\n",
              "      <td>5.575891</td>\n",
              "      <td>-6.748487</td>\n",
              "      <td>2.554098</td>\n",
              "      <td>3.614750</td>\n",
              "      <td>2.604027</td>\n",
              "      <td>4.560569</td>\n",
              "      <td>-3.299785</td>\n",
              "      <td>-1.893383</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-441.007812</td>\n",
              "      <td>106.324257</td>\n",
              "      <td>16.216305</td>\n",
              "      <td>-0.372754</td>\n",
              "      <td>-5.662180</td>\n",
              "      <td>4.839087</td>\n",
              "      <td>-13.598363</td>\n",
              "      <td>2.684526</td>\n",
              "      <td>-17.585520</td>\n",
              "      <td>4.506482</td>\n",
              "      <td>-12.935452</td>\n",
              "      <td>4.270218</td>\n",
              "      <td>-3.772748</td>\n",
              "      <td>4.330646</td>\n",
              "      <td>-4.751668</td>\n",
              "      <td>4.130186</td>\n",
              "      <td>-7.860377</td>\n",
              "      <td>1.021247</td>\n",
              "      <td>2.678426</td>\n",
              "      <td>-4.332246</td>\n",
              "      <td>2.458763</td>\n",
              "      <td>-1.561373</td>\n",
              "      <td>-4.034244</td>\n",
              "      <td>0.284167</td>\n",
              "      <td>-2.059279</td>\n",
              "      <td>2.185651</td>\n",
              "      <td>0.997926</td>\n",
              "      <td>2.565215</td>\n",
              "      <td>-1.885430</td>\n",
              "      <td>2.958353</td>\n",
              "      <td>1.395845</td>\n",
              "      <td>1.285095</td>\n",
              "      <td>2.312257</td>\n",
              "      <td>1.341361</td>\n",
              "      <td>3.835270</td>\n",
              "      <td>4.534562</td>\n",
              "      <td>6.228664</td>\n",
              "      <td>5.207438</td>\n",
              "      <td>7.394763</td>\n",
              "      <td>4.162154</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3223</th>\n",
              "      <td>-424.102631</td>\n",
              "      <td>50.220345</td>\n",
              "      <td>5.280477</td>\n",
              "      <td>31.249874</td>\n",
              "      <td>-3.558672</td>\n",
              "      <td>3.148294</td>\n",
              "      <td>-16.952879</td>\n",
              "      <td>-2.550165</td>\n",
              "      <td>-18.290178</td>\n",
              "      <td>3.051919</td>\n",
              "      <td>-12.109235</td>\n",
              "      <td>6.086262</td>\n",
              "      <td>-10.462587</td>\n",
              "      <td>8.237639</td>\n",
              "      <td>-6.127250</td>\n",
              "      <td>-0.689233</td>\n",
              "      <td>0.128365</td>\n",
              "      <td>0.338181</td>\n",
              "      <td>-3.182065</td>\n",
              "      <td>6.525580</td>\n",
              "      <td>-4.005524</td>\n",
              "      <td>2.205443</td>\n",
              "      <td>-2.934959</td>\n",
              "      <td>-0.969866</td>\n",
              "      <td>-0.997667</td>\n",
              "      <td>2.688710</td>\n",
              "      <td>2.467833</td>\n",
              "      <td>4.423583</td>\n",
              "      <td>0.931781</td>\n",
              "      <td>4.049232</td>\n",
              "      <td>0.505273</td>\n",
              "      <td>2.807501</td>\n",
              "      <td>2.110786</td>\n",
              "      <td>2.967800</td>\n",
              "      <td>6.843550</td>\n",
              "      <td>2.920174</td>\n",
              "      <td>5.495839</td>\n",
              "      <td>0.826391</td>\n",
              "      <td>1.603555</td>\n",
              "      <td>1.449678</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3224</th>\n",
              "      <td>-629.009705</td>\n",
              "      <td>71.803665</td>\n",
              "      <td>-13.054039</td>\n",
              "      <td>16.834644</td>\n",
              "      <td>-0.881978</td>\n",
              "      <td>3.192518</td>\n",
              "      <td>-16.577543</td>\n",
              "      <td>-2.459741</td>\n",
              "      <td>-13.057360</td>\n",
              "      <td>-0.645042</td>\n",
              "      <td>3.398007</td>\n",
              "      <td>-3.270434</td>\n",
              "      <td>0.496059</td>\n",
              "      <td>0.431893</td>\n",
              "      <td>-6.135400</td>\n",
              "      <td>3.120549</td>\n",
              "      <td>-7.691580</td>\n",
              "      <td>-7.917079</td>\n",
              "      <td>-0.264394</td>\n",
              "      <td>-1.961484</td>\n",
              "      <td>-5.957329</td>\n",
              "      <td>2.215244</td>\n",
              "      <td>-7.867542</td>\n",
              "      <td>-3.987488</td>\n",
              "      <td>-1.436217</td>\n",
              "      <td>-0.775939</td>\n",
              "      <td>-3.145589</td>\n",
              "      <td>0.131595</td>\n",
              "      <td>1.379427</td>\n",
              "      <td>-3.193994</td>\n",
              "      <td>0.779776</td>\n",
              "      <td>-3.653557</td>\n",
              "      <td>-0.611122</td>\n",
              "      <td>1.265297</td>\n",
              "      <td>1.623224</td>\n",
              "      <td>6.144341</td>\n",
              "      <td>6.033154</td>\n",
              "      <td>8.222058</td>\n",
              "      <td>10.686578</td>\n",
              "      <td>13.309019</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3225</th>\n",
              "      <td>-407.533295</td>\n",
              "      <td>100.624641</td>\n",
              "      <td>-0.357953</td>\n",
              "      <td>-7.473151</td>\n",
              "      <td>0.395731</td>\n",
              "      <td>8.183878</td>\n",
              "      <td>-15.549829</td>\n",
              "      <td>-2.930701</td>\n",
              "      <td>-20.452114</td>\n",
              "      <td>4.797516</td>\n",
              "      <td>-13.538960</td>\n",
              "      <td>8.235224</td>\n",
              "      <td>-5.792833</td>\n",
              "      <td>5.452796</td>\n",
              "      <td>-5.889821</td>\n",
              "      <td>4.557324</td>\n",
              "      <td>-7.605832</td>\n",
              "      <td>3.734197</td>\n",
              "      <td>-0.734187</td>\n",
              "      <td>-3.371954</td>\n",
              "      <td>-1.562292</td>\n",
              "      <td>-1.115793</td>\n",
              "      <td>-5.337512</td>\n",
              "      <td>0.172614</td>\n",
              "      <td>-4.955670</td>\n",
              "      <td>1.489311</td>\n",
              "      <td>2.315080</td>\n",
              "      <td>1.540555</td>\n",
              "      <td>1.582029</td>\n",
              "      <td>2.554183</td>\n",
              "      <td>2.392972</td>\n",
              "      <td>3.839700</td>\n",
              "      <td>4.596242</td>\n",
              "      <td>1.910476</td>\n",
              "      <td>4.091929</td>\n",
              "      <td>3.469090</td>\n",
              "      <td>6.803777</td>\n",
              "      <td>5.846513</td>\n",
              "      <td>9.960587</td>\n",
              "      <td>9.197869</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3226</th>\n",
              "      <td>-340.759277</td>\n",
              "      <td>46.869247</td>\n",
              "      <td>-21.296412</td>\n",
              "      <td>14.297091</td>\n",
              "      <td>-7.328916</td>\n",
              "      <td>8.740629</td>\n",
              "      <td>-8.607785</td>\n",
              "      <td>-10.973027</td>\n",
              "      <td>-9.456752</td>\n",
              "      <td>15.201485</td>\n",
              "      <td>-27.008495</td>\n",
              "      <td>15.028200</td>\n",
              "      <td>-6.419498</td>\n",
              "      <td>3.820722</td>\n",
              "      <td>0.179731</td>\n",
              "      <td>-1.664312</td>\n",
              "      <td>-1.559684</td>\n",
              "      <td>12.313401</td>\n",
              "      <td>-4.466780</td>\n",
              "      <td>13.167559</td>\n",
              "      <td>9.448455</td>\n",
              "      <td>3.055159</td>\n",
              "      <td>-3.033776</td>\n",
              "      <td>2.072622</td>\n",
              "      <td>3.217650</td>\n",
              "      <td>13.552663</td>\n",
              "      <td>3.615517</td>\n",
              "      <td>1.193751</td>\n",
              "      <td>-0.822213</td>\n",
              "      <td>4.343723</td>\n",
              "      <td>3.226778</td>\n",
              "      <td>2.518669</td>\n",
              "      <td>-4.215891</td>\n",
              "      <td>-5.093396</td>\n",
              "      <td>-0.510830</td>\n",
              "      <td>1.311080</td>\n",
              "      <td>1.495571</td>\n",
              "      <td>1.253940</td>\n",
              "      <td>5.425027</td>\n",
              "      <td>3.144011</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3227</th>\n",
              "      <td>-532.201416</td>\n",
              "      <td>37.814674</td>\n",
              "      <td>-24.501986</td>\n",
              "      <td>9.511352</td>\n",
              "      <td>-22.578871</td>\n",
              "      <td>-7.760836</td>\n",
              "      <td>-7.559933</td>\n",
              "      <td>-11.280194</td>\n",
              "      <td>-11.723581</td>\n",
              "      <td>-2.682984</td>\n",
              "      <td>-11.034406</td>\n",
              "      <td>-4.460667</td>\n",
              "      <td>-9.647865</td>\n",
              "      <td>0.162579</td>\n",
              "      <td>-8.192384</td>\n",
              "      <td>-0.947688</td>\n",
              "      <td>-5.886878</td>\n",
              "      <td>3.983117</td>\n",
              "      <td>0.153583</td>\n",
              "      <td>11.698050</td>\n",
              "      <td>8.545675</td>\n",
              "      <td>8.916297</td>\n",
              "      <td>2.151584</td>\n",
              "      <td>0.060913</td>\n",
              "      <td>-5.278646</td>\n",
              "      <td>-0.347770</td>\n",
              "      <td>2.562568</td>\n",
              "      <td>-1.285123</td>\n",
              "      <td>-5.945213</td>\n",
              "      <td>-3.998254</td>\n",
              "      <td>-1.736574</td>\n",
              "      <td>1.659708</td>\n",
              "      <td>-1.752408</td>\n",
              "      <td>-4.361268</td>\n",
              "      <td>-2.735076</td>\n",
              "      <td>0.449958</td>\n",
              "      <td>0.943044</td>\n",
              "      <td>-0.721119</td>\n",
              "      <td>0.054852</td>\n",
              "      <td>4.308853</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3228 rows Ã— 41 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17e112f9-52cd-42f5-b0ae-e0ccd98a90d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17e112f9-52cd-42f5-b0ae-e0ccd98a90d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17e112f9-52cd-42f5-b0ae-e0ccd98a90d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               0           1          2  ...         38         39  emotion\n",
              "0    -512.883911   57.364391  17.080887  ...  10.242604   8.848364      sad\n",
              "1    -423.976929   72.107246  -8.895686  ...   3.721366   2.546432  disgust\n",
              "2    -479.606476   60.020325 -22.544024  ...  13.111974  10.990307     fear\n",
              "3    -377.455566   73.082817 -10.737463  ...  -3.299785  -1.893383    angry\n",
              "4    -441.007812  106.324257  16.216305  ...   7.394763   4.162154  disgust\n",
              "...          ...         ...        ...  ...        ...        ...      ...\n",
              "3223 -424.102631   50.220345   5.280477  ...   1.603555   1.449678  disgust\n",
              "3224 -629.009705   71.803665 -13.054039  ...  10.686578  13.309019  neutral\n",
              "3225 -407.533295  100.624641  -0.357953  ...   9.960587   9.197869  disgust\n",
              "3226 -340.759277   46.869247 -21.296412  ...   5.425027   3.144011     fear\n",
              "3227 -532.201416   37.814674 -24.501986  ...   0.054852   4.308853    angry\n",
              "\n",
              "[3228 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZK401AlJLkI",
        "outputId": "a8ea3a26-f898-45a5-92dd-4bb357811fcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "np.unique(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueDTtv1nJM9H"
      },
      "outputs": [],
      "source": [
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "new test split"
      ],
      "metadata": {
        "id": "phOJ7CxDXpEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42) # 0.125 x 0.8 = 0.1"
      ],
      "metadata": {
        "id": "kKkuwItBXEVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "lb = LabelEncoder()\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_val = np_utils.to_categorical(lb.fit_transform(y_val))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))"
      ],
      "metadata": {
        "id": "Aaxygy7_YDfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_trainrnn = np.expand_dims(X_train, axis=2)\n",
        "x_valrnn = np.expand_dims(X_val, axis=2)\n",
        "x_testrnn = np.expand_dims(X_test, axis=2)"
      ],
      "metadata": {
        "id": "mysocTqAZY7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNJMWeuAE4fV"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def fscore(y_true, y_pred):\n",
        "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    f_score = 2 * (p * r) / (p + r + K.epsilon())\n",
        "    return f_score\n",
        "\n",
        "def get_lr_metric(optimizer):\n",
        "    def lr(y_true, y_pred):\n",
        "        return optimizer.lr\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wjKCtELI3d3"
      },
      "source": [
        "RNN SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWbdh9m1I5ln",
        "outputId": "b52445ac-63ba-4888-d431-259edc40227a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 128)               16640     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,414\n",
            "Trainable params: 17,414\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "#model = keras.Sequential()\n",
        "#model.add(layers.Embedding(input_dim=3228, output_dim=6))\n",
        "\n",
        "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
        "#model.add(layers.GRU(256, return_sequences=True))\n",
        "\n",
        "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
        "#model.add(layers.SimpleRNN(128))\n",
        "\n",
        "#model.add(layers.Dense(6))\n",
        "\n",
        "#model.summary()\n",
        "\n",
        "hidden_units = 128\n",
        "input_shape=(X_train.shape[1],1)\n",
        "dense_units = 6\n",
        "\n",
        "model = Sequential()\n",
        "model.add(keras.layers.SimpleRNN(hidden_units, input_shape=input_shape,activation='relu'))\n",
        "model.add(Dense(units=dense_units, activation='softmax'))\n",
        "opt = tensorflow.keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', fscore])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gJJrDEpZBgp",
        "outputId": "accfd33c-4327-4369-e6ca-f6ebed2dacc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2259, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_trainrnn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VgglCRVZLoc",
        "outputId": "350c95b6-e839-4718-b1af-acbfb7c66426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2259, 40, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEiDKDsbFLR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae03895-366a-4922-eac5-176aff786d2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "142/142 [==============================] - 4s 17ms/step - loss: 1.9953 - accuracy: 0.2435 - fscore: 0.0682 - val_loss: 1.7017 - val_accuracy: 0.3344 - val_fscore: 0.1501 - lr: 1.0000e-04\n",
            "Epoch 2/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.6484 - accuracy: 0.3178 - fscore: 0.1956 - val_loss: 1.6199 - val_accuracy: 0.3220 - val_fscore: 0.1801 - lr: 1.0000e-04\n",
            "Epoch 3/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.6057 - accuracy: 0.3240 - fscore: 0.1995 - val_loss: 1.5963 - val_accuracy: 0.3313 - val_fscore: 0.1790 - lr: 1.0000e-04\n",
            "Epoch 4/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.5891 - accuracy: 0.3130 - fscore: 0.1969 - val_loss: 1.5834 - val_accuracy: 0.3344 - val_fscore: 0.1795 - lr: 1.0000e-04\n",
            "Epoch 5/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.5778 - accuracy: 0.3187 - fscore: 0.1988 - val_loss: 1.5727 - val_accuracy: 0.3282 - val_fscore: 0.1800 - lr: 1.0000e-04\n",
            "Epoch 6/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.5682 - accuracy: 0.3147 - fscore: 0.1971 - val_loss: 1.5636 - val_accuracy: 0.3344 - val_fscore: 0.1800 - lr: 1.0000e-04\n",
            "Epoch 7/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.5595 - accuracy: 0.3223 - fscore: 0.1987 - val_loss: 1.5551 - val_accuracy: 0.3406 - val_fscore: 0.1806 - lr: 1.0000e-04\n",
            "Epoch 8/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.5516 - accuracy: 0.3232 - fscore: 0.1999 - val_loss: 1.5466 - val_accuracy: 0.3622 - val_fscore: 0.1800 - lr: 1.0000e-04\n",
            "Epoch 9/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.5440 - accuracy: 0.3293 - fscore: 0.1997 - val_loss: 1.5384 - val_accuracy: 0.3622 - val_fscore: 0.1806 - lr: 1.0000e-04\n",
            "Epoch 10/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.5366 - accuracy: 0.3382 - fscore: 0.2023 - val_loss: 1.5303 - val_accuracy: 0.3684 - val_fscore: 0.1806 - lr: 1.0000e-04\n",
            "Epoch 11/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.5290 - accuracy: 0.3431 - fscore: 0.2023 - val_loss: 1.5226 - val_accuracy: 0.3808 - val_fscore: 0.1854 - lr: 1.0000e-04\n",
            "Epoch 12/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 1.5214 - accuracy: 0.3479 - fscore: 0.2005 - val_loss: 1.5142 - val_accuracy: 0.3901 - val_fscore: 0.1848 - lr: 1.0000e-04\n",
            "Epoch 13/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.5137 - accuracy: 0.3572 - fscore: 0.2066 - val_loss: 1.5062 - val_accuracy: 0.4025 - val_fscore: 0.1806 - lr: 1.0000e-04\n",
            "Epoch 14/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.5060 - accuracy: 0.3683 - fscore: 0.2053 - val_loss: 1.4989 - val_accuracy: 0.3994 - val_fscore: 0.1854 - lr: 1.0000e-04\n",
            "Epoch 15/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.4982 - accuracy: 0.3696 - fscore: 0.2077 - val_loss: 1.4906 - val_accuracy: 0.4087 - val_fscore: 0.1851 - lr: 1.0000e-04\n",
            "Epoch 16/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.4903 - accuracy: 0.3785 - fscore: 0.2103 - val_loss: 1.4827 - val_accuracy: 0.4211 - val_fscore: 0.1901 - lr: 1.0000e-04\n",
            "Epoch 17/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.4824 - accuracy: 0.3811 - fscore: 0.2080 - val_loss: 1.4739 - val_accuracy: 0.4334 - val_fscore: 0.1864 - lr: 1.0000e-04\n",
            "Epoch 18/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.4740 - accuracy: 0.3869 - fscore: 0.2077 - val_loss: 1.4658 - val_accuracy: 0.4241 - val_fscore: 0.1959 - lr: 1.0000e-04\n",
            "Epoch 19/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.4658 - accuracy: 0.3922 - fscore: 0.2080 - val_loss: 1.4562 - val_accuracy: 0.4489 - val_fscore: 0.1959 - lr: 1.0000e-04\n",
            "Epoch 20/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.4569 - accuracy: 0.3971 - fscore: 0.2089 - val_loss: 1.4457 - val_accuracy: 0.4489 - val_fscore: 0.1951 - lr: 1.0000e-04\n",
            "Epoch 21/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.4477 - accuracy: 0.4046 - fscore: 0.2135 - val_loss: 1.4359 - val_accuracy: 0.4489 - val_fscore: 0.2001 - lr: 1.0000e-04\n",
            "Epoch 22/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.4379 - accuracy: 0.4104 - fscore: 0.2158 - val_loss: 1.4246 - val_accuracy: 0.4520 - val_fscore: 0.2000 - lr: 1.0000e-04\n",
            "Epoch 23/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.4285 - accuracy: 0.4148 - fscore: 0.2279 - val_loss: 1.4124 - val_accuracy: 0.4675 - val_fscore: 0.2050 - lr: 1.0000e-04\n",
            "Epoch 24/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.4177 - accuracy: 0.4166 - fscore: 0.2358 - val_loss: 1.3993 - val_accuracy: 0.4706 - val_fscore: 0.2195 - lr: 1.0000e-04\n",
            "Epoch 25/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.4062 - accuracy: 0.4259 - fscore: 0.2456 - val_loss: 1.3852 - val_accuracy: 0.4706 - val_fscore: 0.2427 - lr: 1.0000e-04\n",
            "Epoch 26/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.3936 - accuracy: 0.4267 - fscore: 0.2590 - val_loss: 1.3701 - val_accuracy: 0.4737 - val_fscore: 0.2680 - lr: 1.0000e-04\n",
            "Epoch 27/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.3800 - accuracy: 0.4382 - fscore: 0.2718 - val_loss: 1.3527 - val_accuracy: 0.4737 - val_fscore: 0.3074 - lr: 1.0000e-04\n",
            "Epoch 28/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.3659 - accuracy: 0.4369 - fscore: 0.2992 - val_loss: 1.3369 - val_accuracy: 0.4923 - val_fscore: 0.3218 - lr: 1.0000e-04\n",
            "Epoch 29/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.3512 - accuracy: 0.4458 - fscore: 0.3070 - val_loss: 1.3208 - val_accuracy: 0.4923 - val_fscore: 0.3434 - lr: 1.0000e-04\n",
            "Epoch 30/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.3367 - accuracy: 0.4511 - fscore: 0.3265 - val_loss: 1.3032 - val_accuracy: 0.4954 - val_fscore: 0.3497 - lr: 1.0000e-04\n",
            "Epoch 31/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 1.3217 - accuracy: 0.4564 - fscore: 0.3397 - val_loss: 1.2856 - val_accuracy: 0.4861 - val_fscore: 0.3615 - lr: 1.0000e-04\n",
            "Epoch 32/700\n",
            "142/142 [==============================] - 3s 19ms/step - loss: 1.3073 - accuracy: 0.4648 - fscore: 0.3474 - val_loss: 1.2686 - val_accuracy: 0.4799 - val_fscore: 0.3799 - lr: 1.0000e-04\n",
            "Epoch 33/700\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 1.2934 - accuracy: 0.4688 - fscore: 0.3590 - val_loss: 1.2528 - val_accuracy: 0.4892 - val_fscore: 0.3918 - lr: 1.0000e-04\n",
            "Epoch 34/700\n",
            "142/142 [==============================] - 3s 23ms/step - loss: 1.2795 - accuracy: 0.4710 - fscore: 0.3721 - val_loss: 1.2375 - val_accuracy: 0.4954 - val_fscore: 0.3918 - lr: 1.0000e-04\n",
            "Epoch 35/700\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 1.2661 - accuracy: 0.4741 - fscore: 0.3805 - val_loss: 1.2232 - val_accuracy: 0.5015 - val_fscore: 0.3842 - lr: 1.0000e-04\n",
            "Epoch 36/700\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 1.2526 - accuracy: 0.4825 - fscore: 0.3835 - val_loss: 1.2072 - val_accuracy: 0.5139 - val_fscore: 0.4047 - lr: 1.0000e-04\n",
            "Epoch 37/700\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 1.2394 - accuracy: 0.4852 - fscore: 0.3914 - val_loss: 1.1926 - val_accuracy: 0.5046 - val_fscore: 0.3994 - lr: 1.0000e-04\n",
            "Epoch 38/700\n",
            "142/142 [==============================] - 4s 25ms/step - loss: 1.2260 - accuracy: 0.4887 - fscore: 0.3905 - val_loss: 1.1771 - val_accuracy: 0.5139 - val_fscore: 0.4152 - lr: 1.0000e-04\n",
            "Epoch 39/700\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 1.2120 - accuracy: 0.4869 - fscore: 0.3956 - val_loss: 1.1611 - val_accuracy: 0.5108 - val_fscore: 0.4202 - lr: 1.0000e-04\n",
            "Epoch 40/700\n",
            "142/142 [==============================] - 3s 23ms/step - loss: 1.1976 - accuracy: 0.4905 - fscore: 0.4096 - val_loss: 1.1454 - val_accuracy: 0.5077 - val_fscore: 0.4148 - lr: 1.0000e-04\n",
            "Epoch 41/700\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 1.1826 - accuracy: 0.4993 - fscore: 0.3992 - val_loss: 1.1274 - val_accuracy: 0.5139 - val_fscore: 0.4165 - lr: 1.0000e-04\n",
            "Epoch 42/700\n",
            "142/142 [==============================] - 3s 20ms/step - loss: 1.1669 - accuracy: 0.5024 - fscore: 0.4132 - val_loss: 1.1085 - val_accuracy: 0.5201 - val_fscore: 0.4270 - lr: 1.0000e-04\n",
            "Epoch 43/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.1501 - accuracy: 0.5126 - fscore: 0.4200 - val_loss: 1.0875 - val_accuracy: 0.5542 - val_fscore: 0.4332 - lr: 1.0000e-04\n",
            "Epoch 44/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.1322 - accuracy: 0.5201 - fscore: 0.4335 - val_loss: 1.0663 - val_accuracy: 0.5697 - val_fscore: 0.4407 - lr: 1.0000e-04\n",
            "Epoch 45/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.1129 - accuracy: 0.5330 - fscore: 0.4382 - val_loss: 1.0429 - val_accuracy: 0.5728 - val_fscore: 0.4521 - lr: 1.0000e-04\n",
            "Epoch 46/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.0939 - accuracy: 0.5498 - fscore: 0.4577 - val_loss: 1.0208 - val_accuracy: 0.6006 - val_fscore: 0.4747 - lr: 1.0000e-04\n",
            "Epoch 47/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 1.0764 - accuracy: 0.5626 - fscore: 0.4660 - val_loss: 1.0032 - val_accuracy: 0.6037 - val_fscore: 0.5024 - lr: 1.0000e-04\n",
            "Epoch 48/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 1.0592 - accuracy: 0.5724 - fscore: 0.4806 - val_loss: 0.9878 - val_accuracy: 0.6099 - val_fscore: 0.5009 - lr: 1.0000e-04\n",
            "Epoch 49/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.0441 - accuracy: 0.5795 - fscore: 0.4943 - val_loss: 0.9751 - val_accuracy: 0.6254 - val_fscore: 0.5064 - lr: 1.0000e-04\n",
            "Epoch 50/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 1.0296 - accuracy: 0.5910 - fscore: 0.4956 - val_loss: 0.9572 - val_accuracy: 0.6285 - val_fscore: 0.5384 - lr: 1.0000e-04\n",
            "Epoch 51/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.0152 - accuracy: 0.5967 - fscore: 0.5134 - val_loss: 0.9487 - val_accuracy: 0.6316 - val_fscore: 0.5597 - lr: 1.0000e-04\n",
            "Epoch 52/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 1.0028 - accuracy: 0.6060 - fscore: 0.5198 - val_loss: 0.9329 - val_accuracy: 0.6502 - val_fscore: 0.5463 - lr: 1.0000e-04\n",
            "Epoch 53/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.9903 - accuracy: 0.6193 - fscore: 0.5321 - val_loss: 0.9207 - val_accuracy: 0.6471 - val_fscore: 0.5889 - lr: 1.0000e-04\n",
            "Epoch 54/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.9803 - accuracy: 0.6189 - fscore: 0.5418 - val_loss: 0.9156 - val_accuracy: 0.6502 - val_fscore: 0.5761 - lr: 1.0000e-04\n",
            "Epoch 55/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.9691 - accuracy: 0.6242 - fscore: 0.5442 - val_loss: 0.9046 - val_accuracy: 0.6656 - val_fscore: 0.5930 - lr: 1.0000e-04\n",
            "Epoch 56/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.9582 - accuracy: 0.6352 - fscore: 0.5556 - val_loss: 0.8950 - val_accuracy: 0.6502 - val_fscore: 0.6008 - lr: 1.0000e-04\n",
            "Epoch 57/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.9482 - accuracy: 0.6414 - fscore: 0.5634 - val_loss: 0.8906 - val_accuracy: 0.6471 - val_fscore: 0.5977 - lr: 1.0000e-04\n",
            "Epoch 58/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.9386 - accuracy: 0.6459 - fscore: 0.5715 - val_loss: 0.8751 - val_accuracy: 0.6625 - val_fscore: 0.6191 - lr: 1.0000e-04\n",
            "Epoch 59/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.9296 - accuracy: 0.6476 - fscore: 0.5810 - val_loss: 0.8758 - val_accuracy: 0.6563 - val_fscore: 0.6135 - lr: 1.0000e-04\n",
            "Epoch 60/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.9205 - accuracy: 0.6529 - fscore: 0.5904 - val_loss: 0.8636 - val_accuracy: 0.6687 - val_fscore: 0.6243 - lr: 1.0000e-04\n",
            "Epoch 61/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.9122 - accuracy: 0.6569 - fscore: 0.5997 - val_loss: 0.8507 - val_accuracy: 0.6842 - val_fscore: 0.6375 - lr: 1.0000e-04\n",
            "Epoch 62/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.9052 - accuracy: 0.6556 - fscore: 0.6137 - val_loss: 0.8460 - val_accuracy: 0.6842 - val_fscore: 0.6396 - lr: 1.0000e-04\n",
            "Epoch 63/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.8970 - accuracy: 0.6631 - fscore: 0.6115 - val_loss: 0.8386 - val_accuracy: 0.6997 - val_fscore: 0.6373 - lr: 1.0000e-04\n",
            "Epoch 64/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.8879 - accuracy: 0.6671 - fscore: 0.6264 - val_loss: 0.8272 - val_accuracy: 0.6904 - val_fscore: 0.6461 - lr: 1.0000e-04\n",
            "Epoch 65/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.8788 - accuracy: 0.6702 - fscore: 0.6370 - val_loss: 0.8341 - val_accuracy: 0.7059 - val_fscore: 0.6559 - lr: 1.0000e-04\n",
            "Epoch 66/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.8720 - accuracy: 0.6711 - fscore: 0.6393 - val_loss: 0.8097 - val_accuracy: 0.7028 - val_fscore: 0.6537 - lr: 1.0000e-04\n",
            "Epoch 67/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.8622 - accuracy: 0.6729 - fscore: 0.6459 - val_loss: 0.8087 - val_accuracy: 0.6997 - val_fscore: 0.6541 - lr: 1.0000e-04\n",
            "Epoch 68/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.8538 - accuracy: 0.6786 - fscore: 0.6536 - val_loss: 0.7927 - val_accuracy: 0.7059 - val_fscore: 0.6723 - lr: 1.0000e-04\n",
            "Epoch 69/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.8450 - accuracy: 0.6848 - fscore: 0.6605 - val_loss: 0.7923 - val_accuracy: 0.7028 - val_fscore: 0.6747 - lr: 1.0000e-04\n",
            "Epoch 70/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.8379 - accuracy: 0.6813 - fscore: 0.6596 - val_loss: 0.7802 - val_accuracy: 0.7183 - val_fscore: 0.6833 - lr: 1.0000e-04\n",
            "Epoch 71/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.8301 - accuracy: 0.6875 - fscore: 0.6671 - val_loss: 0.7696 - val_accuracy: 0.7183 - val_fscore: 0.6865 - lr: 1.0000e-04\n",
            "Epoch 72/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.8223 - accuracy: 0.6910 - fscore: 0.6708 - val_loss: 0.7680 - val_accuracy: 0.7152 - val_fscore: 0.6923 - lr: 1.0000e-04\n",
            "Epoch 73/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.8166 - accuracy: 0.6879 - fscore: 0.6705 - val_loss: 0.7664 - val_accuracy: 0.7059 - val_fscore: 0.6851 - lr: 1.0000e-04\n",
            "Epoch 74/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.8097 - accuracy: 0.6937 - fscore: 0.6783 - val_loss: 0.7537 - val_accuracy: 0.7183 - val_fscore: 0.6877 - lr: 1.0000e-04\n",
            "Epoch 75/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.8028 - accuracy: 0.6963 - fscore: 0.6808 - val_loss: 0.7489 - val_accuracy: 0.7152 - val_fscore: 0.6958 - lr: 1.0000e-04\n",
            "Epoch 76/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.7968 - accuracy: 0.7008 - fscore: 0.6819 - val_loss: 0.7514 - val_accuracy: 0.7214 - val_fscore: 0.6876 - lr: 1.0000e-04\n",
            "Epoch 77/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.7896 - accuracy: 0.7021 - fscore: 0.6853 - val_loss: 0.7495 - val_accuracy: 0.7337 - val_fscore: 0.6899 - lr: 1.0000e-04\n",
            "Epoch 78/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.7852 - accuracy: 0.7034 - fscore: 0.6827 - val_loss: 0.7345 - val_accuracy: 0.7214 - val_fscore: 0.6992 - lr: 1.0000e-04\n",
            "Epoch 79/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.7789 - accuracy: 0.7065 - fscore: 0.6859 - val_loss: 0.7441 - val_accuracy: 0.7368 - val_fscore: 0.6933 - lr: 1.0000e-04\n",
            "Epoch 80/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.7729 - accuracy: 0.7092 - fscore: 0.6850 - val_loss: 0.7342 - val_accuracy: 0.7368 - val_fscore: 0.7036 - lr: 1.0000e-04\n",
            "Epoch 81/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.7674 - accuracy: 0.7109 - fscore: 0.6934 - val_loss: 0.7238 - val_accuracy: 0.7430 - val_fscore: 0.7049 - lr: 1.0000e-04\n",
            "Epoch 82/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.7619 - accuracy: 0.7131 - fscore: 0.6896 - val_loss: 0.7163 - val_accuracy: 0.7523 - val_fscore: 0.7064 - lr: 1.0000e-04\n",
            "Epoch 83/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.7571 - accuracy: 0.7154 - fscore: 0.6915 - val_loss: 0.7164 - val_accuracy: 0.7492 - val_fscore: 0.6956 - lr: 1.0000e-04\n",
            "Epoch 84/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.7522 - accuracy: 0.7158 - fscore: 0.6986 - val_loss: 0.7195 - val_accuracy: 0.7585 - val_fscore: 0.7042 - lr: 1.0000e-04\n",
            "Epoch 85/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.7468 - accuracy: 0.7171 - fscore: 0.7032 - val_loss: 0.7116 - val_accuracy: 0.7554 - val_fscore: 0.7085 - lr: 1.0000e-04\n",
            "Epoch 86/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.7425 - accuracy: 0.7233 - fscore: 0.7050 - val_loss: 0.7017 - val_accuracy: 0.7554 - val_fscore: 0.6982 - lr: 1.0000e-04\n",
            "Epoch 87/700\n",
            "142/142 [==============================] - 3s 19ms/step - loss: 0.7372 - accuracy: 0.7229 - fscore: 0.6988 - val_loss: 0.6882 - val_accuracy: 0.7523 - val_fscore: 0.7063 - lr: 1.0000e-04\n",
            "Epoch 88/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.7327 - accuracy: 0.7211 - fscore: 0.6985 - val_loss: 0.6884 - val_accuracy: 0.7492 - val_fscore: 0.7070 - lr: 1.0000e-04\n",
            "Epoch 89/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.7294 - accuracy: 0.7278 - fscore: 0.6996 - val_loss: 0.6879 - val_accuracy: 0.7461 - val_fscore: 0.7059 - lr: 1.0000e-04\n",
            "Epoch 90/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.7228 - accuracy: 0.7295 - fscore: 0.6977 - val_loss: 0.6942 - val_accuracy: 0.7492 - val_fscore: 0.7125 - lr: 1.0000e-04\n",
            "Epoch 91/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.7187 - accuracy: 0.7344 - fscore: 0.7071 - val_loss: 0.6795 - val_accuracy: 0.7647 - val_fscore: 0.7205 - lr: 1.0000e-04\n",
            "Epoch 92/700\n",
            "142/142 [==============================] - 4s 26ms/step - loss: 0.7146 - accuracy: 0.7375 - fscore: 0.7110 - val_loss: 0.6768 - val_accuracy: 0.7461 - val_fscore: 0.7080 - lr: 1.0000e-04\n",
            "Epoch 93/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.7094 - accuracy: 0.7366 - fscore: 0.7104 - val_loss: 0.6646 - val_accuracy: 0.7678 - val_fscore: 0.7284 - lr: 1.0000e-04\n",
            "Epoch 94/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.7022 - accuracy: 0.7375 - fscore: 0.7138 - val_loss: 0.6773 - val_accuracy: 0.7678 - val_fscore: 0.7200 - lr: 1.0000e-04\n",
            "Epoch 95/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.6993 - accuracy: 0.7419 - fscore: 0.7176 - val_loss: 0.6793 - val_accuracy: 0.7523 - val_fscore: 0.7168 - lr: 1.0000e-04\n",
            "Epoch 96/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.6944 - accuracy: 0.7335 - fscore: 0.7189 - val_loss: 0.6547 - val_accuracy: 0.7709 - val_fscore: 0.7136 - lr: 1.0000e-04\n",
            "Epoch 97/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.6912 - accuracy: 0.7424 - fscore: 0.7184 - val_loss: 0.6528 - val_accuracy: 0.7678 - val_fscore: 0.7120 - lr: 1.0000e-04\n",
            "Epoch 98/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.6816 - accuracy: 0.7437 - fscore: 0.7223 - val_loss: 0.6683 - val_accuracy: 0.7616 - val_fscore: 0.7256 - lr: 1.0000e-04\n",
            "Epoch 99/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.6825 - accuracy: 0.7477 - fscore: 0.7233 - val_loss: 0.6639 - val_accuracy: 0.7461 - val_fscore: 0.7053 - lr: 1.0000e-04\n",
            "Epoch 100/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.6770 - accuracy: 0.7490 - fscore: 0.7283 - val_loss: 0.6458 - val_accuracy: 0.7647 - val_fscore: 0.7191 - lr: 1.0000e-04\n",
            "Epoch 101/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.6731 - accuracy: 0.7463 - fscore: 0.7260 - val_loss: 0.6833 - val_accuracy: 0.7554 - val_fscore: 0.7051 - lr: 1.0000e-04\n",
            "Epoch 102/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.6679 - accuracy: 0.7463 - fscore: 0.7314 - val_loss: 0.6308 - val_accuracy: 0.7616 - val_fscore: 0.7180 - lr: 1.0000e-04\n",
            "Epoch 103/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.6611 - accuracy: 0.7574 - fscore: 0.7279 - val_loss: 0.6395 - val_accuracy: 0.7771 - val_fscore: 0.7265 - lr: 1.0000e-04\n",
            "Epoch 104/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.6580 - accuracy: 0.7521 - fscore: 0.7314 - val_loss: 0.6264 - val_accuracy: 0.7709 - val_fscore: 0.7225 - lr: 1.0000e-04\n",
            "Epoch 105/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.6507 - accuracy: 0.7552 - fscore: 0.7346 - val_loss: 0.6209 - val_accuracy: 0.7771 - val_fscore: 0.7393 - lr: 1.0000e-04\n",
            "Epoch 106/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.6484 - accuracy: 0.7596 - fscore: 0.7318 - val_loss: 0.6207 - val_accuracy: 0.7709 - val_fscore: 0.7232 - lr: 1.0000e-04\n",
            "Epoch 107/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.6442 - accuracy: 0.7587 - fscore: 0.7396 - val_loss: 0.6136 - val_accuracy: 0.7740 - val_fscore: 0.7184 - lr: 1.0000e-04\n",
            "Epoch 108/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.6379 - accuracy: 0.7614 - fscore: 0.7384 - val_loss: 0.6042 - val_accuracy: 0.7771 - val_fscore: 0.7214 - lr: 1.0000e-04\n",
            "Epoch 109/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.6341 - accuracy: 0.7663 - fscore: 0.7413 - val_loss: 0.6033 - val_accuracy: 0.7802 - val_fscore: 0.7376 - lr: 1.0000e-04\n",
            "Epoch 110/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.6256 - accuracy: 0.7672 - fscore: 0.7439 - val_loss: 0.6042 - val_accuracy: 0.7895 - val_fscore: 0.7283 - lr: 1.0000e-04\n",
            "Epoch 111/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.6235 - accuracy: 0.7742 - fscore: 0.7481 - val_loss: 0.5988 - val_accuracy: 0.7926 - val_fscore: 0.7363 - lr: 1.0000e-04\n",
            "Epoch 112/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.6176 - accuracy: 0.7751 - fscore: 0.7535 - val_loss: 0.6014 - val_accuracy: 0.7957 - val_fscore: 0.7308 - lr: 1.0000e-04\n",
            "Epoch 113/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.6127 - accuracy: 0.7773 - fscore: 0.7568 - val_loss: 0.6178 - val_accuracy: 0.7895 - val_fscore: 0.7153 - lr: 1.0000e-04\n",
            "Epoch 114/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.6053 - accuracy: 0.7813 - fscore: 0.7573 - val_loss: 0.5999 - val_accuracy: 0.7740 - val_fscore: 0.7504 - lr: 1.0000e-04\n",
            "Epoch 115/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.6033 - accuracy: 0.7787 - fscore: 0.7599 - val_loss: 0.5679 - val_accuracy: 0.7957 - val_fscore: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 116/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5984 - accuracy: 0.7840 - fscore: 0.7605 - val_loss: 0.7093 - val_accuracy: 0.7492 - val_fscore: 0.6991 - lr: 1.0000e-04\n",
            "Epoch 117/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.5922 - accuracy: 0.7835 - fscore: 0.7640 - val_loss: 0.5795 - val_accuracy: 0.7988 - val_fscore: 0.7484 - lr: 1.0000e-04\n",
            "Epoch 118/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5897 - accuracy: 0.7844 - fscore: 0.7636 - val_loss: 0.5858 - val_accuracy: 0.7926 - val_fscore: 0.7224 - lr: 1.0000e-04\n",
            "Epoch 119/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5840 - accuracy: 0.7880 - fscore: 0.7642 - val_loss: 0.5616 - val_accuracy: 0.8050 - val_fscore: 0.7456 - lr: 1.0000e-04\n",
            "Epoch 120/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5805 - accuracy: 0.7933 - fscore: 0.7693 - val_loss: 0.5732 - val_accuracy: 0.7988 - val_fscore: 0.7407 - lr: 1.0000e-04\n",
            "Epoch 121/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5771 - accuracy: 0.7880 - fscore: 0.7695 - val_loss: 0.5602 - val_accuracy: 0.8111 - val_fscore: 0.7531 - lr: 1.0000e-04\n",
            "Epoch 122/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5698 - accuracy: 0.7950 - fscore: 0.7743 - val_loss: 0.5526 - val_accuracy: 0.8111 - val_fscore: 0.7557 - lr: 1.0000e-04\n",
            "Epoch 123/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5682 - accuracy: 0.8017 - fscore: 0.7736 - val_loss: 0.5522 - val_accuracy: 0.8111 - val_fscore: 0.7634 - lr: 1.0000e-04\n",
            "Epoch 124/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5645 - accuracy: 0.8008 - fscore: 0.7723 - val_loss: 0.5701 - val_accuracy: 0.7895 - val_fscore: 0.7572 - lr: 1.0000e-04\n",
            "Epoch 125/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.5597 - accuracy: 0.7964 - fscore: 0.7737 - val_loss: 0.5547 - val_accuracy: 0.7957 - val_fscore: 0.7645 - lr: 1.0000e-04\n",
            "Epoch 126/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.5525 - accuracy: 0.8043 - fscore: 0.7861 - val_loss: 0.5655 - val_accuracy: 0.7926 - val_fscore: 0.7834 - lr: 1.0000e-04\n",
            "Epoch 127/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5501 - accuracy: 0.8008 - fscore: 0.7838 - val_loss: 0.5336 - val_accuracy: 0.8080 - val_fscore: 0.7852 - lr: 1.0000e-04\n",
            "Epoch 128/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5459 - accuracy: 0.8017 - fscore: 0.7855 - val_loss: 0.5585 - val_accuracy: 0.7864 - val_fscore: 0.7559 - lr: 1.0000e-04\n",
            "Epoch 129/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.5417 - accuracy: 0.8097 - fscore: 0.7911 - val_loss: 0.5307 - val_accuracy: 0.7988 - val_fscore: 0.7803 - lr: 1.0000e-04\n",
            "Epoch 130/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.5384 - accuracy: 0.8048 - fscore: 0.7806 - val_loss: 0.5650 - val_accuracy: 0.7895 - val_fscore: 0.7769 - lr: 1.0000e-04\n",
            "Epoch 131/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5305 - accuracy: 0.8145 - fscore: 0.8002 - val_loss: 0.5135 - val_accuracy: 0.8328 - val_fscore: 0.8049 - lr: 1.0000e-04\n",
            "Epoch 132/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5263 - accuracy: 0.8083 - fscore: 0.7922 - val_loss: 0.5439 - val_accuracy: 0.8111 - val_fscore: 0.7992 - lr: 1.0000e-04\n",
            "Epoch 133/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5233 - accuracy: 0.8203 - fscore: 0.7968 - val_loss: 0.5298 - val_accuracy: 0.8111 - val_fscore: 0.7894 - lr: 1.0000e-04\n",
            "Epoch 134/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5228 - accuracy: 0.8123 - fscore: 0.8025 - val_loss: 0.5184 - val_accuracy: 0.8359 - val_fscore: 0.8076 - lr: 1.0000e-04\n",
            "Epoch 135/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5140 - accuracy: 0.8176 - fscore: 0.8014 - val_loss: 0.5240 - val_accuracy: 0.8173 - val_fscore: 0.7967 - lr: 1.0000e-04\n",
            "Epoch 136/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5102 - accuracy: 0.8172 - fscore: 0.8100 - val_loss: 0.5263 - val_accuracy: 0.8019 - val_fscore: 0.8027 - lr: 1.0000e-04\n",
            "Epoch 137/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5080 - accuracy: 0.8114 - fscore: 0.8057 - val_loss: 0.4939 - val_accuracy: 0.8390 - val_fscore: 0.8235 - lr: 1.0000e-04\n",
            "Epoch 138/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.5040 - accuracy: 0.8203 - fscore: 0.8140 - val_loss: 0.5148 - val_accuracy: 0.8080 - val_fscore: 0.7993 - lr: 1.0000e-04\n",
            "Epoch 139/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4957 - accuracy: 0.8154 - fscore: 0.8135 - val_loss: 0.5183 - val_accuracy: 0.8050 - val_fscore: 0.7947 - lr: 1.0000e-04\n",
            "Epoch 140/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4964 - accuracy: 0.8225 - fscore: 0.8234 - val_loss: 0.5065 - val_accuracy: 0.8266 - val_fscore: 0.8123 - lr: 1.0000e-04\n",
            "Epoch 141/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4904 - accuracy: 0.8220 - fscore: 0.8216 - val_loss: 0.5036 - val_accuracy: 0.8235 - val_fscore: 0.8155 - lr: 1.0000e-04\n",
            "Epoch 142/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4914 - accuracy: 0.8225 - fscore: 0.8243 - val_loss: 0.4919 - val_accuracy: 0.8297 - val_fscore: 0.8146 - lr: 1.0000e-04\n",
            "Epoch 143/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4849 - accuracy: 0.8287 - fscore: 0.8224 - val_loss: 0.4928 - val_accuracy: 0.8142 - val_fscore: 0.8132 - lr: 1.0000e-04\n",
            "Epoch 144/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4755 - accuracy: 0.8322 - fscore: 0.8230 - val_loss: 0.5171 - val_accuracy: 0.8204 - val_fscore: 0.8126 - lr: 1.0000e-04\n",
            "Epoch 145/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4734 - accuracy: 0.8265 - fscore: 0.8305 - val_loss: 0.4714 - val_accuracy: 0.8421 - val_fscore: 0.8386 - lr: 1.0000e-04\n",
            "Epoch 146/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4710 - accuracy: 0.8296 - fscore: 0.8306 - val_loss: 0.4797 - val_accuracy: 0.8452 - val_fscore: 0.8296 - lr: 1.0000e-04\n",
            "Epoch 147/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.4698 - accuracy: 0.8269 - fscore: 0.8329 - val_loss: 0.4941 - val_accuracy: 0.8142 - val_fscore: 0.8200 - lr: 1.0000e-04\n",
            "Epoch 148/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4646 - accuracy: 0.8265 - fscore: 0.8321 - val_loss: 0.4776 - val_accuracy: 0.8514 - val_fscore: 0.8424 - lr: 1.0000e-04\n",
            "Epoch 149/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4636 - accuracy: 0.8260 - fscore: 0.8269 - val_loss: 0.6654 - val_accuracy: 0.7554 - val_fscore: 0.7551 - lr: 1.0000e-04\n",
            "Epoch 150/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4581 - accuracy: 0.8278 - fscore: 0.8295 - val_loss: 0.7963 - val_accuracy: 0.7337 - val_fscore: 0.7391 - lr: 1.0000e-04\n",
            "Epoch 151/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.4625 - accuracy: 0.8282 - fscore: 0.8241 - val_loss: 0.6564 - val_accuracy: 0.7523 - val_fscore: 0.7344 - lr: 1.0000e-04\n",
            "Epoch 152/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4615 - accuracy: 0.8327 - fscore: 0.8353 - val_loss: 0.4632 - val_accuracy: 0.8545 - val_fscore: 0.8296 - lr: 1.0000e-04\n",
            "Epoch 153/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4464 - accuracy: 0.8398 - fscore: 0.8343 - val_loss: 0.4580 - val_accuracy: 0.8452 - val_fscore: 0.8395 - lr: 1.0000e-04\n",
            "Epoch 154/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4616 - accuracy: 0.8313 - fscore: 0.8319 - val_loss: 0.4933 - val_accuracy: 0.8080 - val_fscore: 0.8104 - lr: 1.0000e-04\n",
            "Epoch 155/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4443 - accuracy: 0.8327 - fscore: 0.8400 - val_loss: 0.4773 - val_accuracy: 0.8328 - val_fscore: 0.8294 - lr: 1.0000e-04\n",
            "Epoch 156/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4376 - accuracy: 0.8420 - fscore: 0.8468 - val_loss: 0.4582 - val_accuracy: 0.8266 - val_fscore: 0.8402 - lr: 1.0000e-04\n",
            "Epoch 157/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4366 - accuracy: 0.8344 - fscore: 0.8380 - val_loss: 0.4835 - val_accuracy: 0.8297 - val_fscore: 0.8051 - lr: 1.0000e-04\n",
            "Epoch 158/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4394 - accuracy: 0.8367 - fscore: 0.8354 - val_loss: 0.4826 - val_accuracy: 0.8173 - val_fscore: 0.8268 - lr: 1.0000e-04\n",
            "Epoch 159/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.4365 - accuracy: 0.8349 - fscore: 0.8403 - val_loss: 0.5055 - val_accuracy: 0.8235 - val_fscore: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 160/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4314 - accuracy: 0.8411 - fscore: 0.8422 - val_loss: 0.4980 - val_accuracy: 0.8111 - val_fscore: 0.8064 - lr: 1.0000e-04\n",
            "Epoch 161/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4281 - accuracy: 0.8415 - fscore: 0.8460 - val_loss: 0.4555 - val_accuracy: 0.8421 - val_fscore: 0.8384 - lr: 1.0000e-04\n",
            "Epoch 162/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4205 - accuracy: 0.8420 - fscore: 0.8507 - val_loss: 0.5533 - val_accuracy: 0.8080 - val_fscore: 0.8100 - lr: 1.0000e-04\n",
            "Epoch 163/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.4184 - accuracy: 0.8437 - fscore: 0.8464 - val_loss: 0.4221 - val_accuracy: 0.8576 - val_fscore: 0.8569 - lr: 1.0000e-04\n",
            "Epoch 164/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4178 - accuracy: 0.8468 - fscore: 0.8518 - val_loss: 0.4218 - val_accuracy: 0.8483 - val_fscore: 0.8499 - lr: 1.0000e-04\n",
            "Epoch 165/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4143 - accuracy: 0.8442 - fscore: 0.8505 - val_loss: 0.4376 - val_accuracy: 0.8514 - val_fscore: 0.8593 - lr: 1.0000e-04\n",
            "Epoch 166/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4173 - accuracy: 0.8486 - fscore: 0.8484 - val_loss: 0.4247 - val_accuracy: 0.8421 - val_fscore: 0.8665 - lr: 1.0000e-04\n",
            "Epoch 167/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4060 - accuracy: 0.8455 - fscore: 0.8567 - val_loss: 0.4152 - val_accuracy: 0.8514 - val_fscore: 0.8591 - lr: 1.0000e-04\n",
            "Epoch 168/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4073 - accuracy: 0.8521 - fscore: 0.8562 - val_loss: 0.4320 - val_accuracy: 0.8452 - val_fscore: 0.8489 - lr: 1.0000e-04\n",
            "Epoch 169/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4042 - accuracy: 0.8535 - fscore: 0.8582 - val_loss: 0.4404 - val_accuracy: 0.8483 - val_fscore: 0.8669 - lr: 1.0000e-04\n",
            "Epoch 170/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.4006 - accuracy: 0.8508 - fscore: 0.8534 - val_loss: 0.5043 - val_accuracy: 0.7771 - val_fscore: 0.7800 - lr: 1.0000e-04\n",
            "Epoch 171/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.4175 - accuracy: 0.8442 - fscore: 0.8471 - val_loss: 0.4199 - val_accuracy: 0.8514 - val_fscore: 0.8539 - lr: 1.0000e-04\n",
            "Epoch 172/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3953 - accuracy: 0.8548 - fscore: 0.8553 - val_loss: 0.4473 - val_accuracy: 0.8266 - val_fscore: 0.8459 - lr: 1.0000e-04\n",
            "Epoch 173/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3951 - accuracy: 0.8539 - fscore: 0.8607 - val_loss: 0.4482 - val_accuracy: 0.8173 - val_fscore: 0.8371 - lr: 1.0000e-04\n",
            "Epoch 174/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3952 - accuracy: 0.8464 - fscore: 0.8535 - val_loss: 0.4207 - val_accuracy: 0.8576 - val_fscore: 0.8532 - lr: 1.0000e-04\n",
            "Epoch 175/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3902 - accuracy: 0.8517 - fscore: 0.8610 - val_loss: 0.4198 - val_accuracy: 0.8576 - val_fscore: 0.8541 - lr: 1.0000e-04\n",
            "Epoch 176/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3897 - accuracy: 0.8557 - fscore: 0.8583 - val_loss: 0.4708 - val_accuracy: 0.8266 - val_fscore: 0.8347 - lr: 1.0000e-04\n",
            "Epoch 177/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3862 - accuracy: 0.8526 - fscore: 0.8587 - val_loss: 0.4107 - val_accuracy: 0.8607 - val_fscore: 0.8619 - lr: 1.0000e-04\n",
            "Epoch 178/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3843 - accuracy: 0.8592 - fscore: 0.8635 - val_loss: 0.4083 - val_accuracy: 0.8514 - val_fscore: 0.8620 - lr: 1.0000e-04\n",
            "Epoch 179/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3813 - accuracy: 0.8570 - fscore: 0.8609 - val_loss: 0.5642 - val_accuracy: 0.7988 - val_fscore: 0.8157 - lr: 1.0000e-04\n",
            "Epoch 180/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3813 - accuracy: 0.8610 - fscore: 0.8605 - val_loss: 0.4079 - val_accuracy: 0.8514 - val_fscore: 0.8566 - lr: 1.0000e-04\n",
            "Epoch 181/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3801 - accuracy: 0.8539 - fscore: 0.8618 - val_loss: 0.6395 - val_accuracy: 0.7926 - val_fscore: 0.7857 - lr: 1.0000e-04\n",
            "Epoch 182/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3765 - accuracy: 0.8570 - fscore: 0.8585 - val_loss: 0.3886 - val_accuracy: 0.8607 - val_fscore: 0.8760 - lr: 1.0000e-04\n",
            "Epoch 183/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3718 - accuracy: 0.8637 - fscore: 0.8679 - val_loss: 0.4293 - val_accuracy: 0.8359 - val_fscore: 0.8560 - lr: 1.0000e-04\n",
            "Epoch 184/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3708 - accuracy: 0.8588 - fscore: 0.8659 - val_loss: 0.4038 - val_accuracy: 0.8669 - val_fscore: 0.8596 - lr: 1.0000e-04\n",
            "Epoch 185/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3704 - accuracy: 0.8628 - fscore: 0.8686 - val_loss: 0.4154 - val_accuracy: 0.8483 - val_fscore: 0.8597 - lr: 1.0000e-04\n",
            "Epoch 186/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3645 - accuracy: 0.8672 - fscore: 0.8674 - val_loss: 0.4326 - val_accuracy: 0.8452 - val_fscore: 0.8434 - lr: 1.0000e-04\n",
            "Epoch 187/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3649 - accuracy: 0.8570 - fscore: 0.8646 - val_loss: 0.4410 - val_accuracy: 0.8452 - val_fscore: 0.8442 - lr: 1.0000e-04\n",
            "Epoch 188/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3636 - accuracy: 0.8610 - fscore: 0.8673 - val_loss: 0.4225 - val_accuracy: 0.8607 - val_fscore: 0.8593 - lr: 1.0000e-04\n",
            "Epoch 189/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3649 - accuracy: 0.8641 - fscore: 0.8722 - val_loss: 0.3976 - val_accuracy: 0.8452 - val_fscore: 0.8540 - lr: 1.0000e-04\n",
            "Epoch 190/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3616 - accuracy: 0.8645 - fscore: 0.8740 - val_loss: 0.3967 - val_accuracy: 0.8700 - val_fscore: 0.8737 - lr: 1.0000e-04\n",
            "Epoch 191/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3585 - accuracy: 0.8650 - fscore: 0.8688 - val_loss: 0.4448 - val_accuracy: 0.8421 - val_fscore: 0.8306 - lr: 1.0000e-04\n",
            "Epoch 192/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3615 - accuracy: 0.8663 - fscore: 0.8672 - val_loss: 0.3985 - val_accuracy: 0.8638 - val_fscore: 0.8631 - lr: 1.0000e-04\n",
            "Epoch 193/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3593 - accuracy: 0.8699 - fscore: 0.8689 - val_loss: 0.3950 - val_accuracy: 0.8421 - val_fscore: 0.8597 - lr: 1.0000e-04\n",
            "Epoch 194/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3586 - accuracy: 0.8641 - fscore: 0.8739 - val_loss: 0.4469 - val_accuracy: 0.8390 - val_fscore: 0.8395 - lr: 1.0000e-04\n",
            "Epoch 195/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3550 - accuracy: 0.8641 - fscore: 0.8704 - val_loss: 0.4007 - val_accuracy: 0.8669 - val_fscore: 0.8761 - lr: 1.0000e-04\n",
            "Epoch 196/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3554 - accuracy: 0.8623 - fscore: 0.8700 - val_loss: 0.4093 - val_accuracy: 0.8421 - val_fscore: 0.8535 - lr: 1.0000e-04\n",
            "Epoch 197/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3470 - accuracy: 0.8681 - fscore: 0.8713 - val_loss: 0.5013 - val_accuracy: 0.7895 - val_fscore: 0.7851 - lr: 1.0000e-04\n",
            "Epoch 198/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3476 - accuracy: 0.8676 - fscore: 0.8724 - val_loss: 0.4678 - val_accuracy: 0.8142 - val_fscore: 0.8232 - lr: 1.0000e-04\n",
            "Epoch 199/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3465 - accuracy: 0.8659 - fscore: 0.8683 - val_loss: 0.3715 - val_accuracy: 0.8731 - val_fscore: 0.8636 - lr: 1.0000e-04\n",
            "Epoch 200/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3481 - accuracy: 0.8716 - fscore: 0.8695 - val_loss: 1.4059 - val_accuracy: 0.6192 - val_fscore: 0.6010 - lr: 1.0000e-04\n",
            "Epoch 201/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3643 - accuracy: 0.8637 - fscore: 0.8680 - val_loss: 0.4418 - val_accuracy: 0.8452 - val_fscore: 0.8436 - lr: 1.0000e-04\n",
            "Epoch 202/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3460 - accuracy: 0.8685 - fscore: 0.8680 - val_loss: 0.3826 - val_accuracy: 0.8700 - val_fscore: 0.8688 - lr: 1.0000e-04\n",
            "Epoch 203/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3450 - accuracy: 0.8721 - fscore: 0.8708 - val_loss: 0.3870 - val_accuracy: 0.8514 - val_fscore: 0.8648 - lr: 1.0000e-04\n",
            "Epoch 204/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3404 - accuracy: 0.8690 - fscore: 0.8734 - val_loss: 0.3754 - val_accuracy: 0.8607 - val_fscore: 0.8690 - lr: 1.0000e-04\n",
            "Epoch 205/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3364 - accuracy: 0.8725 - fscore: 0.8735 - val_loss: 0.4150 - val_accuracy: 0.8421 - val_fscore: 0.8374 - lr: 1.0000e-04\n",
            "Epoch 206/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3441 - accuracy: 0.8690 - fscore: 0.8739 - val_loss: 0.3759 - val_accuracy: 0.8576 - val_fscore: 0.8648 - lr: 1.0000e-04\n",
            "Epoch 207/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3512 - accuracy: 0.8610 - fscore: 0.8701 - val_loss: 0.4133 - val_accuracy: 0.8607 - val_fscore: 0.8532 - lr: 1.0000e-04\n",
            "Epoch 208/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3325 - accuracy: 0.8716 - fscore: 0.8746 - val_loss: 0.3700 - val_accuracy: 0.8824 - val_fscore: 0.8639 - lr: 1.0000e-04\n",
            "Epoch 209/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3386 - accuracy: 0.8659 - fscore: 0.8725 - val_loss: 0.4952 - val_accuracy: 0.8390 - val_fscore: 0.8198 - lr: 1.0000e-04\n",
            "Epoch 210/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3315 - accuracy: 0.8796 - fscore: 0.8792 - val_loss: 0.4510 - val_accuracy: 0.8359 - val_fscore: 0.8535 - lr: 1.0000e-04\n",
            "Epoch 211/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3357 - accuracy: 0.8734 - fscore: 0.8756 - val_loss: 0.3707 - val_accuracy: 0.8638 - val_fscore: 0.8639 - lr: 1.0000e-04\n",
            "Epoch 212/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3343 - accuracy: 0.8765 - fscore: 0.8770 - val_loss: 0.4724 - val_accuracy: 0.8421 - val_fscore: 0.8456 - lr: 1.0000e-04\n",
            "Epoch 213/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3288 - accuracy: 0.8747 - fscore: 0.8740 - val_loss: 0.3824 - val_accuracy: 0.8638 - val_fscore: 0.8569 - lr: 1.0000e-04\n",
            "Epoch 214/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3276 - accuracy: 0.8752 - fscore: 0.8788 - val_loss: 0.3591 - val_accuracy: 0.8793 - val_fscore: 0.8751 - lr: 1.0000e-04\n",
            "Epoch 215/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3259 - accuracy: 0.8778 - fscore: 0.8762 - val_loss: 0.4498 - val_accuracy: 0.8297 - val_fscore: 0.8426 - lr: 1.0000e-04\n",
            "Epoch 216/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3280 - accuracy: 0.8774 - fscore: 0.8788 - val_loss: 0.3789 - val_accuracy: 0.8607 - val_fscore: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 217/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3227 - accuracy: 0.8747 - fscore: 0.8806 - val_loss: 0.3740 - val_accuracy: 0.8731 - val_fscore: 0.8763 - lr: 1.0000e-04\n",
            "Epoch 218/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3236 - accuracy: 0.8765 - fscore: 0.8798 - val_loss: 0.3902 - val_accuracy: 0.8514 - val_fscore: 0.8584 - lr: 1.0000e-04\n",
            "Epoch 219/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3216 - accuracy: 0.8792 - fscore: 0.8801 - val_loss: 0.3739 - val_accuracy: 0.8545 - val_fscore: 0.8601 - lr: 1.0000e-04\n",
            "Epoch 220/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3173 - accuracy: 0.8822 - fscore: 0.8791 - val_loss: 0.6043 - val_accuracy: 0.7647 - val_fscore: 0.7684 - lr: 1.0000e-04\n",
            "Epoch 221/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3239 - accuracy: 0.8814 - fscore: 0.8807 - val_loss: 0.3550 - val_accuracy: 0.8700 - val_fscore: 0.8623 - lr: 1.0000e-04\n",
            "Epoch 222/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3230 - accuracy: 0.8792 - fscore: 0.8763 - val_loss: 0.3619 - val_accuracy: 0.8669 - val_fscore: 0.8756 - lr: 1.0000e-04\n",
            "Epoch 223/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.3242 - accuracy: 0.8752 - fscore: 0.8774 - val_loss: 0.3871 - val_accuracy: 0.8483 - val_fscore: 0.8611 - lr: 1.0000e-04\n",
            "Epoch 224/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3169 - accuracy: 0.8796 - fscore: 0.8806 - val_loss: 0.3619 - val_accuracy: 0.8762 - val_fscore: 0.8664 - lr: 1.0000e-04\n",
            "Epoch 225/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3130 - accuracy: 0.8814 - fscore: 0.8823 - val_loss: 0.3839 - val_accuracy: 0.8483 - val_fscore: 0.8441 - lr: 1.0000e-04\n",
            "Epoch 226/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3163 - accuracy: 0.8787 - fscore: 0.8800 - val_loss: 0.3603 - val_accuracy: 0.8669 - val_fscore: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 227/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3110 - accuracy: 0.8831 - fscore: 0.8821 - val_loss: 0.3730 - val_accuracy: 0.8607 - val_fscore: 0.8722 - lr: 1.0000e-04\n",
            "Epoch 228/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3108 - accuracy: 0.8876 - fscore: 0.8877 - val_loss: 0.6662 - val_accuracy: 0.7926 - val_fscore: 0.7932 - lr: 1.0000e-04\n",
            "Epoch 229/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3170 - accuracy: 0.8862 - fscore: 0.8831 - val_loss: 0.5023 - val_accuracy: 0.8204 - val_fscore: 0.8264 - lr: 1.0000e-04\n",
            "Epoch 230/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.3126 - accuracy: 0.8778 - fscore: 0.8821 - val_loss: 0.3817 - val_accuracy: 0.8545 - val_fscore: 0.8541 - lr: 1.0000e-04\n",
            "Epoch 231/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3123 - accuracy: 0.8769 - fscore: 0.8795 - val_loss: 0.5346 - val_accuracy: 0.7988 - val_fscore: 0.7933 - lr: 1.0000e-04\n",
            "Epoch 232/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3146 - accuracy: 0.8809 - fscore: 0.8801 - val_loss: 0.8843 - val_accuracy: 0.7554 - val_fscore: 0.7507 - lr: 1.0000e-04\n",
            "Epoch 233/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3168 - accuracy: 0.8818 - fscore: 0.8849 - val_loss: 0.4884 - val_accuracy: 0.8080 - val_fscore: 0.8227 - lr: 1.0000e-04\n",
            "Epoch 234/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3064 - accuracy: 0.8836 - fscore: 0.8826 - val_loss: 0.3561 - val_accuracy: 0.8638 - val_fscore: 0.8712 - lr: 1.0000e-04\n",
            "Epoch 235/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3021 - accuracy: 0.8858 - fscore: 0.8844 - val_loss: 0.3659 - val_accuracy: 0.8545 - val_fscore: 0.8554 - lr: 1.0000e-04\n",
            "Epoch 236/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.2996 - accuracy: 0.8889 - fscore: 0.8899 - val_loss: 0.3654 - val_accuracy: 0.8576 - val_fscore: 0.8580 - lr: 1.0000e-04\n",
            "Epoch 237/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2972 - accuracy: 0.8871 - fscore: 0.8871 - val_loss: 0.3448 - val_accuracy: 0.8762 - val_fscore: 0.8692 - lr: 1.0000e-04\n",
            "Epoch 238/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.3023 - accuracy: 0.8849 - fscore: 0.8862 - val_loss: 0.3581 - val_accuracy: 0.8700 - val_fscore: 0.8743 - lr: 1.0000e-04\n",
            "Epoch 239/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.2986 - accuracy: 0.8845 - fscore: 0.8843 - val_loss: 0.3462 - val_accuracy: 0.8793 - val_fscore: 0.8737 - lr: 1.0000e-04\n",
            "Epoch 240/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2982 - accuracy: 0.8845 - fscore: 0.8901 - val_loss: 0.3842 - val_accuracy: 0.8483 - val_fscore: 0.8471 - lr: 1.0000e-04\n",
            "Epoch 241/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2970 - accuracy: 0.8907 - fscore: 0.8889 - val_loss: 0.3644 - val_accuracy: 0.8731 - val_fscore: 0.8645 - lr: 1.0000e-04\n",
            "Epoch 242/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2930 - accuracy: 0.8907 - fscore: 0.8860 - val_loss: 0.3433 - val_accuracy: 0.8576 - val_fscore: 0.8626 - lr: 1.0000e-04\n",
            "Epoch 243/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2937 - accuracy: 0.8911 - fscore: 0.8893 - val_loss: 0.5416 - val_accuracy: 0.8111 - val_fscore: 0.8123 - lr: 1.0000e-04\n",
            "Epoch 244/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2981 - accuracy: 0.8911 - fscore: 0.8849 - val_loss: 0.3616 - val_accuracy: 0.8514 - val_fscore: 0.8589 - lr: 1.0000e-04\n",
            "Epoch 245/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2926 - accuracy: 0.8907 - fscore: 0.8914 - val_loss: 0.3438 - val_accuracy: 0.8731 - val_fscore: 0.8644 - lr: 1.0000e-04\n",
            "Epoch 246/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2906 - accuracy: 0.8915 - fscore: 0.8873 - val_loss: 0.4943 - val_accuracy: 0.8235 - val_fscore: 0.8314 - lr: 1.0000e-04\n",
            "Epoch 247/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2946 - accuracy: 0.8902 - fscore: 0.8898 - val_loss: 0.3812 - val_accuracy: 0.8576 - val_fscore: 0.8549 - lr: 1.0000e-04\n",
            "Epoch 248/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2957 - accuracy: 0.8871 - fscore: 0.8867 - val_loss: 0.3466 - val_accuracy: 0.8607 - val_fscore: 0.8717 - lr: 1.0000e-04\n",
            "Epoch 249/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2785 - accuracy: 0.9004 - fscore: 0.8958 - val_loss: 0.3767 - val_accuracy: 0.8452 - val_fscore: 0.8598 - lr: 1.0000e-04\n",
            "Epoch 250/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2883 - accuracy: 0.8920 - fscore: 0.8932 - val_loss: 0.4748 - val_accuracy: 0.8266 - val_fscore: 0.8408 - lr: 1.0000e-04\n",
            "Epoch 251/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2868 - accuracy: 0.8907 - fscore: 0.8898 - val_loss: 0.3476 - val_accuracy: 0.8638 - val_fscore: 0.8691 - lr: 1.0000e-04\n",
            "Epoch 252/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2832 - accuracy: 0.8942 - fscore: 0.8909 - val_loss: 0.3480 - val_accuracy: 0.8669 - val_fscore: 0.8729 - lr: 1.0000e-04\n",
            "Epoch 253/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2867 - accuracy: 0.8836 - fscore: 0.8856 - val_loss: 0.3561 - val_accuracy: 0.8576 - val_fscore: 0.8702 - lr: 1.0000e-04\n",
            "Epoch 254/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2748 - accuracy: 0.8938 - fscore: 0.8984 - val_loss: 0.3730 - val_accuracy: 0.8545 - val_fscore: 0.8596 - lr: 1.0000e-04\n",
            "Epoch 255/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2773 - accuracy: 0.8898 - fscore: 0.8934 - val_loss: 0.3894 - val_accuracy: 0.8452 - val_fscore: 0.8615 - lr: 1.0000e-04\n",
            "Epoch 256/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2795 - accuracy: 0.8951 - fscore: 0.8911 - val_loss: 0.5789 - val_accuracy: 0.7926 - val_fscore: 0.7905 - lr: 1.0000e-04\n",
            "Epoch 257/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2864 - accuracy: 0.8938 - fscore: 0.8927 - val_loss: 0.3367 - val_accuracy: 0.8669 - val_fscore: 0.8618 - lr: 1.0000e-04\n",
            "Epoch 258/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2737 - accuracy: 0.8915 - fscore: 0.8955 - val_loss: 0.3547 - val_accuracy: 0.8576 - val_fscore: 0.8586 - lr: 1.0000e-04\n",
            "Epoch 259/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2738 - accuracy: 0.9004 - fscore: 0.8950 - val_loss: 0.3372 - val_accuracy: 0.8700 - val_fscore: 0.8790 - lr: 1.0000e-04\n",
            "Epoch 260/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2710 - accuracy: 0.8938 - fscore: 0.8958 - val_loss: 0.3967 - val_accuracy: 0.8545 - val_fscore: 0.8488 - lr: 1.0000e-04\n",
            "Epoch 261/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2857 - accuracy: 0.8880 - fscore: 0.8885 - val_loss: 0.3454 - val_accuracy: 0.8731 - val_fscore: 0.8732 - lr: 1.0000e-04\n",
            "Epoch 262/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2717 - accuracy: 0.8964 - fscore: 0.8981 - val_loss: 0.3774 - val_accuracy: 0.8421 - val_fscore: 0.8558 - lr: 1.0000e-04\n",
            "Epoch 263/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2775 - accuracy: 0.8946 - fscore: 0.8917 - val_loss: 0.3684 - val_accuracy: 0.8545 - val_fscore: 0.8657 - lr: 1.0000e-04\n",
            "Epoch 264/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2726 - accuracy: 0.8973 - fscore: 0.8908 - val_loss: 0.3837 - val_accuracy: 0.8607 - val_fscore: 0.8660 - lr: 1.0000e-04\n",
            "Epoch 265/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2745 - accuracy: 0.8933 - fscore: 0.8936 - val_loss: 0.4639 - val_accuracy: 0.8204 - val_fscore: 0.8240 - lr: 1.0000e-04\n",
            "Epoch 266/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2739 - accuracy: 0.8929 - fscore: 0.8932 - val_loss: 0.3214 - val_accuracy: 0.8731 - val_fscore: 0.8565 - lr: 1.0000e-04\n",
            "Epoch 267/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2758 - accuracy: 0.8929 - fscore: 0.8951 - val_loss: 0.3657 - val_accuracy: 0.8607 - val_fscore: 0.8647 - lr: 1.0000e-04\n",
            "Epoch 268/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2647 - accuracy: 0.8942 - fscore: 0.8965 - val_loss: 0.3930 - val_accuracy: 0.8421 - val_fscore: 0.8470 - lr: 1.0000e-04\n",
            "Epoch 269/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2681 - accuracy: 0.8982 - fscore: 0.8978 - val_loss: 0.3242 - val_accuracy: 0.8700 - val_fscore: 0.8721 - lr: 1.0000e-04\n",
            "Epoch 270/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2675 - accuracy: 0.8995 - fscore: 0.8985 - val_loss: 0.3445 - val_accuracy: 0.8700 - val_fscore: 0.8692 - lr: 1.0000e-04\n",
            "Epoch 271/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2603 - accuracy: 0.9013 - fscore: 0.8969 - val_loss: 0.3306 - val_accuracy: 0.8731 - val_fscore: 0.8777 - lr: 1.0000e-04\n",
            "Epoch 272/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2655 - accuracy: 0.8969 - fscore: 0.8948 - val_loss: 0.3363 - val_accuracy: 0.8669 - val_fscore: 0.8680 - lr: 1.0000e-04\n",
            "Epoch 273/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2651 - accuracy: 0.8982 - fscore: 0.8963 - val_loss: 0.4880 - val_accuracy: 0.8266 - val_fscore: 0.8222 - lr: 1.0000e-04\n",
            "Epoch 274/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2619 - accuracy: 0.8973 - fscore: 0.8978 - val_loss: 0.5253 - val_accuracy: 0.8390 - val_fscore: 0.8378 - lr: 1.0000e-04\n",
            "Epoch 275/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2771 - accuracy: 0.8933 - fscore: 0.8930 - val_loss: 0.3998 - val_accuracy: 0.8545 - val_fscore: 0.8535 - lr: 1.0000e-04\n",
            "Epoch 276/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2621 - accuracy: 0.9031 - fscore: 0.8999 - val_loss: 0.3554 - val_accuracy: 0.8731 - val_fscore: 0.8668 - lr: 1.0000e-04\n",
            "Epoch 277/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2616 - accuracy: 0.9004 - fscore: 0.8993 - val_loss: 0.3594 - val_accuracy: 0.8638 - val_fscore: 0.8691 - lr: 1.0000e-04\n",
            "Epoch 278/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2660 - accuracy: 0.9017 - fscore: 0.9007 - val_loss: 0.3863 - val_accuracy: 0.8483 - val_fscore: 0.8512 - lr: 1.0000e-04\n",
            "Epoch 279/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2599 - accuracy: 0.8973 - fscore: 0.8981 - val_loss: 0.4724 - val_accuracy: 0.8328 - val_fscore: 0.8254 - lr: 1.0000e-04\n",
            "Epoch 280/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2568 - accuracy: 0.8991 - fscore: 0.9009 - val_loss: 0.3596 - val_accuracy: 0.8669 - val_fscore: 0.8676 - lr: 1.0000e-04\n",
            "Epoch 281/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2543 - accuracy: 0.9008 - fscore: 0.8971 - val_loss: 0.3284 - val_accuracy: 0.8731 - val_fscore: 0.8725 - lr: 1.0000e-04\n",
            "Epoch 282/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2589 - accuracy: 0.8946 - fscore: 0.8963 - val_loss: 0.3632 - val_accuracy: 0.8638 - val_fscore: 0.8611 - lr: 1.0000e-04\n",
            "Epoch 283/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2565 - accuracy: 0.9044 - fscore: 0.8975 - val_loss: 0.4463 - val_accuracy: 0.8111 - val_fscore: 0.8109 - lr: 1.0000e-04\n",
            "Epoch 284/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2601 - accuracy: 0.8991 - fscore: 0.8971 - val_loss: 0.3519 - val_accuracy: 0.8700 - val_fscore: 0.8748 - lr: 1.0000e-04\n",
            "Epoch 285/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2526 - accuracy: 0.9008 - fscore: 0.9014 - val_loss: 0.3763 - val_accuracy: 0.8576 - val_fscore: 0.8634 - lr: 1.0000e-04\n",
            "Epoch 286/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2483 - accuracy: 0.9017 - fscore: 0.9027 - val_loss: 0.3288 - val_accuracy: 0.8885 - val_fscore: 0.8885 - lr: 1.0000e-04\n",
            "Epoch 287/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2432 - accuracy: 0.9031 - fscore: 0.9056 - val_loss: 0.3380 - val_accuracy: 0.8576 - val_fscore: 0.8711 - lr: 9.0000e-05\n",
            "Epoch 288/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2462 - accuracy: 0.9039 - fscore: 0.9003 - val_loss: 0.3306 - val_accuracy: 0.8669 - val_fscore: 0.8716 - lr: 9.0000e-05\n",
            "Epoch 289/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2444 - accuracy: 0.9079 - fscore: 0.9036 - val_loss: 0.3515 - val_accuracy: 0.8669 - val_fscore: 0.8594 - lr: 9.0000e-05\n",
            "Epoch 290/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2472 - accuracy: 0.9062 - fscore: 0.9040 - val_loss: 0.5732 - val_accuracy: 0.8080 - val_fscore: 0.8099 - lr: 9.0000e-05\n",
            "Epoch 291/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2486 - accuracy: 0.9057 - fscore: 0.9040 - val_loss: 0.3251 - val_accuracy: 0.8824 - val_fscore: 0.8776 - lr: 9.0000e-05\n",
            "Epoch 292/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2411 - accuracy: 0.9062 - fscore: 0.9053 - val_loss: 0.3333 - val_accuracy: 0.8638 - val_fscore: 0.8609 - lr: 9.0000e-05\n",
            "Epoch 293/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2435 - accuracy: 0.9062 - fscore: 0.9055 - val_loss: 0.3706 - val_accuracy: 0.8638 - val_fscore: 0.8722 - lr: 9.0000e-05\n",
            "Epoch 294/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2474 - accuracy: 0.9053 - fscore: 0.8996 - val_loss: 0.3461 - val_accuracy: 0.8669 - val_fscore: 0.8746 - lr: 9.0000e-05\n",
            "Epoch 295/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2437 - accuracy: 0.9044 - fscore: 0.9043 - val_loss: 0.4865 - val_accuracy: 0.8297 - val_fscore: 0.8139 - lr: 9.0000e-05\n",
            "Epoch 296/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2445 - accuracy: 0.9048 - fscore: 0.9043 - val_loss: 0.3861 - val_accuracy: 0.8452 - val_fscore: 0.8458 - lr: 9.0000e-05\n",
            "Epoch 297/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2414 - accuracy: 0.9066 - fscore: 0.9063 - val_loss: 0.3590 - val_accuracy: 0.8483 - val_fscore: 0.8637 - lr: 9.0000e-05\n",
            "Epoch 298/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2416 - accuracy: 0.9039 - fscore: 0.9047 - val_loss: 0.3741 - val_accuracy: 0.8638 - val_fscore: 0.8497 - lr: 9.0000e-05\n",
            "Epoch 299/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2366 - accuracy: 0.9039 - fscore: 0.9029 - val_loss: 0.3232 - val_accuracy: 0.8700 - val_fscore: 0.8674 - lr: 9.0000e-05\n",
            "Epoch 300/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2404 - accuracy: 0.9070 - fscore: 0.9067 - val_loss: 0.3502 - val_accuracy: 0.8576 - val_fscore: 0.8623 - lr: 9.0000e-05\n",
            "Epoch 301/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2368 - accuracy: 0.9128 - fscore: 0.9064 - val_loss: 0.3071 - val_accuracy: 0.8885 - val_fscore: 0.8840 - lr: 9.0000e-05\n",
            "Epoch 302/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2363 - accuracy: 0.9084 - fscore: 0.9054 - val_loss: 0.3176 - val_accuracy: 0.8700 - val_fscore: 0.8723 - lr: 9.0000e-05\n",
            "Epoch 303/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2361 - accuracy: 0.9044 - fscore: 0.9070 - val_loss: 0.3360 - val_accuracy: 0.8731 - val_fscore: 0.8760 - lr: 9.0000e-05\n",
            "Epoch 304/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2349 - accuracy: 0.9093 - fscore: 0.9030 - val_loss: 0.3359 - val_accuracy: 0.8762 - val_fscore: 0.8757 - lr: 9.0000e-05\n",
            "Epoch 305/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2427 - accuracy: 0.9079 - fscore: 0.9053 - val_loss: 0.5125 - val_accuracy: 0.8050 - val_fscore: 0.8024 - lr: 9.0000e-05\n",
            "Epoch 306/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2366 - accuracy: 0.9088 - fscore: 0.9069 - val_loss: 0.3378 - val_accuracy: 0.8731 - val_fscore: 0.8739 - lr: 9.0000e-05\n",
            "Epoch 307/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2363 - accuracy: 0.9031 - fscore: 0.9076 - val_loss: 0.3057 - val_accuracy: 0.8793 - val_fscore: 0.8785 - lr: 9.0000e-05\n",
            "Epoch 308/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2354 - accuracy: 0.9110 - fscore: 0.9067 - val_loss: 0.3133 - val_accuracy: 0.8793 - val_fscore: 0.8852 - lr: 9.0000e-05\n",
            "Epoch 309/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2333 - accuracy: 0.9088 - fscore: 0.9067 - val_loss: 0.3333 - val_accuracy: 0.8762 - val_fscore: 0.8712 - lr: 9.0000e-05\n",
            "Epoch 310/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2336 - accuracy: 0.9119 - fscore: 0.9089 - val_loss: 0.3537 - val_accuracy: 0.8576 - val_fscore: 0.8707 - lr: 9.0000e-05\n",
            "Epoch 311/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2301 - accuracy: 0.9115 - fscore: 0.9104 - val_loss: 0.3790 - val_accuracy: 0.8514 - val_fscore: 0.8592 - lr: 9.0000e-05\n",
            "Epoch 312/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2459 - accuracy: 0.9057 - fscore: 0.9040 - val_loss: 0.3936 - val_accuracy: 0.8545 - val_fscore: 0.8658 - lr: 9.0000e-05\n",
            "Epoch 313/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2255 - accuracy: 0.9128 - fscore: 0.9104 - val_loss: 0.3069 - val_accuracy: 0.8824 - val_fscore: 0.8759 - lr: 9.0000e-05\n",
            "Epoch 314/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2219 - accuracy: 0.9150 - fscore: 0.9130 - val_loss: 0.3512 - val_accuracy: 0.8793 - val_fscore: 0.8712 - lr: 9.0000e-05\n",
            "Epoch 315/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2287 - accuracy: 0.9146 - fscore: 0.9126 - val_loss: 0.3447 - val_accuracy: 0.8700 - val_fscore: 0.8643 - lr: 9.0000e-05\n",
            "Epoch 316/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2277 - accuracy: 0.9097 - fscore: 0.9100 - val_loss: 0.8455 - val_accuracy: 0.7926 - val_fscore: 0.7817 - lr: 9.0000e-05\n",
            "Epoch 317/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2346 - accuracy: 0.9093 - fscore: 0.9068 - val_loss: 0.3051 - val_accuracy: 0.8793 - val_fscore: 0.8855 - lr: 9.0000e-05\n",
            "Epoch 318/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2268 - accuracy: 0.9137 - fscore: 0.9139 - val_loss: 0.3489 - val_accuracy: 0.8731 - val_fscore: 0.8752 - lr: 9.0000e-05\n",
            "Epoch 319/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2221 - accuracy: 0.9079 - fscore: 0.9074 - val_loss: 0.3270 - val_accuracy: 0.8762 - val_fscore: 0.8784 - lr: 9.0000e-05\n",
            "Epoch 320/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2279 - accuracy: 0.9128 - fscore: 0.9116 - val_loss: 0.3133 - val_accuracy: 0.8700 - val_fscore: 0.8706 - lr: 9.0000e-05\n",
            "Epoch 321/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2254 - accuracy: 0.9150 - fscore: 0.9119 - val_loss: 0.3240 - val_accuracy: 0.8638 - val_fscore: 0.8679 - lr: 9.0000e-05\n",
            "Epoch 322/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2273 - accuracy: 0.9053 - fscore: 0.9024 - val_loss: 0.4393 - val_accuracy: 0.8514 - val_fscore: 0.8419 - lr: 9.0000e-05\n",
            "Epoch 323/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2282 - accuracy: 0.9106 - fscore: 0.9069 - val_loss: 0.3546 - val_accuracy: 0.8576 - val_fscore: 0.8609 - lr: 9.0000e-05\n",
            "Epoch 324/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2223 - accuracy: 0.9185 - fscore: 0.9144 - val_loss: 0.8506 - val_accuracy: 0.7740 - val_fscore: 0.7634 - lr: 9.0000e-05\n",
            "Epoch 325/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2250 - accuracy: 0.9163 - fscore: 0.9129 - val_loss: 0.3175 - val_accuracy: 0.8793 - val_fscore: 0.8805 - lr: 9.0000e-05\n",
            "Epoch 326/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2322 - accuracy: 0.9079 - fscore: 0.9073 - val_loss: 0.3507 - val_accuracy: 0.8669 - val_fscore: 0.8693 - lr: 9.0000e-05\n",
            "Epoch 327/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2173 - accuracy: 0.9093 - fscore: 0.9096 - val_loss: 0.3034 - val_accuracy: 0.8916 - val_fscore: 0.8809 - lr: 9.0000e-05\n",
            "Epoch 328/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2235 - accuracy: 0.9168 - fscore: 0.9148 - val_loss: 0.2992 - val_accuracy: 0.8885 - val_fscore: 0.8902 - lr: 9.0000e-05\n",
            "Epoch 329/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2172 - accuracy: 0.9185 - fscore: 0.9110 - val_loss: 0.3580 - val_accuracy: 0.8607 - val_fscore: 0.8679 - lr: 9.0000e-05\n",
            "Epoch 330/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2204 - accuracy: 0.9172 - fscore: 0.9129 - val_loss: 0.3030 - val_accuracy: 0.8731 - val_fscore: 0.8706 - lr: 9.0000e-05\n",
            "Epoch 331/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2205 - accuracy: 0.9137 - fscore: 0.9125 - val_loss: 0.3405 - val_accuracy: 0.8545 - val_fscore: 0.8668 - lr: 9.0000e-05\n",
            "Epoch 332/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2179 - accuracy: 0.9057 - fscore: 0.9109 - val_loss: 0.2792 - val_accuracy: 0.8854 - val_fscore: 0.8849 - lr: 9.0000e-05\n",
            "Epoch 333/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2207 - accuracy: 0.9177 - fscore: 0.9116 - val_loss: 0.3255 - val_accuracy: 0.8700 - val_fscore: 0.8760 - lr: 9.0000e-05\n",
            "Epoch 334/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2206 - accuracy: 0.9137 - fscore: 0.9095 - val_loss: 0.3012 - val_accuracy: 0.8854 - val_fscore: 0.8756 - lr: 9.0000e-05\n",
            "Epoch 335/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2147 - accuracy: 0.9163 - fscore: 0.9140 - val_loss: 0.3151 - val_accuracy: 0.8824 - val_fscore: 0.8795 - lr: 9.0000e-05\n",
            "Epoch 336/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2148 - accuracy: 0.9172 - fscore: 0.9118 - val_loss: 0.3895 - val_accuracy: 0.8638 - val_fscore: 0.8665 - lr: 9.0000e-05\n",
            "Epoch 337/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2317 - accuracy: 0.9163 - fscore: 0.9132 - val_loss: 0.3253 - val_accuracy: 0.8762 - val_fscore: 0.8851 - lr: 9.0000e-05\n",
            "Epoch 338/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2110 - accuracy: 0.9181 - fscore: 0.9175 - val_loss: 0.3202 - val_accuracy: 0.8700 - val_fscore: 0.8738 - lr: 9.0000e-05\n",
            "Epoch 339/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2194 - accuracy: 0.9119 - fscore: 0.9085 - val_loss: 0.4279 - val_accuracy: 0.8328 - val_fscore: 0.8437 - lr: 9.0000e-05\n",
            "Epoch 340/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2201 - accuracy: 0.9137 - fscore: 0.9117 - val_loss: 0.3447 - val_accuracy: 0.8700 - val_fscore: 0.8563 - lr: 9.0000e-05\n",
            "Epoch 341/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2101 - accuracy: 0.9181 - fscore: 0.9150 - val_loss: 0.3376 - val_accuracy: 0.8793 - val_fscore: 0.8710 - lr: 9.0000e-05\n",
            "Epoch 342/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2120 - accuracy: 0.9163 - fscore: 0.9149 - val_loss: 0.3050 - val_accuracy: 0.8700 - val_fscore: 0.8749 - lr: 9.0000e-05\n",
            "Epoch 343/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2137 - accuracy: 0.9159 - fscore: 0.9154 - val_loss: 0.2990 - val_accuracy: 0.8947 - val_fscore: 0.8857 - lr: 9.0000e-05\n",
            "Epoch 344/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2138 - accuracy: 0.9146 - fscore: 0.9120 - val_loss: 0.3402 - val_accuracy: 0.8731 - val_fscore: 0.8747 - lr: 9.0000e-05\n",
            "Epoch 345/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.2124 - accuracy: 0.9208 - fscore: 0.9187 - val_loss: 0.3539 - val_accuracy: 0.8607 - val_fscore: 0.8661 - lr: 9.0000e-05\n",
            "Epoch 346/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2223 - accuracy: 0.9101 - fscore: 0.9122 - val_loss: 0.3170 - val_accuracy: 0.8824 - val_fscore: 0.8751 - lr: 9.0000e-05\n",
            "Epoch 347/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2064 - accuracy: 0.9146 - fscore: 0.9194 - val_loss: 0.3926 - val_accuracy: 0.8483 - val_fscore: 0.8557 - lr: 9.0000e-05\n",
            "Epoch 348/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2095 - accuracy: 0.9185 - fscore: 0.9159 - val_loss: 0.3646 - val_accuracy: 0.8607 - val_fscore: 0.8644 - lr: 9.0000e-05\n",
            "Epoch 349/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2129 - accuracy: 0.9088 - fscore: 0.9077 - val_loss: 0.3208 - val_accuracy: 0.8669 - val_fscore: 0.8701 - lr: 9.0000e-05\n",
            "Epoch 350/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2098 - accuracy: 0.9190 - fscore: 0.9189 - val_loss: 0.3280 - val_accuracy: 0.8762 - val_fscore: 0.8662 - lr: 9.0000e-05\n",
            "Epoch 351/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2089 - accuracy: 0.9190 - fscore: 0.9120 - val_loss: 0.3005 - val_accuracy: 0.8762 - val_fscore: 0.8789 - lr: 9.0000e-05\n",
            "Epoch 352/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2206 - accuracy: 0.9203 - fscore: 0.9150 - val_loss: 0.2902 - val_accuracy: 0.9009 - val_fscore: 0.8924 - lr: 9.0000e-05\n",
            "Epoch 353/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2029 - accuracy: 0.9256 - fscore: 0.9207 - val_loss: 0.3112 - val_accuracy: 0.8793 - val_fscore: 0.8888 - lr: 8.1000e-05\n",
            "Epoch 354/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2047 - accuracy: 0.9221 - fscore: 0.9184 - val_loss: 0.3159 - val_accuracy: 0.8669 - val_fscore: 0.8719 - lr: 8.1000e-05\n",
            "Epoch 355/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2031 - accuracy: 0.9208 - fscore: 0.9184 - val_loss: 0.2919 - val_accuracy: 0.8854 - val_fscore: 0.8888 - lr: 8.1000e-05\n",
            "Epoch 356/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1995 - accuracy: 0.9243 - fscore: 0.9161 - val_loss: 0.3558 - val_accuracy: 0.8700 - val_fscore: 0.8708 - lr: 8.1000e-05\n",
            "Epoch 357/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2011 - accuracy: 0.9239 - fscore: 0.9175 - val_loss: 0.3112 - val_accuracy: 0.8731 - val_fscore: 0.8775 - lr: 8.1000e-05\n",
            "Epoch 358/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2071 - accuracy: 0.9208 - fscore: 0.9152 - val_loss: 0.3595 - val_accuracy: 0.8762 - val_fscore: 0.8795 - lr: 8.1000e-05\n",
            "Epoch 359/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2042 - accuracy: 0.9172 - fscore: 0.9158 - val_loss: 0.2993 - val_accuracy: 0.8824 - val_fscore: 0.8846 - lr: 8.1000e-05\n",
            "Epoch 360/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2010 - accuracy: 0.9256 - fscore: 0.9193 - val_loss: 0.3002 - val_accuracy: 0.8916 - val_fscore: 0.8801 - lr: 8.1000e-05\n",
            "Epoch 361/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1999 - accuracy: 0.9225 - fscore: 0.9192 - val_loss: 0.3358 - val_accuracy: 0.8669 - val_fscore: 0.8714 - lr: 8.1000e-05\n",
            "Epoch 362/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2043 - accuracy: 0.9208 - fscore: 0.9157 - val_loss: 0.4600 - val_accuracy: 0.8235 - val_fscore: 0.8323 - lr: 8.1000e-05\n",
            "Epoch 363/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2020 - accuracy: 0.9208 - fscore: 0.9182 - val_loss: 0.3062 - val_accuracy: 0.8824 - val_fscore: 0.8787 - lr: 8.1000e-05\n",
            "Epoch 364/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1981 - accuracy: 0.9225 - fscore: 0.9210 - val_loss: 0.2821 - val_accuracy: 0.8947 - val_fscore: 0.8869 - lr: 8.1000e-05\n",
            "Epoch 365/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1962 - accuracy: 0.9239 - fscore: 0.9230 - val_loss: 0.3565 - val_accuracy: 0.8731 - val_fscore: 0.8604 - lr: 8.1000e-05\n",
            "Epoch 366/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1920 - accuracy: 0.9225 - fscore: 0.9229 - val_loss: 0.3585 - val_accuracy: 0.8638 - val_fscore: 0.8590 - lr: 8.1000e-05\n",
            "Epoch 367/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1946 - accuracy: 0.9243 - fscore: 0.9215 - val_loss: 0.3114 - val_accuracy: 0.8916 - val_fscore: 0.8862 - lr: 8.1000e-05\n",
            "Epoch 368/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1962 - accuracy: 0.9225 - fscore: 0.9197 - val_loss: 0.3181 - val_accuracy: 0.8854 - val_fscore: 0.8753 - lr: 8.1000e-05\n",
            "Epoch 369/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2034 - accuracy: 0.9154 - fscore: 0.9130 - val_loss: 0.6347 - val_accuracy: 0.7957 - val_fscore: 0.8030 - lr: 8.1000e-05\n",
            "Epoch 370/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.2143 - accuracy: 0.9150 - fscore: 0.9134 - val_loss: 0.3353 - val_accuracy: 0.8700 - val_fscore: 0.8591 - lr: 8.1000e-05\n",
            "Epoch 371/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1980 - accuracy: 0.9190 - fscore: 0.9205 - val_loss: 0.3725 - val_accuracy: 0.8793 - val_fscore: 0.8700 - lr: 8.1000e-05\n",
            "Epoch 372/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.2022 - accuracy: 0.9208 - fscore: 0.9190 - val_loss: 0.3310 - val_accuracy: 0.8793 - val_fscore: 0.8777 - lr: 8.1000e-05\n",
            "Epoch 373/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1933 - accuracy: 0.9278 - fscore: 0.9232 - val_loss: 0.3266 - val_accuracy: 0.8824 - val_fscore: 0.8806 - lr: 7.2900e-05\n",
            "Epoch 374/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1928 - accuracy: 0.9278 - fscore: 0.9226 - val_loss: 0.3208 - val_accuracy: 0.8638 - val_fscore: 0.8617 - lr: 7.2900e-05\n",
            "Epoch 375/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1896 - accuracy: 0.9278 - fscore: 0.9264 - val_loss: 0.2863 - val_accuracy: 0.8854 - val_fscore: 0.8800 - lr: 7.2900e-05\n",
            "Epoch 376/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1869 - accuracy: 0.9318 - fscore: 0.9242 - val_loss: 0.3263 - val_accuracy: 0.8793 - val_fscore: 0.8730 - lr: 7.2900e-05\n",
            "Epoch 377/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1889 - accuracy: 0.9252 - fscore: 0.9243 - val_loss: 0.2890 - val_accuracy: 0.9071 - val_fscore: 0.8863 - lr: 7.2900e-05\n",
            "Epoch 378/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1880 - accuracy: 0.9243 - fscore: 0.9178 - val_loss: 0.3562 - val_accuracy: 0.8700 - val_fscore: 0.8675 - lr: 7.2900e-05\n",
            "Epoch 379/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1972 - accuracy: 0.9208 - fscore: 0.9176 - val_loss: 0.3248 - val_accuracy: 0.8731 - val_fscore: 0.8696 - lr: 7.2900e-05\n",
            "Epoch 380/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1892 - accuracy: 0.9243 - fscore: 0.9235 - val_loss: 0.4748 - val_accuracy: 0.8235 - val_fscore: 0.8128 - lr: 7.2900e-05\n",
            "Epoch 381/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1981 - accuracy: 0.9203 - fscore: 0.9186 - val_loss: 0.5068 - val_accuracy: 0.8173 - val_fscore: 0.8161 - lr: 7.2900e-05\n",
            "Epoch 382/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1998 - accuracy: 0.9221 - fscore: 0.9186 - val_loss: 0.3179 - val_accuracy: 0.8762 - val_fscore: 0.8760 - lr: 7.2900e-05\n",
            "Epoch 383/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1921 - accuracy: 0.9274 - fscore: 0.9242 - val_loss: 0.2751 - val_accuracy: 0.8824 - val_fscore: 0.8837 - lr: 7.2900e-05\n",
            "Epoch 384/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1853 - accuracy: 0.9301 - fscore: 0.9266 - val_loss: 0.3064 - val_accuracy: 0.8854 - val_fscore: 0.8896 - lr: 7.2900e-05\n",
            "Epoch 385/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1840 - accuracy: 0.9296 - fscore: 0.9271 - val_loss: 0.3503 - val_accuracy: 0.8824 - val_fscore: 0.8763 - lr: 7.2900e-05\n",
            "Epoch 386/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1886 - accuracy: 0.9247 - fscore: 0.9251 - val_loss: 0.2865 - val_accuracy: 0.9009 - val_fscore: 0.8945 - lr: 7.2900e-05\n",
            "Epoch 387/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1875 - accuracy: 0.9261 - fscore: 0.9262 - val_loss: 0.3036 - val_accuracy: 0.8762 - val_fscore: 0.8845 - lr: 7.2900e-05\n",
            "Epoch 388/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1830 - accuracy: 0.9309 - fscore: 0.9270 - val_loss: 0.2899 - val_accuracy: 0.8854 - val_fscore: 0.8805 - lr: 7.2900e-05\n",
            "Epoch 389/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1801 - accuracy: 0.9278 - fscore: 0.9244 - val_loss: 0.7552 - val_accuracy: 0.7492 - val_fscore: 0.7503 - lr: 7.2900e-05\n",
            "Epoch 390/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1888 - accuracy: 0.9190 - fscore: 0.9196 - val_loss: 0.3066 - val_accuracy: 0.8824 - val_fscore: 0.8757 - lr: 7.2900e-05\n",
            "Epoch 391/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1794 - accuracy: 0.9349 - fscore: 0.9286 - val_loss: 0.3135 - val_accuracy: 0.8793 - val_fscore: 0.8851 - lr: 7.2900e-05\n",
            "Epoch 392/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1806 - accuracy: 0.9318 - fscore: 0.9276 - val_loss: 0.2886 - val_accuracy: 0.8762 - val_fscore: 0.8804 - lr: 7.2900e-05\n",
            "Epoch 393/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1841 - accuracy: 0.9270 - fscore: 0.9267 - val_loss: 0.4328 - val_accuracy: 0.8545 - val_fscore: 0.8422 - lr: 7.2900e-05\n",
            "Epoch 394/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1825 - accuracy: 0.9278 - fscore: 0.9280 - val_loss: 0.2984 - val_accuracy: 0.8885 - val_fscore: 0.8834 - lr: 7.2900e-05\n",
            "Epoch 395/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1781 - accuracy: 0.9314 - fscore: 0.9298 - val_loss: 0.2856 - val_accuracy: 0.8854 - val_fscore: 0.8864 - lr: 7.2900e-05\n",
            "Epoch 396/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1835 - accuracy: 0.9278 - fscore: 0.9220 - val_loss: 0.2711 - val_accuracy: 0.8885 - val_fscore: 0.8859 - lr: 7.2900e-05\n",
            "Epoch 397/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1814 - accuracy: 0.9274 - fscore: 0.9262 - val_loss: 0.3489 - val_accuracy: 0.8669 - val_fscore: 0.8672 - lr: 7.2900e-05\n",
            "Epoch 398/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1932 - accuracy: 0.9225 - fscore: 0.9198 - val_loss: 0.2973 - val_accuracy: 0.8885 - val_fscore: 0.8927 - lr: 7.2900e-05\n",
            "Epoch 399/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1812 - accuracy: 0.9336 - fscore: 0.9311 - val_loss: 0.5473 - val_accuracy: 0.8452 - val_fscore: 0.8224 - lr: 7.2900e-05\n",
            "Epoch 400/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1844 - accuracy: 0.9247 - fscore: 0.9235 - val_loss: 0.2757 - val_accuracy: 0.8824 - val_fscore: 0.8777 - lr: 7.2900e-05\n",
            "Epoch 401/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1823 - accuracy: 0.9309 - fscore: 0.9248 - val_loss: 0.3852 - val_accuracy: 0.8638 - val_fscore: 0.8579 - lr: 7.2900e-05\n",
            "Epoch 402/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1827 - accuracy: 0.9243 - fscore: 0.9238 - val_loss: 0.2888 - val_accuracy: 0.8824 - val_fscore: 0.8791 - lr: 7.2900e-05\n",
            "Epoch 403/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1787 - accuracy: 0.9287 - fscore: 0.9273 - val_loss: 0.2797 - val_accuracy: 0.8885 - val_fscore: 0.8767 - lr: 7.2900e-05\n",
            "Epoch 404/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1776 - accuracy: 0.9327 - fscore: 0.9247 - val_loss: 0.5896 - val_accuracy: 0.8080 - val_fscore: 0.8192 - lr: 7.2900e-05\n",
            "Epoch 405/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1908 - accuracy: 0.9225 - fscore: 0.9211 - val_loss: 0.3020 - val_accuracy: 0.8854 - val_fscore: 0.8829 - lr: 7.2900e-05\n",
            "Epoch 406/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1784 - accuracy: 0.9278 - fscore: 0.9281 - val_loss: 0.2782 - val_accuracy: 0.8947 - val_fscore: 0.8942 - lr: 7.2900e-05\n",
            "Epoch 407/700\n",
            "142/142 [==============================] - 4s 32ms/step - loss: 0.1742 - accuracy: 0.9287 - fscore: 0.9280 - val_loss: 0.2776 - val_accuracy: 0.8885 - val_fscore: 0.8788 - lr: 7.2900e-05\n",
            "Epoch 408/700\n",
            "142/142 [==============================] - 4s 30ms/step - loss: 0.1819 - accuracy: 0.9283 - fscore: 0.9259 - val_loss: 0.6429 - val_accuracy: 0.8297 - val_fscore: 0.8359 - lr: 7.2900e-05\n",
            "Epoch 409/700\n",
            "142/142 [==============================] - 4s 31ms/step - loss: 0.1824 - accuracy: 0.9239 - fscore: 0.9276 - val_loss: 0.3255 - val_accuracy: 0.8854 - val_fscore: 0.8724 - lr: 7.2900e-05\n",
            "Epoch 410/700\n",
            "142/142 [==============================] - 4s 30ms/step - loss: 0.1808 - accuracy: 0.9239 - fscore: 0.9234 - val_loss: 0.3008 - val_accuracy: 0.8700 - val_fscore: 0.8763 - lr: 7.2900e-05\n",
            "Epoch 411/700\n",
            "142/142 [==============================] - 4s 28ms/step - loss: 0.1840 - accuracy: 0.9239 - fscore: 0.9250 - val_loss: 0.2770 - val_accuracy: 0.8885 - val_fscore: 0.8874 - lr: 7.2900e-05\n",
            "Epoch 412/700\n",
            "142/142 [==============================] - 4s 30ms/step - loss: 0.1795 - accuracy: 0.9270 - fscore: 0.9262 - val_loss: 0.3002 - val_accuracy: 0.8762 - val_fscore: 0.8761 - lr: 7.2900e-05\n",
            "Epoch 413/700\n",
            "142/142 [==============================] - 4s 31ms/step - loss: 0.1734 - accuracy: 0.9354 - fscore: 0.9319 - val_loss: 0.4931 - val_accuracy: 0.8359 - val_fscore: 0.8296 - lr: 7.2900e-05\n",
            "Epoch 414/700\n",
            "142/142 [==============================] - 3s 23ms/step - loss: 0.1820 - accuracy: 0.9278 - fscore: 0.9273 - val_loss: 0.2852 - val_accuracy: 0.8916 - val_fscore: 0.8834 - lr: 7.2900e-05\n",
            "Epoch 415/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1725 - accuracy: 0.9305 - fscore: 0.9306 - val_loss: 0.2779 - val_accuracy: 0.8854 - val_fscore: 0.8912 - lr: 7.2900e-05\n",
            "Epoch 416/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1746 - accuracy: 0.9283 - fscore: 0.9294 - val_loss: 0.2747 - val_accuracy: 0.8885 - val_fscore: 0.8804 - lr: 7.2900e-05\n",
            "Epoch 417/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1714 - accuracy: 0.9327 - fscore: 0.9280 - val_loss: 0.2852 - val_accuracy: 0.8885 - val_fscore: 0.8855 - lr: 6.5610e-05\n",
            "Epoch 418/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1691 - accuracy: 0.9336 - fscore: 0.9325 - val_loss: 0.2792 - val_accuracy: 0.8916 - val_fscore: 0.8845 - lr: 6.5610e-05\n",
            "Epoch 419/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1703 - accuracy: 0.9301 - fscore: 0.9268 - val_loss: 0.2946 - val_accuracy: 0.8854 - val_fscore: 0.8776 - lr: 6.5610e-05\n",
            "Epoch 420/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1672 - accuracy: 0.9363 - fscore: 0.9370 - val_loss: 0.2992 - val_accuracy: 0.8793 - val_fscore: 0.8819 - lr: 6.5610e-05\n",
            "Epoch 421/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1678 - accuracy: 0.9363 - fscore: 0.9320 - val_loss: 0.3220 - val_accuracy: 0.8885 - val_fscore: 0.8859 - lr: 6.5610e-05\n",
            "Epoch 422/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1727 - accuracy: 0.9309 - fscore: 0.9298 - val_loss: 0.3135 - val_accuracy: 0.8762 - val_fscore: 0.8746 - lr: 6.5610e-05\n",
            "Epoch 423/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1749 - accuracy: 0.9332 - fscore: 0.9314 - val_loss: 0.2969 - val_accuracy: 0.8762 - val_fscore: 0.8761 - lr: 6.5610e-05\n",
            "Epoch 424/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1721 - accuracy: 0.9318 - fscore: 0.9314 - val_loss: 0.3361 - val_accuracy: 0.8762 - val_fscore: 0.8681 - lr: 6.5610e-05\n",
            "Epoch 425/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1697 - accuracy: 0.9340 - fscore: 0.9299 - val_loss: 0.3218 - val_accuracy: 0.8824 - val_fscore: 0.8780 - lr: 6.5610e-05\n",
            "Epoch 426/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1686 - accuracy: 0.9363 - fscore: 0.9304 - val_loss: 0.2882 - val_accuracy: 0.8824 - val_fscore: 0.8869 - lr: 6.5610e-05\n",
            "Epoch 427/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1638 - accuracy: 0.9402 - fscore: 0.9370 - val_loss: 0.3592 - val_accuracy: 0.8700 - val_fscore: 0.8603 - lr: 6.5610e-05\n",
            "Epoch 428/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1689 - accuracy: 0.9323 - fscore: 0.9327 - val_loss: 0.2647 - val_accuracy: 0.8793 - val_fscore: 0.8827 - lr: 6.5610e-05\n",
            "Epoch 429/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1649 - accuracy: 0.9323 - fscore: 0.9325 - val_loss: 0.2827 - val_accuracy: 0.8854 - val_fscore: 0.8826 - lr: 6.5610e-05\n",
            "Epoch 430/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1628 - accuracy: 0.9367 - fscore: 0.9345 - val_loss: 0.4279 - val_accuracy: 0.8576 - val_fscore: 0.8588 - lr: 6.5610e-05\n",
            "Epoch 431/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1710 - accuracy: 0.9296 - fscore: 0.9313 - val_loss: 0.3162 - val_accuracy: 0.8854 - val_fscore: 0.8732 - lr: 6.5610e-05\n",
            "Epoch 432/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1705 - accuracy: 0.9314 - fscore: 0.9290 - val_loss: 0.3285 - val_accuracy: 0.8762 - val_fscore: 0.8708 - lr: 6.5610e-05\n",
            "Epoch 433/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1637 - accuracy: 0.9345 - fscore: 0.9310 - val_loss: 0.3909 - val_accuracy: 0.8483 - val_fscore: 0.8392 - lr: 6.5610e-05\n",
            "Epoch 434/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1715 - accuracy: 0.9332 - fscore: 0.9289 - val_loss: 0.3312 - val_accuracy: 0.8824 - val_fscore: 0.8885 - lr: 6.5610e-05\n",
            "Epoch 435/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1681 - accuracy: 0.9296 - fscore: 0.9291 - val_loss: 0.2819 - val_accuracy: 0.8947 - val_fscore: 0.8867 - lr: 6.5610e-05\n",
            "Epoch 436/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1631 - accuracy: 0.9354 - fscore: 0.9314 - val_loss: 0.4298 - val_accuracy: 0.8514 - val_fscore: 0.8508 - lr: 6.5610e-05\n",
            "Epoch 437/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1645 - accuracy: 0.9332 - fscore: 0.9313 - val_loss: 0.2707 - val_accuracy: 0.9040 - val_fscore: 0.8943 - lr: 6.5610e-05\n",
            "Epoch 438/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1638 - accuracy: 0.9371 - fscore: 0.9320 - val_loss: 0.3125 - val_accuracy: 0.8824 - val_fscore: 0.8791 - lr: 6.5610e-05\n",
            "Epoch 439/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1602 - accuracy: 0.9367 - fscore: 0.9350 - val_loss: 0.3928 - val_accuracy: 0.8607 - val_fscore: 0.8596 - lr: 6.5610e-05\n",
            "Epoch 440/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1637 - accuracy: 0.9336 - fscore: 0.9313 - val_loss: 0.2913 - val_accuracy: 0.8947 - val_fscore: 0.8839 - lr: 6.5610e-05\n",
            "Epoch 441/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1595 - accuracy: 0.9371 - fscore: 0.9329 - val_loss: 0.3105 - val_accuracy: 0.8824 - val_fscore: 0.8706 - lr: 6.5610e-05\n",
            "Epoch 442/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1655 - accuracy: 0.9327 - fscore: 0.9303 - val_loss: 0.3051 - val_accuracy: 0.8793 - val_fscore: 0.8733 - lr: 6.5610e-05\n",
            "Epoch 443/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1646 - accuracy: 0.9363 - fscore: 0.9310 - val_loss: 0.2994 - val_accuracy: 0.8762 - val_fscore: 0.8714 - lr: 6.5610e-05\n",
            "Epoch 444/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1603 - accuracy: 0.9363 - fscore: 0.9336 - val_loss: 0.2793 - val_accuracy: 0.8885 - val_fscore: 0.8850 - lr: 6.5610e-05\n",
            "Epoch 445/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1617 - accuracy: 0.9380 - fscore: 0.9349 - val_loss: 0.2799 - val_accuracy: 0.8916 - val_fscore: 0.8843 - lr: 6.5610e-05\n",
            "Epoch 446/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1598 - accuracy: 0.9367 - fscore: 0.9334 - val_loss: 1.1469 - val_accuracy: 0.6997 - val_fscore: 0.7040 - lr: 6.5610e-05\n",
            "Epoch 447/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1717 - accuracy: 0.9336 - fscore: 0.9289 - val_loss: 0.3416 - val_accuracy: 0.8793 - val_fscore: 0.8886 - lr: 6.5610e-05\n",
            "Epoch 448/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1638 - accuracy: 0.9354 - fscore: 0.9331 - val_loss: 0.2724 - val_accuracy: 0.8916 - val_fscore: 0.8930 - lr: 6.5610e-05\n",
            "Epoch 449/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1600 - accuracy: 0.9336 - fscore: 0.9322 - val_loss: 0.3006 - val_accuracy: 0.8824 - val_fscore: 0.8786 - lr: 5.9049e-05\n",
            "Epoch 450/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1567 - accuracy: 0.9371 - fscore: 0.9338 - val_loss: 0.3082 - val_accuracy: 0.8793 - val_fscore: 0.8839 - lr: 5.9049e-05\n",
            "Epoch 451/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1559 - accuracy: 0.9380 - fscore: 0.9371 - val_loss: 0.3462 - val_accuracy: 0.8731 - val_fscore: 0.8800 - lr: 5.9049e-05\n",
            "Epoch 452/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1570 - accuracy: 0.9398 - fscore: 0.9371 - val_loss: 0.3151 - val_accuracy: 0.8793 - val_fscore: 0.8816 - lr: 5.9049e-05\n",
            "Epoch 453/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1612 - accuracy: 0.9327 - fscore: 0.9331 - val_loss: 0.3012 - val_accuracy: 0.8916 - val_fscore: 0.8889 - lr: 5.9049e-05\n",
            "Epoch 454/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1570 - accuracy: 0.9309 - fscore: 0.9319 - val_loss: 0.3284 - val_accuracy: 0.8700 - val_fscore: 0.8604 - lr: 5.9049e-05\n",
            "Epoch 455/700\n",
            "142/142 [==============================] - 3s 21ms/step - loss: 0.1598 - accuracy: 0.9340 - fscore: 0.9360 - val_loss: 0.2685 - val_accuracy: 0.8854 - val_fscore: 0.8864 - lr: 5.9049e-05\n",
            "Epoch 456/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1546 - accuracy: 0.9389 - fscore: 0.9357 - val_loss: 0.2950 - val_accuracy: 0.8947 - val_fscore: 0.8922 - lr: 5.9049e-05\n",
            "Epoch 457/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1547 - accuracy: 0.9398 - fscore: 0.9370 - val_loss: 0.3115 - val_accuracy: 0.8793 - val_fscore: 0.8753 - lr: 5.9049e-05\n",
            "Epoch 458/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1543 - accuracy: 0.9420 - fscore: 0.9422 - val_loss: 0.2883 - val_accuracy: 0.8854 - val_fscore: 0.8871 - lr: 5.9049e-05\n",
            "Epoch 459/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1534 - accuracy: 0.9425 - fscore: 0.9394 - val_loss: 0.2774 - val_accuracy: 0.8947 - val_fscore: 0.8906 - lr: 5.9049e-05\n",
            "Epoch 460/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1542 - accuracy: 0.9407 - fscore: 0.9391 - val_loss: 0.2873 - val_accuracy: 0.8916 - val_fscore: 0.8844 - lr: 5.9049e-05\n",
            "Epoch 461/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1523 - accuracy: 0.9402 - fscore: 0.9371 - val_loss: 0.3314 - val_accuracy: 0.8731 - val_fscore: 0.8834 - lr: 5.9049e-05\n",
            "Epoch 462/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1526 - accuracy: 0.9389 - fscore: 0.9373 - val_loss: 0.2805 - val_accuracy: 0.8916 - val_fscore: 0.8860 - lr: 5.9049e-05\n",
            "Epoch 463/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1494 - accuracy: 0.9389 - fscore: 0.9380 - val_loss: 0.2797 - val_accuracy: 0.8824 - val_fscore: 0.8842 - lr: 5.9049e-05\n",
            "Epoch 464/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1510 - accuracy: 0.9398 - fscore: 0.9368 - val_loss: 0.3789 - val_accuracy: 0.8607 - val_fscore: 0.8489 - lr: 5.9049e-05\n",
            "Epoch 465/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1541 - accuracy: 0.9416 - fscore: 0.9380 - val_loss: 0.2984 - val_accuracy: 0.8824 - val_fscore: 0.8780 - lr: 5.9049e-05\n",
            "Epoch 466/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1514 - accuracy: 0.9376 - fscore: 0.9375 - val_loss: 0.2795 - val_accuracy: 0.8854 - val_fscore: 0.8836 - lr: 5.9049e-05\n",
            "Epoch 467/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1536 - accuracy: 0.9385 - fscore: 0.9372 - val_loss: 0.3211 - val_accuracy: 0.8824 - val_fscore: 0.8837 - lr: 5.9049e-05\n",
            "Epoch 468/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1518 - accuracy: 0.9371 - fscore: 0.9351 - val_loss: 0.3023 - val_accuracy: 0.8947 - val_fscore: 0.8860 - lr: 5.9049e-05\n",
            "Epoch 469/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1487 - accuracy: 0.9429 - fscore: 0.9381 - val_loss: 0.7826 - val_accuracy: 0.8111 - val_fscore: 0.7950 - lr: 5.3144e-05\n",
            "Epoch 470/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1530 - accuracy: 0.9442 - fscore: 0.9398 - val_loss: 0.2747 - val_accuracy: 0.8793 - val_fscore: 0.8841 - lr: 5.3144e-05\n",
            "Epoch 471/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1456 - accuracy: 0.9389 - fscore: 0.9356 - val_loss: 0.2855 - val_accuracy: 0.8824 - val_fscore: 0.8785 - lr: 5.3144e-05\n",
            "Epoch 472/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1479 - accuracy: 0.9425 - fscore: 0.9386 - val_loss: 0.3058 - val_accuracy: 0.8824 - val_fscore: 0.8808 - lr: 5.3144e-05\n",
            "Epoch 473/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1451 - accuracy: 0.9442 - fscore: 0.9441 - val_loss: 0.3811 - val_accuracy: 0.8669 - val_fscore: 0.8554 - lr: 5.3144e-05\n",
            "Epoch 474/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1471 - accuracy: 0.9411 - fscore: 0.9378 - val_loss: 0.2755 - val_accuracy: 0.8824 - val_fscore: 0.9019 - lr: 5.3144e-05\n",
            "Epoch 475/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1491 - accuracy: 0.9429 - fscore: 0.9418 - val_loss: 0.3376 - val_accuracy: 0.8638 - val_fscore: 0.8606 - lr: 5.3144e-05\n",
            "Epoch 476/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1489 - accuracy: 0.9402 - fscore: 0.9381 - val_loss: 0.3223 - val_accuracy: 0.8824 - val_fscore: 0.8927 - lr: 5.3144e-05\n",
            "Epoch 477/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1479 - accuracy: 0.9442 - fscore: 0.9369 - val_loss: 0.3195 - val_accuracy: 0.8762 - val_fscore: 0.8854 - lr: 5.3144e-05\n",
            "Epoch 478/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1481 - accuracy: 0.9420 - fscore: 0.9413 - val_loss: 0.2758 - val_accuracy: 0.8824 - val_fscore: 0.8909 - lr: 5.3144e-05\n",
            "Epoch 479/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1475 - accuracy: 0.9411 - fscore: 0.9391 - val_loss: 0.2658 - val_accuracy: 0.8885 - val_fscore: 0.8909 - lr: 5.3144e-05\n",
            "Epoch 480/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1446 - accuracy: 0.9425 - fscore: 0.9402 - val_loss: 0.2892 - val_accuracy: 0.8885 - val_fscore: 0.8926 - lr: 5.3144e-05\n",
            "Epoch 481/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1447 - accuracy: 0.9394 - fscore: 0.9398 - val_loss: 0.2771 - val_accuracy: 0.8916 - val_fscore: 0.8871 - lr: 5.3144e-05\n",
            "Epoch 482/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1439 - accuracy: 0.9429 - fscore: 0.9427 - val_loss: 0.2751 - val_accuracy: 0.8731 - val_fscore: 0.8849 - lr: 5.3144e-05\n",
            "Epoch 483/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1433 - accuracy: 0.9451 - fscore: 0.9447 - val_loss: 0.3757 - val_accuracy: 0.8731 - val_fscore: 0.8658 - lr: 5.3144e-05\n",
            "Epoch 484/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1480 - accuracy: 0.9402 - fscore: 0.9399 - val_loss: 0.3702 - val_accuracy: 0.8669 - val_fscore: 0.8723 - lr: 5.3144e-05\n",
            "Epoch 485/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1519 - accuracy: 0.9411 - fscore: 0.9393 - val_loss: 0.2992 - val_accuracy: 0.8854 - val_fscore: 0.8826 - lr: 5.3144e-05\n",
            "Epoch 486/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1446 - accuracy: 0.9451 - fscore: 0.9413 - val_loss: 0.3231 - val_accuracy: 0.8854 - val_fscore: 0.8799 - lr: 5.3144e-05\n",
            "Epoch 487/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1484 - accuracy: 0.9411 - fscore: 0.9370 - val_loss: 0.3201 - val_accuracy: 0.8824 - val_fscore: 0.8790 - lr: 5.3144e-05\n",
            "Epoch 488/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1492 - accuracy: 0.9447 - fscore: 0.9430 - val_loss: 0.2773 - val_accuracy: 0.8885 - val_fscore: 0.8917 - lr: 5.3144e-05\n",
            "Epoch 489/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1387 - accuracy: 0.9425 - fscore: 0.9412 - val_loss: 0.2883 - val_accuracy: 0.8854 - val_fscore: 0.8803 - lr: 4.7830e-05\n",
            "Epoch 490/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1417 - accuracy: 0.9464 - fscore: 0.9416 - val_loss: 0.3181 - val_accuracy: 0.8885 - val_fscore: 0.8782 - lr: 4.7830e-05\n",
            "Epoch 491/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1408 - accuracy: 0.9478 - fscore: 0.9465 - val_loss: 0.2680 - val_accuracy: 0.9009 - val_fscore: 0.8960 - lr: 4.7830e-05\n",
            "Epoch 492/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1397 - accuracy: 0.9460 - fscore: 0.9430 - val_loss: 0.2896 - val_accuracy: 0.8854 - val_fscore: 0.8816 - lr: 4.7830e-05\n",
            "Epoch 493/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1429 - accuracy: 0.9456 - fscore: 0.9437 - val_loss: 0.2656 - val_accuracy: 0.8885 - val_fscore: 0.8948 - lr: 4.7830e-05\n",
            "Epoch 494/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1415 - accuracy: 0.9429 - fscore: 0.9433 - val_loss: 0.3400 - val_accuracy: 0.8731 - val_fscore: 0.8776 - lr: 4.7830e-05\n",
            "Epoch 495/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1426 - accuracy: 0.9398 - fscore: 0.9407 - val_loss: 0.2834 - val_accuracy: 0.8824 - val_fscore: 0.8769 - lr: 4.7830e-05\n",
            "Epoch 496/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1404 - accuracy: 0.9491 - fscore: 0.9431 - val_loss: 0.3134 - val_accuracy: 0.8793 - val_fscore: 0.8776 - lr: 4.7830e-05\n",
            "Epoch 497/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1392 - accuracy: 0.9438 - fscore: 0.9401 - val_loss: 0.3626 - val_accuracy: 0.8700 - val_fscore: 0.8685 - lr: 4.7830e-05\n",
            "Epoch 498/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1401 - accuracy: 0.9438 - fscore: 0.9429 - val_loss: 0.2844 - val_accuracy: 0.8885 - val_fscore: 0.8793 - lr: 4.7830e-05\n",
            "Epoch 499/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1386 - accuracy: 0.9491 - fscore: 0.9431 - val_loss: 0.3268 - val_accuracy: 0.8793 - val_fscore: 0.8776 - lr: 4.7830e-05\n",
            "Epoch 500/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1441 - accuracy: 0.9429 - fscore: 0.9414 - val_loss: 0.2790 - val_accuracy: 0.8885 - val_fscore: 0.8911 - lr: 4.7830e-05\n",
            "Epoch 501/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1404 - accuracy: 0.9438 - fscore: 0.9432 - val_loss: 0.2760 - val_accuracy: 0.8793 - val_fscore: 0.8837 - lr: 4.7830e-05\n",
            "Epoch 502/700\n",
            "142/142 [==============================] - 3s 20ms/step - loss: 0.1359 - accuracy: 0.9433 - fscore: 0.9446 - val_loss: 0.2847 - val_accuracy: 0.8824 - val_fscore: 0.8832 - lr: 4.7830e-05\n",
            "Epoch 503/700\n",
            "142/142 [==============================] - 3s 19ms/step - loss: 0.1379 - accuracy: 0.9429 - fscore: 0.9402 - val_loss: 0.2608 - val_accuracy: 0.8947 - val_fscore: 0.8840 - lr: 4.7830e-05\n",
            "Epoch 504/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1420 - accuracy: 0.9433 - fscore: 0.9412 - val_loss: 0.2801 - val_accuracy: 0.8854 - val_fscore: 0.8865 - lr: 4.7830e-05\n",
            "Epoch 505/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1344 - accuracy: 0.9482 - fscore: 0.9455 - val_loss: 0.2841 - val_accuracy: 0.8824 - val_fscore: 0.8839 - lr: 4.7830e-05\n",
            "Epoch 506/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1372 - accuracy: 0.9491 - fscore: 0.9447 - val_loss: 0.2657 - val_accuracy: 0.8978 - val_fscore: 0.8966 - lr: 4.7830e-05\n",
            "Epoch 507/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1386 - accuracy: 0.9442 - fscore: 0.9420 - val_loss: 0.2712 - val_accuracy: 0.8854 - val_fscore: 0.8805 - lr: 4.7830e-05\n",
            "Epoch 508/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1378 - accuracy: 0.9469 - fscore: 0.9430 - val_loss: 0.2595 - val_accuracy: 0.8854 - val_fscore: 0.8960 - lr: 4.7830e-05\n",
            "Epoch 509/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1393 - accuracy: 0.9447 - fscore: 0.9438 - val_loss: 0.2929 - val_accuracy: 0.8885 - val_fscore: 0.8870 - lr: 4.7830e-05\n",
            "Epoch 510/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1377 - accuracy: 0.9447 - fscore: 0.9449 - val_loss: 0.2763 - val_accuracy: 0.8885 - val_fscore: 0.8924 - lr: 4.7830e-05\n",
            "Epoch 511/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1370 - accuracy: 0.9438 - fscore: 0.9414 - val_loss: 0.2837 - val_accuracy: 0.8978 - val_fscore: 0.8879 - lr: 4.7830e-05\n",
            "Epoch 512/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1364 - accuracy: 0.9504 - fscore: 0.9477 - val_loss: 0.4600 - val_accuracy: 0.8390 - val_fscore: 0.8250 - lr: 4.7830e-05\n",
            "Epoch 513/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1375 - accuracy: 0.9478 - fscore: 0.9468 - val_loss: 0.2765 - val_accuracy: 0.8824 - val_fscore: 0.8902 - lr: 4.7830e-05\n",
            "Epoch 514/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1363 - accuracy: 0.9460 - fscore: 0.9419 - val_loss: 0.3901 - val_accuracy: 0.8700 - val_fscore: 0.8612 - lr: 4.7830e-05\n",
            "Epoch 515/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1383 - accuracy: 0.9438 - fscore: 0.9411 - val_loss: 0.2700 - val_accuracy: 0.8978 - val_fscore: 0.9017 - lr: 4.7830e-05\n",
            "Epoch 516/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1371 - accuracy: 0.9473 - fscore: 0.9421 - val_loss: 0.2721 - val_accuracy: 0.8947 - val_fscore: 0.8906 - lr: 4.7830e-05\n",
            "Epoch 517/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1326 - accuracy: 0.9486 - fscore: 0.9464 - val_loss: 0.2673 - val_accuracy: 0.8885 - val_fscore: 0.8848 - lr: 4.7830e-05\n",
            "Epoch 518/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1336 - accuracy: 0.9442 - fscore: 0.9421 - val_loss: 0.3962 - val_accuracy: 0.8514 - val_fscore: 0.8532 - lr: 4.7830e-05\n",
            "Epoch 519/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1400 - accuracy: 0.9442 - fscore: 0.9433 - val_loss: 0.2855 - val_accuracy: 0.8916 - val_fscore: 0.8905 - lr: 4.7830e-05\n",
            "Epoch 520/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1338 - accuracy: 0.9460 - fscore: 0.9461 - val_loss: 0.2643 - val_accuracy: 0.8916 - val_fscore: 0.8889 - lr: 4.7830e-05\n",
            "Epoch 521/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1318 - accuracy: 0.9456 - fscore: 0.9431 - val_loss: 0.2856 - val_accuracy: 0.8731 - val_fscore: 0.8829 - lr: 4.7830e-05\n",
            "Epoch 522/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1339 - accuracy: 0.9473 - fscore: 0.9462 - val_loss: 0.2845 - val_accuracy: 0.8947 - val_fscore: 0.8822 - lr: 4.7830e-05\n",
            "Epoch 523/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1322 - accuracy: 0.9456 - fscore: 0.9426 - val_loss: 0.2935 - val_accuracy: 0.8824 - val_fscore: 0.8839 - lr: 4.7830e-05\n",
            "Epoch 524/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1357 - accuracy: 0.9464 - fscore: 0.9439 - val_loss: 0.6264 - val_accuracy: 0.8204 - val_fscore: 0.8191 - lr: 4.7830e-05\n",
            "Epoch 525/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1355 - accuracy: 0.9482 - fscore: 0.9452 - val_loss: 0.2668 - val_accuracy: 0.8854 - val_fscore: 0.8873 - lr: 4.7830e-05\n",
            "Epoch 526/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1333 - accuracy: 0.9526 - fscore: 0.9467 - val_loss: 0.3015 - val_accuracy: 0.8824 - val_fscore: 0.8822 - lr: 4.7830e-05\n",
            "Epoch 527/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1401 - accuracy: 0.9451 - fscore: 0.9424 - val_loss: 0.2655 - val_accuracy: 0.8916 - val_fscore: 0.8966 - lr: 4.7830e-05\n",
            "Epoch 528/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1357 - accuracy: 0.9451 - fscore: 0.9425 - val_loss: 0.2817 - val_accuracy: 0.8916 - val_fscore: 0.8799 - lr: 4.7830e-05\n",
            "Epoch 529/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1338 - accuracy: 0.9460 - fscore: 0.9464 - val_loss: 0.2586 - val_accuracy: 0.8885 - val_fscore: 0.8949 - lr: 4.3047e-05\n",
            "Epoch 530/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1301 - accuracy: 0.9513 - fscore: 0.9475 - val_loss: 0.3356 - val_accuracy: 0.8824 - val_fscore: 0.8781 - lr: 4.3047e-05\n",
            "Epoch 531/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1309 - accuracy: 0.9486 - fscore: 0.9466 - val_loss: 0.4636 - val_accuracy: 0.8545 - val_fscore: 0.8633 - lr: 4.3047e-05\n",
            "Epoch 532/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1306 - accuracy: 0.9513 - fscore: 0.9475 - val_loss: 0.2718 - val_accuracy: 0.8793 - val_fscore: 0.8897 - lr: 4.3047e-05\n",
            "Epoch 533/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1305 - accuracy: 0.9473 - fscore: 0.9459 - val_loss: 0.2796 - val_accuracy: 0.8824 - val_fscore: 0.8960 - lr: 4.3047e-05\n",
            "Epoch 534/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1300 - accuracy: 0.9495 - fscore: 0.9447 - val_loss: 0.2740 - val_accuracy: 0.8854 - val_fscore: 0.8932 - lr: 4.3047e-05\n",
            "Epoch 535/700\n",
            "142/142 [==============================] - 2s 18ms/step - loss: 0.1326 - accuracy: 0.9473 - fscore: 0.9461 - val_loss: 0.2731 - val_accuracy: 0.8824 - val_fscore: 0.8820 - lr: 4.3047e-05\n",
            "Epoch 536/700\n",
            "142/142 [==============================] - 3s 20ms/step - loss: 0.1283 - accuracy: 0.9526 - fscore: 0.9497 - val_loss: 0.2696 - val_accuracy: 0.8885 - val_fscore: 0.8913 - lr: 4.3047e-05\n",
            "Epoch 537/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1301 - accuracy: 0.9495 - fscore: 0.9465 - val_loss: 0.2720 - val_accuracy: 0.8947 - val_fscore: 0.8899 - lr: 4.3047e-05\n",
            "Epoch 538/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1282 - accuracy: 0.9495 - fscore: 0.9475 - val_loss: 0.6486 - val_accuracy: 0.8173 - val_fscore: 0.8132 - lr: 4.3047e-05\n",
            "Epoch 539/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1490 - accuracy: 0.9482 - fscore: 0.9457 - val_loss: 0.2834 - val_accuracy: 0.8885 - val_fscore: 0.8892 - lr: 4.3047e-05\n",
            "Epoch 540/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1292 - accuracy: 0.9504 - fscore: 0.9461 - val_loss: 0.3657 - val_accuracy: 0.8669 - val_fscore: 0.8812 - lr: 4.3047e-05\n",
            "Epoch 541/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1318 - accuracy: 0.9486 - fscore: 0.9476 - val_loss: 0.3232 - val_accuracy: 0.8947 - val_fscore: 0.8907 - lr: 4.3047e-05\n",
            "Epoch 542/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1299 - accuracy: 0.9500 - fscore: 0.9473 - val_loss: 0.3223 - val_accuracy: 0.8669 - val_fscore: 0.8647 - lr: 4.3047e-05\n",
            "Epoch 543/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1321 - accuracy: 0.9517 - fscore: 0.9511 - val_loss: 0.2791 - val_accuracy: 0.8885 - val_fscore: 0.8811 - lr: 4.3047e-05\n",
            "Epoch 544/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1298 - accuracy: 0.9478 - fscore: 0.9439 - val_loss: 0.2752 - val_accuracy: 0.8824 - val_fscore: 0.8874 - lr: 4.3047e-05\n",
            "Epoch 545/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1278 - accuracy: 0.9491 - fscore: 0.9480 - val_loss: 0.2822 - val_accuracy: 0.8947 - val_fscore: 0.8856 - lr: 4.3047e-05\n",
            "Epoch 546/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1288 - accuracy: 0.9478 - fscore: 0.9452 - val_loss: 0.2681 - val_accuracy: 0.8978 - val_fscore: 0.8905 - lr: 4.3047e-05\n",
            "Epoch 547/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1265 - accuracy: 0.9500 - fscore: 0.9488 - val_loss: 0.2591 - val_accuracy: 0.8885 - val_fscore: 0.8892 - lr: 4.3047e-05\n",
            "Epoch 548/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1272 - accuracy: 0.9509 - fscore: 0.9479 - val_loss: 0.3081 - val_accuracy: 0.8824 - val_fscore: 0.8829 - lr: 4.3047e-05\n",
            "Epoch 549/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1290 - accuracy: 0.9482 - fscore: 0.9479 - val_loss: 0.4439 - val_accuracy: 0.8669 - val_fscore: 0.8653 - lr: 4.3047e-05\n",
            "Epoch 550/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1228 - accuracy: 0.9531 - fscore: 0.9499 - val_loss: 0.2766 - val_accuracy: 0.8854 - val_fscore: 0.8858 - lr: 3.8742e-05\n",
            "Epoch 551/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1243 - accuracy: 0.9531 - fscore: 0.9515 - val_loss: 0.3382 - val_accuracy: 0.8824 - val_fscore: 0.8750 - lr: 3.8742e-05\n",
            "Epoch 552/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1253 - accuracy: 0.9504 - fscore: 0.9489 - val_loss: 0.2758 - val_accuracy: 0.8885 - val_fscore: 0.8894 - lr: 3.8742e-05\n",
            "Epoch 553/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1252 - accuracy: 0.9517 - fscore: 0.9494 - val_loss: 0.5258 - val_accuracy: 0.8669 - val_fscore: 0.8579 - lr: 3.8742e-05\n",
            "Epoch 554/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1437 - accuracy: 0.9460 - fscore: 0.9447 - val_loss: 0.2776 - val_accuracy: 0.8947 - val_fscore: 0.8854 - lr: 3.8742e-05\n",
            "Epoch 555/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1220 - accuracy: 0.9531 - fscore: 0.9541 - val_loss: 0.2837 - val_accuracy: 0.8916 - val_fscore: 0.8798 - lr: 3.8742e-05\n",
            "Epoch 556/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1256 - accuracy: 0.9482 - fscore: 0.9473 - val_loss: 0.2873 - val_accuracy: 0.8854 - val_fscore: 0.8834 - lr: 3.8742e-05\n",
            "Epoch 557/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1252 - accuracy: 0.9517 - fscore: 0.9483 - val_loss: 0.2812 - val_accuracy: 0.8947 - val_fscore: 0.8900 - lr: 3.8742e-05\n",
            "Epoch 558/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1221 - accuracy: 0.9522 - fscore: 0.9489 - val_loss: 0.3455 - val_accuracy: 0.8638 - val_fscore: 0.8570 - lr: 3.8742e-05\n",
            "Epoch 559/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1242 - accuracy: 0.9495 - fscore: 0.9501 - val_loss: 0.2709 - val_accuracy: 0.8916 - val_fscore: 0.9024 - lr: 3.8742e-05\n",
            "Epoch 560/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1219 - accuracy: 0.9531 - fscore: 0.9506 - val_loss: 0.3287 - val_accuracy: 0.8824 - val_fscore: 0.8786 - lr: 3.8742e-05\n",
            "Epoch 561/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1258 - accuracy: 0.9540 - fscore: 0.9514 - val_loss: 0.2699 - val_accuracy: 0.9009 - val_fscore: 0.8921 - lr: 3.8742e-05\n",
            "Epoch 562/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1212 - accuracy: 0.9544 - fscore: 0.9540 - val_loss: 0.2880 - val_accuracy: 0.8854 - val_fscore: 0.8869 - lr: 3.8742e-05\n",
            "Epoch 563/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1214 - accuracy: 0.9540 - fscore: 0.9492 - val_loss: 0.2734 - val_accuracy: 0.8916 - val_fscore: 0.8954 - lr: 3.8742e-05\n",
            "Epoch 564/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1209 - accuracy: 0.9526 - fscore: 0.9511 - val_loss: 0.2863 - val_accuracy: 0.8854 - val_fscore: 0.8827 - lr: 3.8742e-05\n",
            "Epoch 565/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1214 - accuracy: 0.9571 - fscore: 0.9548 - val_loss: 0.3194 - val_accuracy: 0.8793 - val_fscore: 0.8801 - lr: 3.8742e-05\n",
            "Epoch 566/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1225 - accuracy: 0.9513 - fscore: 0.9507 - val_loss: 0.3102 - val_accuracy: 0.8916 - val_fscore: 0.8988 - lr: 3.8742e-05\n",
            "Epoch 567/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1255 - accuracy: 0.9509 - fscore: 0.9497 - val_loss: 0.2762 - val_accuracy: 0.8885 - val_fscore: 0.8902 - lr: 3.8742e-05\n",
            "Epoch 568/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1244 - accuracy: 0.9553 - fscore: 0.9527 - val_loss: 0.4465 - val_accuracy: 0.8545 - val_fscore: 0.8519 - lr: 3.8742e-05\n",
            "Epoch 569/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1244 - accuracy: 0.9526 - fscore: 0.9512 - val_loss: 0.2704 - val_accuracy: 0.9009 - val_fscore: 0.9032 - lr: 3.8742e-05\n",
            "Epoch 570/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1190 - accuracy: 0.9544 - fscore: 0.9548 - val_loss: 0.2880 - val_accuracy: 0.8916 - val_fscore: 0.9012 - lr: 3.4868e-05\n",
            "Epoch 571/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1182 - accuracy: 0.9557 - fscore: 0.9522 - val_loss: 0.3426 - val_accuracy: 0.8762 - val_fscore: 0.8687 - lr: 3.4868e-05\n",
            "Epoch 572/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1199 - accuracy: 0.9522 - fscore: 0.9515 - val_loss: 0.2988 - val_accuracy: 0.9009 - val_fscore: 0.8901 - lr: 3.4868e-05\n",
            "Epoch 573/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1197 - accuracy: 0.9535 - fscore: 0.9527 - val_loss: 0.2725 - val_accuracy: 0.8885 - val_fscore: 0.8866 - lr: 3.4868e-05\n",
            "Epoch 574/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1185 - accuracy: 0.9540 - fscore: 0.9521 - val_loss: 0.2741 - val_accuracy: 0.8947 - val_fscore: 0.8903 - lr: 3.4868e-05\n",
            "Epoch 575/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1203 - accuracy: 0.9504 - fscore: 0.9503 - val_loss: 0.3124 - val_accuracy: 0.8916 - val_fscore: 0.8903 - lr: 3.4868e-05\n",
            "Epoch 576/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1158 - accuracy: 0.9557 - fscore: 0.9563 - val_loss: 0.3157 - val_accuracy: 0.8916 - val_fscore: 0.8889 - lr: 3.4868e-05\n",
            "Epoch 577/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1200 - accuracy: 0.9513 - fscore: 0.9504 - val_loss: 0.2823 - val_accuracy: 0.8824 - val_fscore: 0.8845 - lr: 3.4868e-05\n",
            "Epoch 578/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1187 - accuracy: 0.9562 - fscore: 0.9539 - val_loss: 0.2667 - val_accuracy: 0.9040 - val_fscore: 0.8946 - lr: 3.4868e-05\n",
            "Epoch 579/700\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.1206 - accuracy: 0.9544 - fscore: 0.9522 - val_loss: 0.3018 - val_accuracy: 0.8947 - val_fscore: 0.8920 - lr: 3.4868e-05\n",
            "Epoch 580/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1180 - accuracy: 0.9562 - fscore: 0.9529 - val_loss: 0.2927 - val_accuracy: 0.8916 - val_fscore: 0.9001 - lr: 3.4868e-05\n",
            "Epoch 581/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1184 - accuracy: 0.9540 - fscore: 0.9509 - val_loss: 0.2850 - val_accuracy: 0.8916 - val_fscore: 0.9006 - lr: 3.4868e-05\n",
            "Epoch 582/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1163 - accuracy: 0.9553 - fscore: 0.9545 - val_loss: 0.2979 - val_accuracy: 0.8885 - val_fscore: 0.8946 - lr: 3.4868e-05\n",
            "Epoch 583/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1194 - accuracy: 0.9540 - fscore: 0.9507 - val_loss: 0.2906 - val_accuracy: 0.8916 - val_fscore: 0.8970 - lr: 3.4868e-05\n",
            "Epoch 584/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1165 - accuracy: 0.9526 - fscore: 0.9518 - val_loss: 0.3423 - val_accuracy: 0.8669 - val_fscore: 0.8731 - lr: 3.4868e-05\n",
            "Epoch 585/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1188 - accuracy: 0.9522 - fscore: 0.9515 - val_loss: 0.2675 - val_accuracy: 0.8978 - val_fscore: 0.8863 - lr: 3.4868e-05\n",
            "Epoch 586/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1195 - accuracy: 0.9562 - fscore: 0.9538 - val_loss: 0.3121 - val_accuracy: 0.8793 - val_fscore: 0.8771 - lr: 3.4868e-05\n",
            "Epoch 587/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1179 - accuracy: 0.9535 - fscore: 0.9546 - val_loss: 0.2949 - val_accuracy: 0.8854 - val_fscore: 0.8967 - lr: 3.4868e-05\n",
            "Epoch 588/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1170 - accuracy: 0.9553 - fscore: 0.9543 - val_loss: 0.3133 - val_accuracy: 0.8824 - val_fscore: 0.8875 - lr: 3.4868e-05\n",
            "Epoch 589/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1170 - accuracy: 0.9513 - fscore: 0.9506 - val_loss: 0.2734 - val_accuracy: 0.8762 - val_fscore: 0.8901 - lr: 3.4868e-05\n",
            "Epoch 590/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1132 - accuracy: 0.9535 - fscore: 0.9555 - val_loss: 0.2692 - val_accuracy: 0.9009 - val_fscore: 0.8972 - lr: 3.1381e-05\n",
            "Epoch 591/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1133 - accuracy: 0.9566 - fscore: 0.9566 - val_loss: 0.2637 - val_accuracy: 0.8885 - val_fscore: 0.9020 - lr: 3.1381e-05\n",
            "Epoch 592/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1126 - accuracy: 0.9553 - fscore: 0.9557 - val_loss: 0.2548 - val_accuracy: 0.8947 - val_fscore: 0.9019 - lr: 3.1381e-05\n",
            "Epoch 593/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1175 - accuracy: 0.9575 - fscore: 0.9562 - val_loss: 0.2880 - val_accuracy: 0.8885 - val_fscore: 0.8969 - lr: 3.1381e-05\n",
            "Epoch 594/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1181 - accuracy: 0.9513 - fscore: 0.9503 - val_loss: 0.2673 - val_accuracy: 0.8885 - val_fscore: 0.9008 - lr: 3.1381e-05\n",
            "Epoch 595/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1164 - accuracy: 0.9526 - fscore: 0.9533 - val_loss: 0.3437 - val_accuracy: 0.8731 - val_fscore: 0.8689 - lr: 3.1381e-05\n",
            "Epoch 596/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1175 - accuracy: 0.9544 - fscore: 0.9529 - val_loss: 0.2688 - val_accuracy: 0.8854 - val_fscore: 0.8852 - lr: 3.1381e-05\n",
            "Epoch 597/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1156 - accuracy: 0.9553 - fscore: 0.9505 - val_loss: 0.2895 - val_accuracy: 0.8885 - val_fscore: 0.8930 - lr: 3.1381e-05\n",
            "Epoch 598/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1161 - accuracy: 0.9535 - fscore: 0.9534 - val_loss: 0.3118 - val_accuracy: 0.8700 - val_fscore: 0.8737 - lr: 3.1381e-05\n",
            "Epoch 599/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1158 - accuracy: 0.9562 - fscore: 0.9556 - val_loss: 0.2744 - val_accuracy: 0.8916 - val_fscore: 0.8859 - lr: 3.1381e-05\n",
            "Epoch 600/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1136 - accuracy: 0.9575 - fscore: 0.9565 - val_loss: 0.2843 - val_accuracy: 0.8854 - val_fscore: 0.8943 - lr: 3.1381e-05\n",
            "Epoch 601/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1132 - accuracy: 0.9597 - fscore: 0.9572 - val_loss: 0.2799 - val_accuracy: 0.8793 - val_fscore: 0.8790 - lr: 3.1381e-05\n",
            "Epoch 602/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1122 - accuracy: 0.9628 - fscore: 0.9594 - val_loss: 0.2712 - val_accuracy: 0.8978 - val_fscore: 0.8967 - lr: 3.1381e-05\n",
            "Epoch 603/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1158 - accuracy: 0.9553 - fscore: 0.9550 - val_loss: 0.2969 - val_accuracy: 0.8916 - val_fscore: 0.8916 - lr: 3.1381e-05\n",
            "Epoch 604/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1153 - accuracy: 0.9531 - fscore: 0.9496 - val_loss: 0.2817 - val_accuracy: 0.8885 - val_fscore: 0.8958 - lr: 3.1381e-05\n",
            "Epoch 605/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1121 - accuracy: 0.9557 - fscore: 0.9546 - val_loss: 0.4307 - val_accuracy: 0.8607 - val_fscore: 0.8599 - lr: 3.1381e-05\n",
            "Epoch 606/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1150 - accuracy: 0.9579 - fscore: 0.9536 - val_loss: 0.2910 - val_accuracy: 0.8947 - val_fscore: 0.9000 - lr: 3.1381e-05\n",
            "Epoch 607/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1160 - accuracy: 0.9579 - fscore: 0.9581 - val_loss: 0.2798 - val_accuracy: 0.8885 - val_fscore: 0.8877 - lr: 3.1381e-05\n",
            "Epoch 608/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1123 - accuracy: 0.9584 - fscore: 0.9568 - val_loss: 0.2802 - val_accuracy: 0.8978 - val_fscore: 0.9038 - lr: 3.1381e-05\n",
            "Epoch 609/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1153 - accuracy: 0.9540 - fscore: 0.9551 - val_loss: 0.2715 - val_accuracy: 0.8978 - val_fscore: 0.9032 - lr: 3.1381e-05\n",
            "Epoch 610/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1110 - accuracy: 0.9584 - fscore: 0.9576 - val_loss: 0.2833 - val_accuracy: 0.8978 - val_fscore: 0.9037 - lr: 3.1381e-05\n",
            "Epoch 611/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1117 - accuracy: 0.9575 - fscore: 0.9561 - val_loss: 0.2822 - val_accuracy: 0.8916 - val_fscore: 0.8952 - lr: 3.1381e-05\n",
            "Epoch 612/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1136 - accuracy: 0.9575 - fscore: 0.9539 - val_loss: 0.2708 - val_accuracy: 0.8854 - val_fscore: 0.9057 - lr: 3.1381e-05\n",
            "Epoch 613/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1115 - accuracy: 0.9584 - fscore: 0.9568 - val_loss: 0.2774 - val_accuracy: 0.9009 - val_fscore: 0.9019 - lr: 2.8243e-05\n",
            "Epoch 614/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1112 - accuracy: 0.9579 - fscore: 0.9563 - val_loss: 0.3133 - val_accuracy: 0.8824 - val_fscore: 0.8740 - lr: 2.8243e-05\n",
            "Epoch 615/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1139 - accuracy: 0.9531 - fscore: 0.9539 - val_loss: 0.2935 - val_accuracy: 0.8854 - val_fscore: 0.8819 - lr: 2.8243e-05\n",
            "Epoch 616/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1108 - accuracy: 0.9553 - fscore: 0.9526 - val_loss: 0.6512 - val_accuracy: 0.8204 - val_fscore: 0.8249 - lr: 2.8243e-05\n",
            "Epoch 617/700\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.1151 - accuracy: 0.9557 - fscore: 0.9542 - val_loss: 0.2712 - val_accuracy: 0.8916 - val_fscore: 0.8984 - lr: 2.8243e-05\n",
            "Epoch 618/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1090 - accuracy: 0.9588 - fscore: 0.9574 - val_loss: 0.3003 - val_accuracy: 0.8916 - val_fscore: 0.8987 - lr: 2.8243e-05\n",
            "Epoch 619/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1121 - accuracy: 0.9548 - fscore: 0.9559 - val_loss: 0.2715 - val_accuracy: 0.9009 - val_fscore: 0.9124 - lr: 2.8243e-05\n",
            "Epoch 620/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1094 - accuracy: 0.9584 - fscore: 0.9567 - val_loss: 0.2806 - val_accuracy: 0.8854 - val_fscore: 0.8853 - lr: 2.8243e-05\n",
            "Epoch 621/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.1085 - accuracy: 0.9610 - fscore: 0.9592 - val_loss: 0.2649 - val_accuracy: 0.9009 - val_fscore: 0.8983 - lr: 2.8243e-05\n",
            "Epoch 622/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1110 - accuracy: 0.9557 - fscore: 0.9555 - val_loss: 0.2685 - val_accuracy: 0.8978 - val_fscore: 0.9033 - lr: 2.8243e-05\n",
            "Epoch 623/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1089 - accuracy: 0.9579 - fscore: 0.9555 - val_loss: 0.2823 - val_accuracy: 0.8978 - val_fscore: 0.8968 - lr: 2.8243e-05\n",
            "Epoch 624/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1088 - accuracy: 0.9562 - fscore: 0.9547 - val_loss: 0.3071 - val_accuracy: 0.8978 - val_fscore: 0.9006 - lr: 2.8243e-05\n",
            "Epoch 625/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1106 - accuracy: 0.9606 - fscore: 0.9577 - val_loss: 0.2760 - val_accuracy: 0.9040 - val_fscore: 0.8975 - lr: 2.8243e-05\n",
            "Epoch 626/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1089 - accuracy: 0.9575 - fscore: 0.9576 - val_loss: 0.2749 - val_accuracy: 0.8916 - val_fscore: 0.8866 - lr: 2.8243e-05\n",
            "Epoch 627/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1110 - accuracy: 0.9575 - fscore: 0.9537 - val_loss: 0.2856 - val_accuracy: 0.8854 - val_fscore: 0.8934 - lr: 2.8243e-05\n",
            "Epoch 628/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1078 - accuracy: 0.9602 - fscore: 0.9591 - val_loss: 0.2903 - val_accuracy: 0.8885 - val_fscore: 0.9038 - lr: 2.8243e-05\n",
            "Epoch 629/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1069 - accuracy: 0.9633 - fscore: 0.9634 - val_loss: 0.2864 - val_accuracy: 0.8700 - val_fscore: 0.8784 - lr: 2.8243e-05\n",
            "Epoch 630/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1111 - accuracy: 0.9593 - fscore: 0.9559 - val_loss: 0.2799 - val_accuracy: 0.8978 - val_fscore: 0.8900 - lr: 2.8243e-05\n",
            "Epoch 631/700\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.1079 - accuracy: 0.9602 - fscore: 0.9581 - val_loss: 0.2780 - val_accuracy: 0.8916 - val_fscore: 0.8961 - lr: 2.8243e-05\n",
            "Epoch 632/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1105 - accuracy: 0.9571 - fscore: 0.9581 - val_loss: 0.3026 - val_accuracy: 0.8793 - val_fscore: 0.8816 - lr: 2.8243e-05\n",
            "Epoch 633/700\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.1067 - accuracy: 0.9584 - fscore: 0.9581 - val_loss: 0.2623 - val_accuracy: 0.8885 - val_fscore: 0.8993 - lr: 2.5419e-05\n",
            "Epoch 634/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1079 - accuracy: 0.9579 - fscore: 0.9565 - val_loss: 0.2710 - val_accuracy: 0.8916 - val_fscore: 0.8936 - lr: 2.5419e-05\n",
            "Epoch 635/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1062 - accuracy: 0.9597 - fscore: 0.9579 - val_loss: 0.5109 - val_accuracy: 0.8514 - val_fscore: 0.8490 - lr: 2.5419e-05\n",
            "Epoch 636/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1097 - accuracy: 0.9602 - fscore: 0.9581 - val_loss: 0.2715 - val_accuracy: 0.8854 - val_fscore: 0.9004 - lr: 2.5419e-05\n",
            "Epoch 637/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1086 - accuracy: 0.9593 - fscore: 0.9587 - val_loss: 0.2688 - val_accuracy: 0.8793 - val_fscore: 0.8878 - lr: 2.5419e-05\n",
            "Epoch 638/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1057 - accuracy: 0.9615 - fscore: 0.9595 - val_loss: 0.2766 - val_accuracy: 0.9102 - val_fscore: 0.9047 - lr: 2.5419e-05\n",
            "Epoch 639/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1089 - accuracy: 0.9597 - fscore: 0.9602 - val_loss: 0.2749 - val_accuracy: 0.8885 - val_fscore: 0.9032 - lr: 2.5419e-05\n",
            "Epoch 640/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1058 - accuracy: 0.9597 - fscore: 0.9554 - val_loss: 0.2751 - val_accuracy: 0.8916 - val_fscore: 0.8996 - lr: 2.5419e-05\n",
            "Epoch 641/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1055 - accuracy: 0.9615 - fscore: 0.9595 - val_loss: 0.2733 - val_accuracy: 0.8978 - val_fscore: 0.8894 - lr: 2.5419e-05\n",
            "Epoch 642/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1060 - accuracy: 0.9619 - fscore: 0.9613 - val_loss: 0.2638 - val_accuracy: 0.8885 - val_fscore: 0.8892 - lr: 2.5419e-05\n",
            "Epoch 643/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1053 - accuracy: 0.9606 - fscore: 0.9607 - val_loss: 0.2976 - val_accuracy: 0.8885 - val_fscore: 0.8969 - lr: 2.5419e-05\n",
            "Epoch 644/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1038 - accuracy: 0.9562 - fscore: 0.9593 - val_loss: 0.2694 - val_accuracy: 0.9009 - val_fscore: 0.9005 - lr: 2.5419e-05\n",
            "Epoch 645/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1039 - accuracy: 0.9602 - fscore: 0.9613 - val_loss: 0.2920 - val_accuracy: 0.8947 - val_fscore: 0.8907 - lr: 2.5419e-05\n",
            "Epoch 646/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1068 - accuracy: 0.9584 - fscore: 0.9567 - val_loss: 0.2891 - val_accuracy: 0.8885 - val_fscore: 0.8883 - lr: 2.5419e-05\n",
            "Epoch 647/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1055 - accuracy: 0.9615 - fscore: 0.9605 - val_loss: 0.2630 - val_accuracy: 0.8978 - val_fscore: 0.8936 - lr: 2.5419e-05\n",
            "Epoch 648/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1066 - accuracy: 0.9588 - fscore: 0.9570 - val_loss: 0.2965 - val_accuracy: 0.8824 - val_fscore: 0.8888 - lr: 2.5419e-05\n",
            "Epoch 649/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1052 - accuracy: 0.9606 - fscore: 0.9608 - val_loss: 0.2791 - val_accuracy: 0.8854 - val_fscore: 0.8849 - lr: 2.5419e-05\n",
            "Epoch 650/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1052 - accuracy: 0.9619 - fscore: 0.9579 - val_loss: 0.2715 - val_accuracy: 0.8978 - val_fscore: 0.8951 - lr: 2.5419e-05\n",
            "Epoch 651/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1074 - accuracy: 0.9597 - fscore: 0.9569 - val_loss: 0.2786 - val_accuracy: 0.8916 - val_fscore: 0.9028 - lr: 2.5419e-05\n",
            "Epoch 652/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1058 - accuracy: 0.9610 - fscore: 0.9612 - val_loss: 0.2899 - val_accuracy: 0.8824 - val_fscore: 0.8824 - lr: 2.5419e-05\n",
            "Epoch 653/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1026 - accuracy: 0.9628 - fscore: 0.9619 - val_loss: 0.2989 - val_accuracy: 0.9009 - val_fscore: 0.9059 - lr: 2.2877e-05\n",
            "Epoch 654/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1051 - accuracy: 0.9606 - fscore: 0.9605 - val_loss: 0.2718 - val_accuracy: 0.8978 - val_fscore: 0.8998 - lr: 2.2877e-05\n",
            "Epoch 655/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1024 - accuracy: 0.9619 - fscore: 0.9627 - val_loss: 0.2723 - val_accuracy: 0.8916 - val_fscore: 0.8883 - lr: 2.2877e-05\n",
            "Epoch 656/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1036 - accuracy: 0.9610 - fscore: 0.9602 - val_loss: 0.2786 - val_accuracy: 0.8793 - val_fscore: 0.9024 - lr: 2.2877e-05\n",
            "Epoch 657/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1042 - accuracy: 0.9624 - fscore: 0.9610 - val_loss: 0.2716 - val_accuracy: 0.8885 - val_fscore: 0.8898 - lr: 2.2877e-05\n",
            "Epoch 658/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1040 - accuracy: 0.9606 - fscore: 0.9590 - val_loss: 0.2822 - val_accuracy: 0.8885 - val_fscore: 0.8804 - lr: 2.2877e-05\n",
            "Epoch 659/700\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.1026 - accuracy: 0.9615 - fscore: 0.9595 - val_loss: 0.2831 - val_accuracy: 0.8916 - val_fscore: 0.9064 - lr: 2.2877e-05\n",
            "Epoch 660/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1029 - accuracy: 0.9619 - fscore: 0.9615 - val_loss: 0.2806 - val_accuracy: 0.8978 - val_fscore: 0.8898 - lr: 2.2877e-05\n",
            "Epoch 661/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1016 - accuracy: 0.9610 - fscore: 0.9600 - val_loss: 0.2871 - val_accuracy: 0.8885 - val_fscore: 0.8979 - lr: 2.2877e-05\n",
            "Epoch 662/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1031 - accuracy: 0.9597 - fscore: 0.9558 - val_loss: 0.2837 - val_accuracy: 0.9040 - val_fscore: 0.8949 - lr: 2.2877e-05\n",
            "Epoch 663/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1031 - accuracy: 0.9637 - fscore: 0.9629 - val_loss: 0.2818 - val_accuracy: 0.8916 - val_fscore: 0.9021 - lr: 2.2877e-05\n",
            "Epoch 664/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1031 - accuracy: 0.9633 - fscore: 0.9616 - val_loss: 0.2673 - val_accuracy: 0.8916 - val_fscore: 0.9019 - lr: 2.2877e-05\n",
            "Epoch 665/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1033 - accuracy: 0.9606 - fscore: 0.9601 - val_loss: 0.2784 - val_accuracy: 0.8978 - val_fscore: 0.9050 - lr: 2.2877e-05\n",
            "Epoch 666/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1025 - accuracy: 0.9602 - fscore: 0.9592 - val_loss: 0.3756 - val_accuracy: 0.8854 - val_fscore: 0.8843 - lr: 2.2877e-05\n",
            "Epoch 667/700\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.1069 - accuracy: 0.9588 - fscore: 0.9574 - val_loss: 0.2709 - val_accuracy: 0.8978 - val_fscore: 0.9034 - lr: 2.2877e-05\n",
            "Epoch 668/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1032 - accuracy: 0.9615 - fscore: 0.9607 - val_loss: 0.2675 - val_accuracy: 0.8916 - val_fscore: 0.8965 - lr: 2.2877e-05\n",
            "Epoch 669/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1000 - accuracy: 0.9619 - fscore: 0.9625 - val_loss: 0.2927 - val_accuracy: 0.8885 - val_fscore: 0.8917 - lr: 2.2877e-05\n",
            "Epoch 670/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1023 - accuracy: 0.9633 - fscore: 0.9597 - val_loss: 0.2884 - val_accuracy: 0.8885 - val_fscore: 0.8943 - lr: 2.2877e-05\n",
            "Epoch 671/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1020 - accuracy: 0.9615 - fscore: 0.9619 - val_loss: 0.2809 - val_accuracy: 0.8854 - val_fscore: 0.8825 - lr: 2.2877e-05\n",
            "Epoch 672/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1018 - accuracy: 0.9633 - fscore: 0.9604 - val_loss: 0.4665 - val_accuracy: 0.8700 - val_fscore: 0.8777 - lr: 2.2877e-05\n",
            "Epoch 673/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1099 - accuracy: 0.9606 - fscore: 0.9607 - val_loss: 0.2794 - val_accuracy: 0.9009 - val_fscore: 0.9060 - lr: 2.0589e-05\n",
            "Epoch 674/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1008 - accuracy: 0.9646 - fscore: 0.9582 - val_loss: 0.4014 - val_accuracy: 0.8824 - val_fscore: 0.8732 - lr: 2.0589e-05\n",
            "Epoch 675/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1017 - accuracy: 0.9641 - fscore: 0.9631 - val_loss: 0.2691 - val_accuracy: 0.8947 - val_fscore: 0.9044 - lr: 2.0589e-05\n",
            "Epoch 676/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1005 - accuracy: 0.9610 - fscore: 0.9618 - val_loss: 0.2925 - val_accuracy: 0.8947 - val_fscore: 0.8947 - lr: 2.0589e-05\n",
            "Epoch 677/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1010 - accuracy: 0.9624 - fscore: 0.9611 - val_loss: 0.2955 - val_accuracy: 0.8947 - val_fscore: 0.8929 - lr: 2.0589e-05\n",
            "Epoch 678/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1012 - accuracy: 0.9619 - fscore: 0.9618 - val_loss: 0.2825 - val_accuracy: 0.8947 - val_fscore: 0.9036 - lr: 2.0589e-05\n",
            "Epoch 679/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.0990 - accuracy: 0.9624 - fscore: 0.9632 - val_loss: 0.2737 - val_accuracy: 0.8916 - val_fscore: 0.9028 - lr: 2.0589e-05\n",
            "Epoch 680/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1000 - accuracy: 0.9646 - fscore: 0.9621 - val_loss: 0.2818 - val_accuracy: 0.8947 - val_fscore: 0.8989 - lr: 2.0589e-05\n",
            "Epoch 681/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.0997 - accuracy: 0.9610 - fscore: 0.9589 - val_loss: 0.2677 - val_accuracy: 0.8854 - val_fscore: 0.8894 - lr: 2.0589e-05\n",
            "Epoch 682/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.0993 - accuracy: 0.9650 - fscore: 0.9636 - val_loss: 0.2853 - val_accuracy: 0.8978 - val_fscore: 0.8979 - lr: 2.0589e-05\n",
            "Epoch 683/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.0997 - accuracy: 0.9624 - fscore: 0.9610 - val_loss: 0.2743 - val_accuracy: 0.8947 - val_fscore: 0.9063 - lr: 2.0589e-05\n",
            "Epoch 684/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1009 - accuracy: 0.9650 - fscore: 0.9635 - val_loss: 0.2745 - val_accuracy: 0.8916 - val_fscore: 0.9002 - lr: 2.0589e-05\n",
            "Epoch 685/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.0994 - accuracy: 0.9624 - fscore: 0.9609 - val_loss: 0.3286 - val_accuracy: 0.8731 - val_fscore: 0.8848 - lr: 2.0589e-05\n",
            "Epoch 686/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1008 - accuracy: 0.9637 - fscore: 0.9621 - val_loss: 0.2756 - val_accuracy: 0.8885 - val_fscore: 0.8846 - lr: 2.0589e-05\n",
            "Epoch 687/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.0999 - accuracy: 0.9624 - fscore: 0.9601 - val_loss: 0.2747 - val_accuracy: 0.9040 - val_fscore: 0.9155 - lr: 2.0589e-05\n",
            "Epoch 688/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1004 - accuracy: 0.9637 - fscore: 0.9624 - val_loss: 0.2617 - val_accuracy: 0.9009 - val_fscore: 0.8983 - lr: 2.0589e-05\n",
            "Epoch 689/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.1001 - accuracy: 0.9619 - fscore: 0.9604 - val_loss: 0.2715 - val_accuracy: 0.8978 - val_fscore: 0.9084 - lr: 2.0589e-05\n",
            "Epoch 690/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1004 - accuracy: 0.9606 - fscore: 0.9608 - val_loss: 0.2700 - val_accuracy: 0.9040 - val_fscore: 0.9117 - lr: 2.0589e-05\n",
            "Epoch 691/700\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.0988 - accuracy: 0.9646 - fscore: 0.9633 - val_loss: 0.2992 - val_accuracy: 0.8947 - val_fscore: 0.8985 - lr: 2.0589e-05\n",
            "Epoch 692/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.1003 - accuracy: 0.9579 - fscore: 0.9597 - val_loss: 0.2906 - val_accuracy: 0.8854 - val_fscore: 0.8924 - lr: 2.0589e-05\n",
            "Epoch 693/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.0985 - accuracy: 0.9619 - fscore: 0.9620 - val_loss: 0.2718 - val_accuracy: 0.8824 - val_fscore: 0.8995 - lr: 1.8530e-05\n",
            "Epoch 694/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.0974 - accuracy: 0.9641 - fscore: 0.9630 - val_loss: 0.2905 - val_accuracy: 0.8916 - val_fscore: 0.8984 - lr: 1.8530e-05\n",
            "Epoch 695/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.0975 - accuracy: 0.9655 - fscore: 0.9615 - val_loss: 0.2717 - val_accuracy: 0.9009 - val_fscore: 0.9110 - lr: 1.8530e-05\n",
            "Epoch 696/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.0983 - accuracy: 0.9641 - fscore: 0.9637 - val_loss: 0.2674 - val_accuracy: 0.8916 - val_fscore: 0.9080 - lr: 1.8530e-05\n",
            "Epoch 697/700\n",
            "142/142 [==============================] - 2s 16ms/step - loss: 0.0983 - accuracy: 0.9615 - fscore: 0.9604 - val_loss: 0.2842 - val_accuracy: 0.8793 - val_fscore: 0.8938 - lr: 1.8530e-05\n",
            "Epoch 698/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.0982 - accuracy: 0.9650 - fscore: 0.9637 - val_loss: 0.2958 - val_accuracy: 0.8885 - val_fscore: 0.8977 - lr: 1.8530e-05\n",
            "Epoch 699/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.0974 - accuracy: 0.9655 - fscore: 0.9651 - val_loss: 0.2793 - val_accuracy: 0.8854 - val_fscore: 0.8965 - lr: 1.8530e-05\n",
            "Epoch 700/700\n",
            "142/142 [==============================] - 2s 17ms/step - loss: 0.0976 - accuracy: 0.9646 - fscore: 0.9621 - val_loss: 0.2746 - val_accuracy: 0.8885 - val_fscore: 0.8990 - lr: 1.8530e-05\n"
          ]
        }
      ],
      "source": [
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "mcp_save = ModelCheckpoint('model/rnnmodel.h5', save_best_only=True, monitor='val_loss', mode='min') #MODEL SAVE HERE!!!!!!!!!!!!\n",
        "rnn_hist = model.fit(x_trainrnn,y_train,batch_size=16, epochs=700, validation_data=(x_valrnn, y_val), callbacks=[mcp_save, lr_reduce])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLmWc3jdHs_o"
      },
      "outputs": [],
      "source": [
        "# Saving the model.json deneme\n",
        "model_json = model.to_json()\n",
        "with open(\"modelrnn.json\", \"w\") as json_file: #BÄ°R DE BÃ–YLE BÄ°R MODEL SAVE VAR AMA YUKARDAKÄ°YLE FARKI NE ANLAMADIM\n",
        "    json_file.write(model_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcPBlixTFKAD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ce00d520-d0c8-46e2-c643-dae5515534b3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "plt.plot(rnn_hist.history['loss'])\n",
        "plt.plot(rnn_hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaVWukwF-6to"
      },
      "outputs": [],
      "source": [
        "test_predicted = model.predict(x_testrnn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names, \n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "        \n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "caH6BmshnwS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(y_test.argmax(axis=1), test_predicted.argmax(axis=1))\n",
        "print_confusion_matrix(c, observed_emotions)"
      ],
      "metadata": {
        "id": "CwCOhAIjndmC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "6f9e2fe6-5601-4388-adc9-d92be56bbed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_testrnn, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "print(precision(test_predicted, y_test))\n",
        "print(recall(test_predicted, y_test))\n",
        "print(fscore(test_predicted, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCIcehzRo5cH",
        "outputId": "b417bf57-b3eb-4660-b8c3-8b2f05ab3610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 90.71%\n",
            "tf.Tensor(0.9009288, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9122257, shape=(), dtype=float32)\n",
            "tf.Tensor(0.90654206, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN adam"
      ],
      "metadata": {
        "id": "9TEI7tsrPfLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_units = 35\n",
        "input_shape=(X_train.shape[1],1)\n",
        "dense_units = 6\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(keras.layers.SimpleRNN(hidden_units, input_shape=input_shape,activation='relu'))\n",
        "model2.add(Dense(units=dense_units, activation='softmax'))\n",
        "opt2 = tensorflow.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=opt2, metrics=['accuracy', fscore])\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "N4Lzfk1vPhZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a427498-affd-4080-df52-50e729e13cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 35)                1295      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 216       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,511\n",
            "Trainable params: 1,511\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_reduce2 = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "\n",
        "rnn_hist2 = model2.fit(x_trainrnn,y_train,batch_size=16, epochs=700, validation_data=(x_valrnn, y_val))"
      ],
      "metadata": {
        "id": "jYE_Fp2VPkv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b41c8c-55f1-40c9-9a33-cc016d434fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "142/142 [==============================] - 3s 13ms/step - loss: 2.7484 - accuracy: 0.1678 - fscore: 0.1014 - val_loss: 2.4382 - val_accuracy: 0.1579 - val_fscore: 0.0805\n",
            "Epoch 2/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 2.3527 - accuracy: 0.1797 - fscore: 0.0722 - val_loss: 2.1415 - val_accuracy: 0.1981 - val_fscore: 0.0480\n",
            "Epoch 3/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 2.0976 - accuracy: 0.2098 - fscore: 0.0291 - val_loss: 1.9355 - val_accuracy: 0.2229 - val_fscore: 0.0330\n",
            "Epoch 4/700\n",
            "142/142 [==============================] - 1s 9ms/step - loss: 1.9075 - accuracy: 0.2603 - fscore: 0.0345 - val_loss: 1.7848 - val_accuracy: 0.2817 - val_fscore: 0.0380\n",
            "Epoch 5/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 1.7609 - accuracy: 0.3046 - fscore: 0.0577 - val_loss: 1.6765 - val_accuracy: 0.3189 - val_fscore: 0.0866\n",
            "Epoch 6/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 1.6494 - accuracy: 0.3276 - fscore: 0.1330 - val_loss: 1.5927 - val_accuracy: 0.3406 - val_fscore: 0.1184\n",
            "Epoch 7/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 1.5598 - accuracy: 0.3440 - fscore: 0.1704 - val_loss: 1.5224 - val_accuracy: 0.3437 - val_fscore: 0.1668\n",
            "Epoch 8/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 1.4876 - accuracy: 0.3475 - fscore: 0.2086 - val_loss: 1.4672 - val_accuracy: 0.3622 - val_fscore: 0.1933\n",
            "Epoch 9/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 1.4323 - accuracy: 0.3758 - fscore: 0.2400 - val_loss: 1.4160 - val_accuracy: 0.3963 - val_fscore: 0.2346\n",
            "Epoch 10/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 1.3838 - accuracy: 0.4046 - fscore: 0.2595 - val_loss: 1.3688 - val_accuracy: 0.4087 - val_fscore: 0.2493\n",
            "Epoch 11/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 1.3358 - accuracy: 0.4405 - fscore: 0.2781 - val_loss: 1.3227 - val_accuracy: 0.4892 - val_fscore: 0.2719\n",
            "Epoch 12/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 1.2898 - accuracy: 0.4847 - fscore: 0.3164 - val_loss: 1.2715 - val_accuracy: 0.5201 - val_fscore: 0.2992\n",
            "Epoch 13/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 1.2382 - accuracy: 0.5232 - fscore: 0.3585 - val_loss: 1.2221 - val_accuracy: 0.5728 - val_fscore: 0.3229\n",
            "Epoch 14/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 1.1899 - accuracy: 0.5547 - fscore: 0.4095 - val_loss: 1.1792 - val_accuracy: 0.5975 - val_fscore: 0.3707\n",
            "Epoch 15/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 1.1430 - accuracy: 0.5750 - fscore: 0.4509 - val_loss: 1.1388 - val_accuracy: 0.6037 - val_fscore: 0.4327\n",
            "Epoch 16/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 1.1105 - accuracy: 0.5892 - fscore: 0.4895 - val_loss: 1.1059 - val_accuracy: 0.6099 - val_fscore: 0.4729\n",
            "Epoch 17/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 1.0791 - accuracy: 0.6056 - fscore: 0.5042 - val_loss: 1.0726 - val_accuracy: 0.6223 - val_fscore: 0.4986\n",
            "Epoch 18/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 1.0404 - accuracy: 0.6166 - fscore: 0.5328 - val_loss: 1.0401 - val_accuracy: 0.6285 - val_fscore: 0.5342\n",
            "Epoch 19/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 1.0105 - accuracy: 0.6295 - fscore: 0.5453 - val_loss: 1.0439 - val_accuracy: 0.6285 - val_fscore: 0.5468\n",
            "Epoch 20/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.9852 - accuracy: 0.6361 - fscore: 0.5740 - val_loss: 0.9850 - val_accuracy: 0.6471 - val_fscore: 0.5461\n",
            "Epoch 21/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.9593 - accuracy: 0.6383 - fscore: 0.5819 - val_loss: 0.9577 - val_accuracy: 0.6625 - val_fscore: 0.5750\n",
            "Epoch 22/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.9345 - accuracy: 0.6534 - fscore: 0.5974 - val_loss: 0.9312 - val_accuracy: 0.6656 - val_fscore: 0.5780\n",
            "Epoch 23/700\n",
            "142/142 [==============================] - 1s 11ms/step - loss: 0.9070 - accuracy: 0.6609 - fscore: 0.6148 - val_loss: 0.9194 - val_accuracy: 0.6780 - val_fscore: 0.6112\n",
            "Epoch 24/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.8899 - accuracy: 0.6649 - fscore: 0.6237 - val_loss: 0.8943 - val_accuracy: 0.6656 - val_fscore: 0.6168\n",
            "Epoch 25/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.8620 - accuracy: 0.6799 - fscore: 0.6508 - val_loss: 0.8645 - val_accuracy: 0.6842 - val_fscore: 0.6357\n",
            "Epoch 26/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.8372 - accuracy: 0.6999 - fscore: 0.6530 - val_loss: 0.8547 - val_accuracy: 0.6687 - val_fscore: 0.6526\n",
            "Epoch 27/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.8168 - accuracy: 0.6994 - fscore: 0.6686 - val_loss: 0.8342 - val_accuracy: 0.7059 - val_fscore: 0.6567\n",
            "Epoch 28/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.8023 - accuracy: 0.7056 - fscore: 0.6772 - val_loss: 0.8151 - val_accuracy: 0.6842 - val_fscore: 0.6697\n",
            "Epoch 29/700\n",
            "142/142 [==============================] - 3s 20ms/step - loss: 0.7753 - accuracy: 0.7167 - fscore: 0.6863 - val_loss: 0.8048 - val_accuracy: 0.7121 - val_fscore: 0.6753\n",
            "Epoch 30/700\n",
            "142/142 [==============================] - 3s 19ms/step - loss: 0.7557 - accuracy: 0.7242 - fscore: 0.6942 - val_loss: 0.7898 - val_accuracy: 0.6966 - val_fscore: 0.6867\n",
            "Epoch 31/700\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.7403 - accuracy: 0.7251 - fscore: 0.7047 - val_loss: 0.7864 - val_accuracy: 0.7121 - val_fscore: 0.6839\n",
            "Epoch 32/700\n",
            "142/142 [==============================] - 2s 15ms/step - loss: 0.7217 - accuracy: 0.7331 - fscore: 0.7149 - val_loss: 0.7602 - val_accuracy: 0.7276 - val_fscore: 0.6864\n",
            "Epoch 33/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.7146 - accuracy: 0.7344 - fscore: 0.7226 - val_loss: 0.8252 - val_accuracy: 0.6811 - val_fscore: 0.6618\n",
            "Epoch 34/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.6972 - accuracy: 0.7446 - fscore: 0.7302 - val_loss: 0.7415 - val_accuracy: 0.7245 - val_fscore: 0.7110\n",
            "Epoch 35/700\n",
            "142/142 [==============================] - 1s 11ms/step - loss: 0.6900 - accuracy: 0.7379 - fscore: 0.7363 - val_loss: 0.7175 - val_accuracy: 0.7430 - val_fscore: 0.7156\n",
            "Epoch 36/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.6747 - accuracy: 0.7490 - fscore: 0.7417 - val_loss: 0.7501 - val_accuracy: 0.7214 - val_fscore: 0.7051\n",
            "Epoch 37/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.6563 - accuracy: 0.7552 - fscore: 0.7547 - val_loss: 0.7144 - val_accuracy: 0.7337 - val_fscore: 0.7096\n",
            "Epoch 38/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.6441 - accuracy: 0.7632 - fscore: 0.7628 - val_loss: 0.6861 - val_accuracy: 0.7585 - val_fscore: 0.7271\n",
            "Epoch 39/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.6325 - accuracy: 0.7623 - fscore: 0.7654 - val_loss: 0.6699 - val_accuracy: 0.7461 - val_fscore: 0.7368\n",
            "Epoch 40/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.6184 - accuracy: 0.7658 - fscore: 0.7598 - val_loss: 0.6585 - val_accuracy: 0.7616 - val_fscore: 0.7419\n",
            "Epoch 41/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.6034 - accuracy: 0.7804 - fscore: 0.7703 - val_loss: 0.6535 - val_accuracy: 0.7554 - val_fscore: 0.7409\n",
            "Epoch 42/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.5936 - accuracy: 0.7826 - fscore: 0.7724 - val_loss: 0.6556 - val_accuracy: 0.7585 - val_fscore: 0.7561\n",
            "Epoch 43/700\n",
            "142/142 [==============================] - 1s 9ms/step - loss: 0.5777 - accuracy: 0.7818 - fscore: 0.7795 - val_loss: 0.6270 - val_accuracy: 0.7647 - val_fscore: 0.7699\n",
            "Epoch 44/700\n",
            "142/142 [==============================] - 1s 9ms/step - loss: 0.5720 - accuracy: 0.7880 - fscore: 0.7847 - val_loss: 0.6555 - val_accuracy: 0.7430 - val_fscore: 0.7587\n",
            "Epoch 45/700\n",
            "142/142 [==============================] - 1s 9ms/step - loss: 0.5587 - accuracy: 0.7924 - fscore: 0.7857 - val_loss: 0.6040 - val_accuracy: 0.7616 - val_fscore: 0.7844\n",
            "Epoch 46/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.5487 - accuracy: 0.7902 - fscore: 0.7914 - val_loss: 0.6035 - val_accuracy: 0.7802 - val_fscore: 0.7779\n",
            "Epoch 47/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.5406 - accuracy: 0.7942 - fscore: 0.7935 - val_loss: 0.6566 - val_accuracy: 0.7368 - val_fscore: 0.7363\n",
            "Epoch 48/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.5320 - accuracy: 0.7973 - fscore: 0.7966 - val_loss: 0.5665 - val_accuracy: 0.7802 - val_fscore: 0.7904\n",
            "Epoch 49/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.5213 - accuracy: 0.8097 - fscore: 0.7982 - val_loss: 0.5937 - val_accuracy: 0.7771 - val_fscore: 0.7918\n",
            "Epoch 50/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.5138 - accuracy: 0.8057 - fscore: 0.8082 - val_loss: 0.5725 - val_accuracy: 0.7988 - val_fscore: 0.7980\n",
            "Epoch 51/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.5100 - accuracy: 0.8043 - fscore: 0.8050 - val_loss: 0.5634 - val_accuracy: 0.7895 - val_fscore: 0.7922\n",
            "Epoch 52/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.5005 - accuracy: 0.8088 - fscore: 0.8101 - val_loss: 0.5486 - val_accuracy: 0.7988 - val_fscore: 0.8087\n",
            "Epoch 53/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4958 - accuracy: 0.8105 - fscore: 0.8066 - val_loss: 0.5277 - val_accuracy: 0.7957 - val_fscore: 0.8088\n",
            "Epoch 54/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4899 - accuracy: 0.8167 - fscore: 0.8158 - val_loss: 0.6008 - val_accuracy: 0.7833 - val_fscore: 0.7814\n",
            "Epoch 55/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4910 - accuracy: 0.8092 - fscore: 0.8127 - val_loss: 0.5642 - val_accuracy: 0.8019 - val_fscore: 0.8042\n",
            "Epoch 56/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4786 - accuracy: 0.8176 - fscore: 0.8200 - val_loss: 0.5291 - val_accuracy: 0.7864 - val_fscore: 0.7932\n",
            "Epoch 57/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4714 - accuracy: 0.8158 - fscore: 0.8203 - val_loss: 0.5355 - val_accuracy: 0.8019 - val_fscore: 0.8065\n",
            "Epoch 58/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4691 - accuracy: 0.8194 - fscore: 0.8190 - val_loss: 0.5496 - val_accuracy: 0.7802 - val_fscore: 0.7951\n",
            "Epoch 59/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4617 - accuracy: 0.8194 - fscore: 0.8226 - val_loss: 0.5264 - val_accuracy: 0.7988 - val_fscore: 0.8022\n",
            "Epoch 60/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4549 - accuracy: 0.8229 - fscore: 0.8296 - val_loss: 0.4954 - val_accuracy: 0.8111 - val_fscore: 0.8199\n",
            "Epoch 61/700\n",
            "142/142 [==============================] - 1s 11ms/step - loss: 0.4466 - accuracy: 0.8274 - fscore: 0.8283 - val_loss: 0.5000 - val_accuracy: 0.8050 - val_fscore: 0.8152\n",
            "Epoch 62/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4442 - accuracy: 0.8265 - fscore: 0.8307 - val_loss: 0.5106 - val_accuracy: 0.7957 - val_fscore: 0.8015\n",
            "Epoch 63/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.4434 - accuracy: 0.8265 - fscore: 0.8268 - val_loss: 0.4820 - val_accuracy: 0.8173 - val_fscore: 0.8220\n",
            "Epoch 64/700\n",
            "142/142 [==============================] - 1s 11ms/step - loss: 0.4351 - accuracy: 0.8300 - fscore: 0.8309 - val_loss: 0.4898 - val_accuracy: 0.8235 - val_fscore: 0.8203\n",
            "Epoch 65/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4434 - accuracy: 0.8225 - fscore: 0.8243 - val_loss: 0.5019 - val_accuracy: 0.8019 - val_fscore: 0.8129\n",
            "Epoch 66/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4299 - accuracy: 0.8269 - fscore: 0.8354 - val_loss: 0.5004 - val_accuracy: 0.8173 - val_fscore: 0.8130\n",
            "Epoch 67/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4290 - accuracy: 0.8313 - fscore: 0.8343 - val_loss: 0.4893 - val_accuracy: 0.8111 - val_fscore: 0.8180\n",
            "Epoch 68/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4244 - accuracy: 0.8305 - fscore: 0.8388 - val_loss: 0.4756 - val_accuracy: 0.8235 - val_fscore: 0.8294\n",
            "Epoch 69/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4141 - accuracy: 0.8362 - fscore: 0.8424 - val_loss: 0.5111 - val_accuracy: 0.7988 - val_fscore: 0.8093\n",
            "Epoch 70/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4221 - accuracy: 0.8305 - fscore: 0.8345 - val_loss: 0.4532 - val_accuracy: 0.8173 - val_fscore: 0.8284\n",
            "Epoch 71/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4102 - accuracy: 0.8362 - fscore: 0.8401 - val_loss: 0.4940 - val_accuracy: 0.8080 - val_fscore: 0.8110\n",
            "Epoch 72/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4134 - accuracy: 0.8371 - fscore: 0.8379 - val_loss: 0.5664 - val_accuracy: 0.7802 - val_fscore: 0.7930\n",
            "Epoch 73/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4113 - accuracy: 0.8367 - fscore: 0.8388 - val_loss: 0.4737 - val_accuracy: 0.8235 - val_fscore: 0.8182\n",
            "Epoch 74/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4063 - accuracy: 0.8384 - fscore: 0.8401 - val_loss: 0.4738 - val_accuracy: 0.8421 - val_fscore: 0.8299\n",
            "Epoch 75/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.3935 - accuracy: 0.8358 - fscore: 0.8405 - val_loss: 0.5098 - val_accuracy: 0.7957 - val_fscore: 0.8080\n",
            "Epoch 76/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.4055 - accuracy: 0.8380 - fscore: 0.8385 - val_loss: 0.4665 - val_accuracy: 0.8297 - val_fscore: 0.8330\n",
            "Epoch 77/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3922 - accuracy: 0.8429 - fscore: 0.8440 - val_loss: 0.4530 - val_accuracy: 0.8297 - val_fscore: 0.8408\n",
            "Epoch 78/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3918 - accuracy: 0.8411 - fscore: 0.8509 - val_loss: 0.4596 - val_accuracy: 0.8328 - val_fscore: 0.8261\n",
            "Epoch 79/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3835 - accuracy: 0.8459 - fscore: 0.8445 - val_loss: 0.4998 - val_accuracy: 0.8111 - val_fscore: 0.8102\n",
            "Epoch 80/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3890 - accuracy: 0.8389 - fscore: 0.8483 - val_loss: 0.4825 - val_accuracy: 0.8111 - val_fscore: 0.8120\n",
            "Epoch 81/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3826 - accuracy: 0.8455 - fscore: 0.8476 - val_loss: 0.4877 - val_accuracy: 0.8173 - val_fscore: 0.8107\n",
            "Epoch 82/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3992 - accuracy: 0.8380 - fscore: 0.8416 - val_loss: 0.4485 - val_accuracy: 0.8359 - val_fscore: 0.8283\n",
            "Epoch 83/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3862 - accuracy: 0.8406 - fscore: 0.8410 - val_loss: 0.4504 - val_accuracy: 0.8421 - val_fscore: 0.8360\n",
            "Epoch 84/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3729 - accuracy: 0.8535 - fscore: 0.8529 - val_loss: 0.4436 - val_accuracy: 0.8421 - val_fscore: 0.8307\n",
            "Epoch 85/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3740 - accuracy: 0.8495 - fscore: 0.8483 - val_loss: 0.4592 - val_accuracy: 0.8328 - val_fscore: 0.8352\n",
            "Epoch 86/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3637 - accuracy: 0.8499 - fscore: 0.8545 - val_loss: 0.4512 - val_accuracy: 0.8235 - val_fscore: 0.8352\n",
            "Epoch 87/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3702 - accuracy: 0.8517 - fscore: 0.8536 - val_loss: 0.4713 - val_accuracy: 0.8204 - val_fscore: 0.8267\n",
            "Epoch 88/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3704 - accuracy: 0.8477 - fscore: 0.8531 - val_loss: 0.4419 - val_accuracy: 0.8545 - val_fscore: 0.8394\n",
            "Epoch 89/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3603 - accuracy: 0.8526 - fscore: 0.8575 - val_loss: 0.4803 - val_accuracy: 0.8204 - val_fscore: 0.8281\n",
            "Epoch 90/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.3624 - accuracy: 0.8495 - fscore: 0.8547 - val_loss: 0.4322 - val_accuracy: 0.8452 - val_fscore: 0.8370\n",
            "Epoch 91/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.3543 - accuracy: 0.8535 - fscore: 0.8575 - val_loss: 0.4466 - val_accuracy: 0.8235 - val_fscore: 0.8295\n",
            "Epoch 92/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.3503 - accuracy: 0.8597 - fscore: 0.8597 - val_loss: 0.4408 - val_accuracy: 0.8359 - val_fscore: 0.8275\n",
            "Epoch 93/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.3469 - accuracy: 0.8561 - fscore: 0.8592 - val_loss: 0.4470 - val_accuracy: 0.8173 - val_fscore: 0.8314\n",
            "Epoch 94/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3566 - accuracy: 0.8570 - fscore: 0.8566 - val_loss: 0.4515 - val_accuracy: 0.8235 - val_fscore: 0.8159\n",
            "Epoch 95/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3463 - accuracy: 0.8592 - fscore: 0.8639 - val_loss: 0.4289 - val_accuracy: 0.8421 - val_fscore: 0.8305\n",
            "Epoch 96/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.3380 - accuracy: 0.8592 - fscore: 0.8655 - val_loss: 0.4335 - val_accuracy: 0.8297 - val_fscore: 0.8460\n",
            "Epoch 97/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.3448 - accuracy: 0.8548 - fscore: 0.8606 - val_loss: 0.4745 - val_accuracy: 0.8235 - val_fscore: 0.8134\n",
            "Epoch 98/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3406 - accuracy: 0.8583 - fscore: 0.8629 - val_loss: 0.4296 - val_accuracy: 0.8328 - val_fscore: 0.8263\n",
            "Epoch 99/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3413 - accuracy: 0.8579 - fscore: 0.8606 - val_loss: 0.4267 - val_accuracy: 0.8421 - val_fscore: 0.8249\n",
            "Epoch 100/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3347 - accuracy: 0.8583 - fscore: 0.8644 - val_loss: 0.4588 - val_accuracy: 0.8266 - val_fscore: 0.8351\n",
            "Epoch 101/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3368 - accuracy: 0.8583 - fscore: 0.8683 - val_loss: 0.4394 - val_accuracy: 0.8173 - val_fscore: 0.8305\n",
            "Epoch 102/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.3418 - accuracy: 0.8566 - fscore: 0.8630 - val_loss: 0.4025 - val_accuracy: 0.8607 - val_fscore: 0.8435\n",
            "Epoch 103/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.3260 - accuracy: 0.8681 - fscore: 0.8677 - val_loss: 0.4348 - val_accuracy: 0.8204 - val_fscore: 0.8243\n",
            "Epoch 104/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.3326 - accuracy: 0.8632 - fscore: 0.8691 - val_loss: 0.4560 - val_accuracy: 0.8297 - val_fscore: 0.8225\n",
            "Epoch 105/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.3271 - accuracy: 0.8637 - fscore: 0.8692 - val_loss: 0.4451 - val_accuracy: 0.8452 - val_fscore: 0.8321\n",
            "Epoch 106/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3280 - accuracy: 0.8632 - fscore: 0.8623 - val_loss: 0.4387 - val_accuracy: 0.8297 - val_fscore: 0.8253\n",
            "Epoch 107/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.3238 - accuracy: 0.8645 - fscore: 0.8671 - val_loss: 0.4823 - val_accuracy: 0.8142 - val_fscore: 0.8187\n",
            "Epoch 108/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3327 - accuracy: 0.8632 - fscore: 0.8648 - val_loss: 0.4411 - val_accuracy: 0.8235 - val_fscore: 0.8219\n",
            "Epoch 109/700\n",
            "142/142 [==============================] - 1s 9ms/step - loss: 0.3343 - accuracy: 0.8637 - fscore: 0.8685 - val_loss: 0.4220 - val_accuracy: 0.8421 - val_fscore: 0.8446\n",
            "Epoch 110/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3149 - accuracy: 0.8659 - fscore: 0.8708 - val_loss: 0.4316 - val_accuracy: 0.8297 - val_fscore: 0.8181\n",
            "Epoch 111/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3197 - accuracy: 0.8725 - fscore: 0.8736 - val_loss: 0.4571 - val_accuracy: 0.8266 - val_fscore: 0.8359\n",
            "Epoch 112/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3154 - accuracy: 0.8707 - fscore: 0.8730 - val_loss: 0.4021 - val_accuracy: 0.8452 - val_fscore: 0.8513\n",
            "Epoch 113/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3082 - accuracy: 0.8778 - fscore: 0.8778 - val_loss: 0.4179 - val_accuracy: 0.8390 - val_fscore: 0.8418\n",
            "Epoch 114/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3159 - accuracy: 0.8663 - fscore: 0.8717 - val_loss: 0.4138 - val_accuracy: 0.8390 - val_fscore: 0.8460\n",
            "Epoch 115/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3182 - accuracy: 0.8659 - fscore: 0.8699 - val_loss: 0.4658 - val_accuracy: 0.8173 - val_fscore: 0.8222\n",
            "Epoch 116/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3105 - accuracy: 0.8769 - fscore: 0.8755 - val_loss: 0.4020 - val_accuracy: 0.8390 - val_fscore: 0.8484\n",
            "Epoch 117/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.3021 - accuracy: 0.8756 - fscore: 0.8799 - val_loss: 0.4574 - val_accuracy: 0.8235 - val_fscore: 0.8243\n",
            "Epoch 118/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3047 - accuracy: 0.8800 - fscore: 0.8826 - val_loss: 0.4041 - val_accuracy: 0.8421 - val_fscore: 0.8394\n",
            "Epoch 119/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3032 - accuracy: 0.8730 - fscore: 0.8764 - val_loss: 0.3886 - val_accuracy: 0.8421 - val_fscore: 0.8454\n",
            "Epoch 120/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3021 - accuracy: 0.8747 - fscore: 0.8758 - val_loss: 0.4066 - val_accuracy: 0.8452 - val_fscore: 0.8479\n",
            "Epoch 121/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2960 - accuracy: 0.8734 - fscore: 0.8792 - val_loss: 0.4162 - val_accuracy: 0.8359 - val_fscore: 0.8321\n",
            "Epoch 122/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2999 - accuracy: 0.8827 - fscore: 0.8811 - val_loss: 0.3983 - val_accuracy: 0.8421 - val_fscore: 0.8394\n",
            "Epoch 123/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2917 - accuracy: 0.8836 - fscore: 0.8836 - val_loss: 0.4004 - val_accuracy: 0.8452 - val_fscore: 0.8458\n",
            "Epoch 124/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3068 - accuracy: 0.8756 - fscore: 0.8746 - val_loss: 0.3867 - val_accuracy: 0.8545 - val_fscore: 0.8478\n",
            "Epoch 125/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2982 - accuracy: 0.8796 - fscore: 0.8830 - val_loss: 0.4211 - val_accuracy: 0.8359 - val_fscore: 0.8396\n",
            "Epoch 126/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2885 - accuracy: 0.8778 - fscore: 0.8849 - val_loss: 0.4263 - val_accuracy: 0.8297 - val_fscore: 0.8328\n",
            "Epoch 127/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2865 - accuracy: 0.8845 - fscore: 0.8843 - val_loss: 0.3966 - val_accuracy: 0.8421 - val_fscore: 0.8385\n",
            "Epoch 128/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2955 - accuracy: 0.8805 - fscore: 0.8839 - val_loss: 0.3765 - val_accuracy: 0.8607 - val_fscore: 0.8604\n",
            "Epoch 129/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2858 - accuracy: 0.8845 - fscore: 0.8860 - val_loss: 0.4052 - val_accuracy: 0.8390 - val_fscore: 0.8306\n",
            "Epoch 130/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3086 - accuracy: 0.8743 - fscore: 0.8759 - val_loss: 0.4067 - val_accuracy: 0.8421 - val_fscore: 0.8269\n",
            "Epoch 131/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2867 - accuracy: 0.8818 - fscore: 0.8859 - val_loss: 0.4079 - val_accuracy: 0.8359 - val_fscore: 0.8325\n",
            "Epoch 132/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2825 - accuracy: 0.8822 - fscore: 0.8837 - val_loss: 0.3833 - val_accuracy: 0.8514 - val_fscore: 0.8373\n",
            "Epoch 133/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.3015 - accuracy: 0.8792 - fscore: 0.8805 - val_loss: 0.3985 - val_accuracy: 0.8390 - val_fscore: 0.8383\n",
            "Epoch 134/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2993 - accuracy: 0.8809 - fscore: 0.8786 - val_loss: 0.4058 - val_accuracy: 0.8483 - val_fscore: 0.8454\n",
            "Epoch 135/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2947 - accuracy: 0.8787 - fscore: 0.8763 - val_loss: 0.3802 - val_accuracy: 0.8514 - val_fscore: 0.8538\n",
            "Epoch 136/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2904 - accuracy: 0.8814 - fscore: 0.8834 - val_loss: 0.3903 - val_accuracy: 0.8452 - val_fscore: 0.8385\n",
            "Epoch 137/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2741 - accuracy: 0.8849 - fscore: 0.8887 - val_loss: 0.3856 - val_accuracy: 0.8421 - val_fscore: 0.8385\n",
            "Epoch 138/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2712 - accuracy: 0.8898 - fscore: 0.8899 - val_loss: 0.3975 - val_accuracy: 0.8328 - val_fscore: 0.8443\n",
            "Epoch 139/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2783 - accuracy: 0.8880 - fscore: 0.8880 - val_loss: 0.3782 - val_accuracy: 0.8452 - val_fscore: 0.8470\n",
            "Epoch 140/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2718 - accuracy: 0.8915 - fscore: 0.8926 - val_loss: 0.4054 - val_accuracy: 0.8483 - val_fscore: 0.8402\n",
            "Epoch 141/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2745 - accuracy: 0.8849 - fscore: 0.8874 - val_loss: 0.4753 - val_accuracy: 0.8235 - val_fscore: 0.8236\n",
            "Epoch 142/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2704 - accuracy: 0.8893 - fscore: 0.8854 - val_loss: 0.3856 - val_accuracy: 0.8514 - val_fscore: 0.8428\n",
            "Epoch 143/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2834 - accuracy: 0.8867 - fscore: 0.8830 - val_loss: 0.3772 - val_accuracy: 0.8483 - val_fscore: 0.8366\n",
            "Epoch 144/700\n",
            "142/142 [==============================] - 1s 11ms/step - loss: 0.2710 - accuracy: 0.8929 - fscore: 0.8935 - val_loss: 0.3736 - val_accuracy: 0.8514 - val_fscore: 0.8444\n",
            "Epoch 145/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2717 - accuracy: 0.8858 - fscore: 0.8874 - val_loss: 0.3673 - val_accuracy: 0.8545 - val_fscore: 0.8513\n",
            "Epoch 146/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2730 - accuracy: 0.8849 - fscore: 0.8861 - val_loss: 0.3790 - val_accuracy: 0.8607 - val_fscore: 0.8543\n",
            "Epoch 147/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2657 - accuracy: 0.8867 - fscore: 0.8919 - val_loss: 0.3679 - val_accuracy: 0.8576 - val_fscore: 0.8556\n",
            "Epoch 148/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2612 - accuracy: 0.8929 - fscore: 0.8929 - val_loss: 0.3796 - val_accuracy: 0.8607 - val_fscore: 0.8478\n",
            "Epoch 149/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2600 - accuracy: 0.8933 - fscore: 0.8920 - val_loss: 0.3816 - val_accuracy: 0.8576 - val_fscore: 0.8444\n",
            "Epoch 150/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2605 - accuracy: 0.8915 - fscore: 0.8914 - val_loss: 0.3806 - val_accuracy: 0.8452 - val_fscore: 0.8489\n",
            "Epoch 151/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2626 - accuracy: 0.8911 - fscore: 0.8929 - val_loss: 0.3699 - val_accuracy: 0.8421 - val_fscore: 0.8573\n",
            "Epoch 152/700\n",
            "142/142 [==============================] - 1s 11ms/step - loss: 0.2723 - accuracy: 0.8858 - fscore: 0.8893 - val_loss: 0.3976 - val_accuracy: 0.8545 - val_fscore: 0.8440\n",
            "Epoch 153/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2611 - accuracy: 0.8898 - fscore: 0.8883 - val_loss: 0.3685 - val_accuracy: 0.8483 - val_fscore: 0.8524\n",
            "Epoch 154/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2554 - accuracy: 0.8973 - fscore: 0.8967 - val_loss: 0.3682 - val_accuracy: 0.8607 - val_fscore: 0.8606\n",
            "Epoch 155/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2577 - accuracy: 0.8933 - fscore: 0.8936 - val_loss: 0.3855 - val_accuracy: 0.8452 - val_fscore: 0.8511\n",
            "Epoch 156/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2651 - accuracy: 0.8933 - fscore: 0.8897 - val_loss: 0.3618 - val_accuracy: 0.8483 - val_fscore: 0.8580\n",
            "Epoch 157/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2479 - accuracy: 0.8964 - fscore: 0.8957 - val_loss: 0.3581 - val_accuracy: 0.8576 - val_fscore: 0.8588\n",
            "Epoch 158/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2493 - accuracy: 0.8969 - fscore: 0.8987 - val_loss: 0.3682 - val_accuracy: 0.8638 - val_fscore: 0.8572\n",
            "Epoch 159/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2565 - accuracy: 0.8938 - fscore: 0.8972 - val_loss: 0.3633 - val_accuracy: 0.8638 - val_fscore: 0.8579\n",
            "Epoch 160/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2536 - accuracy: 0.8889 - fscore: 0.8910 - val_loss: 0.3662 - val_accuracy: 0.8638 - val_fscore: 0.8558\n",
            "Epoch 161/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2590 - accuracy: 0.8915 - fscore: 0.8920 - val_loss: 0.4085 - val_accuracy: 0.8483 - val_fscore: 0.8438\n",
            "Epoch 162/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2539 - accuracy: 0.8951 - fscore: 0.8928 - val_loss: 0.3689 - val_accuracy: 0.8545 - val_fscore: 0.8514\n",
            "Epoch 163/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2492 - accuracy: 0.8933 - fscore: 0.8966 - val_loss: 0.3707 - val_accuracy: 0.8390 - val_fscore: 0.8561\n",
            "Epoch 164/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2638 - accuracy: 0.8924 - fscore: 0.8932 - val_loss: 0.3731 - val_accuracy: 0.8483 - val_fscore: 0.8442\n",
            "Epoch 165/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2452 - accuracy: 0.9013 - fscore: 0.9025 - val_loss: 0.3534 - val_accuracy: 0.8607 - val_fscore: 0.8530\n",
            "Epoch 166/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2415 - accuracy: 0.9004 - fscore: 0.9012 - val_loss: 0.3872 - val_accuracy: 0.8545 - val_fscore: 0.8502\n",
            "Epoch 167/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2479 - accuracy: 0.9000 - fscore: 0.8983 - val_loss: 0.3595 - val_accuracy: 0.8669 - val_fscore: 0.8594\n",
            "Epoch 168/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2508 - accuracy: 0.8960 - fscore: 0.8975 - val_loss: 0.3604 - val_accuracy: 0.8607 - val_fscore: 0.8605\n",
            "Epoch 169/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2382 - accuracy: 0.9026 - fscore: 0.9007 - val_loss: 0.3550 - val_accuracy: 0.8576 - val_fscore: 0.8583\n",
            "Epoch 170/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2439 - accuracy: 0.9000 - fscore: 0.8998 - val_loss: 0.3734 - val_accuracy: 0.8607 - val_fscore: 0.8594\n",
            "Epoch 171/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.2390 - accuracy: 0.9048 - fscore: 0.9075 - val_loss: 0.3666 - val_accuracy: 0.8700 - val_fscore: 0.8542\n",
            "Epoch 172/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.2474 - accuracy: 0.9008 - fscore: 0.8981 - val_loss: 0.3452 - val_accuracy: 0.8607 - val_fscore: 0.8581\n",
            "Epoch 173/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2371 - accuracy: 0.9004 - fscore: 0.9015 - val_loss: 0.3839 - val_accuracy: 0.8576 - val_fscore: 0.8539\n",
            "Epoch 174/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2424 - accuracy: 0.9000 - fscore: 0.9016 - val_loss: 0.3751 - val_accuracy: 0.8638 - val_fscore: 0.8579\n",
            "Epoch 175/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2414 - accuracy: 0.9022 - fscore: 0.8998 - val_loss: 0.3704 - val_accuracy: 0.8700 - val_fscore: 0.8594\n",
            "Epoch 176/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2564 - accuracy: 0.8929 - fscore: 0.8959 - val_loss: 0.3644 - val_accuracy: 0.8762 - val_fscore: 0.8579\n",
            "Epoch 177/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2399 - accuracy: 0.9008 - fscore: 0.9041 - val_loss: 0.4380 - val_accuracy: 0.8483 - val_fscore: 0.8387\n",
            "Epoch 178/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2302 - accuracy: 0.9066 - fscore: 0.9052 - val_loss: 0.3757 - val_accuracy: 0.8607 - val_fscore: 0.8526\n",
            "Epoch 179/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2318 - accuracy: 0.9048 - fscore: 0.9025 - val_loss: 0.3531 - val_accuracy: 0.8700 - val_fscore: 0.8602\n",
            "Epoch 180/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2328 - accuracy: 0.9013 - fscore: 0.9038 - val_loss: 0.3603 - val_accuracy: 0.8669 - val_fscore: 0.8557\n",
            "Epoch 181/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2370 - accuracy: 0.8977 - fscore: 0.8971 - val_loss: 0.3757 - val_accuracy: 0.8576 - val_fscore: 0.8592\n",
            "Epoch 182/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2260 - accuracy: 0.9057 - fscore: 0.9066 - val_loss: 0.3392 - val_accuracy: 0.8700 - val_fscore: 0.8663\n",
            "Epoch 183/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.2320 - accuracy: 0.9026 - fscore: 0.9029 - val_loss: 0.3456 - val_accuracy: 0.8638 - val_fscore: 0.8486\n",
            "Epoch 184/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2318 - accuracy: 0.9048 - fscore: 0.9056 - val_loss: 0.3538 - val_accuracy: 0.8700 - val_fscore: 0.8658\n",
            "Epoch 185/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2399 - accuracy: 0.8955 - fscore: 0.8970 - val_loss: 0.3750 - val_accuracy: 0.8576 - val_fscore: 0.8489\n",
            "Epoch 186/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2302 - accuracy: 0.9048 - fscore: 0.9028 - val_loss: 0.3432 - val_accuracy: 0.8700 - val_fscore: 0.8541\n",
            "Epoch 187/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2325 - accuracy: 0.9062 - fscore: 0.9044 - val_loss: 0.3952 - val_accuracy: 0.8545 - val_fscore: 0.8552\n",
            "Epoch 188/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2462 - accuracy: 0.8986 - fscore: 0.8993 - val_loss: 0.3577 - val_accuracy: 0.8793 - val_fscore: 0.8650\n",
            "Epoch 189/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2277 - accuracy: 0.9075 - fscore: 0.9079 - val_loss: 0.3541 - val_accuracy: 0.8638 - val_fscore: 0.8622\n",
            "Epoch 190/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2259 - accuracy: 0.9097 - fscore: 0.9067 - val_loss: 0.3504 - val_accuracy: 0.8731 - val_fscore: 0.8605\n",
            "Epoch 191/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.2196 - accuracy: 0.9093 - fscore: 0.9075 - val_loss: 0.3563 - val_accuracy: 0.8700 - val_fscore: 0.8566\n",
            "Epoch 192/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2176 - accuracy: 0.9128 - fscore: 0.9113 - val_loss: 0.3504 - val_accuracy: 0.8700 - val_fscore: 0.8596\n",
            "Epoch 193/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.2198 - accuracy: 0.9097 - fscore: 0.9093 - val_loss: 0.3515 - val_accuracy: 0.8669 - val_fscore: 0.8631\n",
            "Epoch 194/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2216 - accuracy: 0.9088 - fscore: 0.9084 - val_loss: 0.3687 - val_accuracy: 0.8607 - val_fscore: 0.8542\n",
            "Epoch 195/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2299 - accuracy: 0.9035 - fscore: 0.9050 - val_loss: 0.3732 - val_accuracy: 0.8576 - val_fscore: 0.8581\n",
            "Epoch 196/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.2285 - accuracy: 0.9039 - fscore: 0.9088 - val_loss: 0.3883 - val_accuracy: 0.8669 - val_fscore: 0.8626\n",
            "Epoch 197/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2372 - accuracy: 0.9026 - fscore: 0.9052 - val_loss: 0.3421 - val_accuracy: 0.8793 - val_fscore: 0.8661\n",
            "Epoch 198/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.2204 - accuracy: 0.9106 - fscore: 0.9085 - val_loss: 0.3529 - val_accuracy: 0.8731 - val_fscore: 0.8613\n",
            "Epoch 199/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2395 - accuracy: 0.9057 - fscore: 0.9037 - val_loss: 0.3416 - val_accuracy: 0.8700 - val_fscore: 0.8681\n",
            "Epoch 200/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2157 - accuracy: 0.9101 - fscore: 0.9086 - val_loss: 0.3553 - val_accuracy: 0.8762 - val_fscore: 0.8636\n",
            "Epoch 201/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2142 - accuracy: 0.9119 - fscore: 0.9127 - val_loss: 0.3496 - val_accuracy: 0.8669 - val_fscore: 0.8502\n",
            "Epoch 202/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2240 - accuracy: 0.9141 - fscore: 0.9095 - val_loss: 0.4225 - val_accuracy: 0.8483 - val_fscore: 0.8446\n",
            "Epoch 203/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2140 - accuracy: 0.9115 - fscore: 0.9132 - val_loss: 0.3453 - val_accuracy: 0.8762 - val_fscore: 0.8659\n",
            "Epoch 204/700\n",
            "142/142 [==============================] - 1s 11ms/step - loss: 0.2207 - accuracy: 0.9110 - fscore: 0.9096 - val_loss: 0.4007 - val_accuracy: 0.8390 - val_fscore: 0.8386\n",
            "Epoch 205/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2756 - accuracy: 0.8889 - fscore: 0.8877 - val_loss: 0.4659 - val_accuracy: 0.8266 - val_fscore: 0.8336\n",
            "Epoch 206/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2149 - accuracy: 0.9159 - fscore: 0.9149 - val_loss: 0.3403 - val_accuracy: 0.8762 - val_fscore: 0.8681\n",
            "Epoch 207/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2130 - accuracy: 0.9177 - fscore: 0.9145 - val_loss: 0.3584 - val_accuracy: 0.8669 - val_fscore: 0.8628\n",
            "Epoch 208/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2164 - accuracy: 0.9115 - fscore: 0.9127 - val_loss: 0.3355 - val_accuracy: 0.8731 - val_fscore: 0.8652\n",
            "Epoch 209/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2097 - accuracy: 0.9163 - fscore: 0.9144 - val_loss: 0.3288 - val_accuracy: 0.8793 - val_fscore: 0.8680\n",
            "Epoch 210/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2064 - accuracy: 0.9163 - fscore: 0.9164 - val_loss: 0.3399 - val_accuracy: 0.8824 - val_fscore: 0.8636\n",
            "Epoch 211/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2018 - accuracy: 0.9216 - fscore: 0.9190 - val_loss: 0.3606 - val_accuracy: 0.8762 - val_fscore: 0.8641\n",
            "Epoch 212/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2097 - accuracy: 0.9137 - fscore: 0.9126 - val_loss: 0.3275 - val_accuracy: 0.8731 - val_fscore: 0.8684\n",
            "Epoch 213/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2265 - accuracy: 0.9039 - fscore: 0.9062 - val_loss: 0.3556 - val_accuracy: 0.8731 - val_fscore: 0.8699\n",
            "Epoch 214/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2419 - accuracy: 0.9017 - fscore: 0.9025 - val_loss: 0.6423 - val_accuracy: 0.7957 - val_fscore: 0.7957\n",
            "Epoch 215/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2421 - accuracy: 0.9017 - fscore: 0.9014 - val_loss: 0.3398 - val_accuracy: 0.8731 - val_fscore: 0.8626\n",
            "Epoch 216/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2016 - accuracy: 0.9230 - fscore: 0.9211 - val_loss: 0.3365 - val_accuracy: 0.8669 - val_fscore: 0.8610\n",
            "Epoch 217/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2022 - accuracy: 0.9185 - fscore: 0.9181 - val_loss: 0.3489 - val_accuracy: 0.8700 - val_fscore: 0.8619\n",
            "Epoch 218/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2133 - accuracy: 0.9146 - fscore: 0.9165 - val_loss: 0.3459 - val_accuracy: 0.8731 - val_fscore: 0.8693\n",
            "Epoch 219/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2097 - accuracy: 0.9177 - fscore: 0.9149 - val_loss: 0.3542 - val_accuracy: 0.8700 - val_fscore: 0.8596\n",
            "Epoch 220/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1978 - accuracy: 0.9194 - fscore: 0.9177 - val_loss: 0.3505 - val_accuracy: 0.8700 - val_fscore: 0.8595\n",
            "Epoch 221/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1999 - accuracy: 0.9216 - fscore: 0.9202 - val_loss: 0.3456 - val_accuracy: 0.8824 - val_fscore: 0.8701\n",
            "Epoch 222/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2183 - accuracy: 0.9154 - fscore: 0.9146 - val_loss: 0.3800 - val_accuracy: 0.8638 - val_fscore: 0.8628\n",
            "Epoch 223/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1994 - accuracy: 0.9234 - fscore: 0.9207 - val_loss: 0.3844 - val_accuracy: 0.8514 - val_fscore: 0.8498\n",
            "Epoch 224/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1986 - accuracy: 0.9212 - fscore: 0.9210 - val_loss: 0.3474 - val_accuracy: 0.8638 - val_fscore: 0.8620\n",
            "Epoch 225/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.2045 - accuracy: 0.9168 - fscore: 0.9120 - val_loss: 0.3677 - val_accuracy: 0.8576 - val_fscore: 0.8548\n",
            "Epoch 226/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2074 - accuracy: 0.9124 - fscore: 0.9131 - val_loss: 0.3847 - val_accuracy: 0.8731 - val_fscore: 0.8628\n",
            "Epoch 227/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2130 - accuracy: 0.9163 - fscore: 0.9127 - val_loss: 0.3642 - val_accuracy: 0.8669 - val_fscore: 0.8643\n",
            "Epoch 228/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2046 - accuracy: 0.9168 - fscore: 0.9179 - val_loss: 0.4051 - val_accuracy: 0.8576 - val_fscore: 0.8511\n",
            "Epoch 229/700\n",
            "142/142 [==============================] - 1s 11ms/step - loss: 0.2027 - accuracy: 0.9190 - fscore: 0.9191 - val_loss: 0.3427 - val_accuracy: 0.8669 - val_fscore: 0.8700\n",
            "Epoch 230/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2057 - accuracy: 0.9150 - fscore: 0.9159 - val_loss: 0.3580 - val_accuracy: 0.8576 - val_fscore: 0.8588\n",
            "Epoch 231/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2123 - accuracy: 0.9177 - fscore: 0.9132 - val_loss: 0.4037 - val_accuracy: 0.8545 - val_fscore: 0.8562\n",
            "Epoch 232/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.1988 - accuracy: 0.9172 - fscore: 0.9154 - val_loss: 0.3623 - val_accuracy: 0.8669 - val_fscore: 0.8603\n",
            "Epoch 233/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1933 - accuracy: 0.9225 - fscore: 0.9201 - val_loss: 0.3478 - val_accuracy: 0.8731 - val_fscore: 0.8707\n",
            "Epoch 234/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1929 - accuracy: 0.9225 - fscore: 0.9206 - val_loss: 0.3555 - val_accuracy: 0.8762 - val_fscore: 0.8716\n",
            "Epoch 235/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1916 - accuracy: 0.9252 - fscore: 0.9255 - val_loss: 0.3528 - val_accuracy: 0.8731 - val_fscore: 0.8642\n",
            "Epoch 236/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2107 - accuracy: 0.9163 - fscore: 0.9131 - val_loss: 0.3257 - val_accuracy: 0.8731 - val_fscore: 0.8741\n",
            "Epoch 237/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1974 - accuracy: 0.9234 - fscore: 0.9242 - val_loss: 0.3372 - val_accuracy: 0.8762 - val_fscore: 0.8588\n",
            "Epoch 238/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1967 - accuracy: 0.9252 - fscore: 0.9195 - val_loss: 0.3662 - val_accuracy: 0.8669 - val_fscore: 0.8671\n",
            "Epoch 239/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2060 - accuracy: 0.9190 - fscore: 0.9190 - val_loss: 0.3619 - val_accuracy: 0.8731 - val_fscore: 0.8644\n",
            "Epoch 240/700\n",
            "142/142 [==============================] - 1s 11ms/step - loss: 0.1934 - accuracy: 0.9261 - fscore: 0.9250 - val_loss: 0.3483 - val_accuracy: 0.8762 - val_fscore: 0.8697\n",
            "Epoch 241/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.1894 - accuracy: 0.9270 - fscore: 0.9268 - val_loss: 0.3351 - val_accuracy: 0.8824 - val_fscore: 0.8723\n",
            "Epoch 242/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.1870 - accuracy: 0.9252 - fscore: 0.9220 - val_loss: 0.3414 - val_accuracy: 0.8885 - val_fscore: 0.8783\n",
            "Epoch 243/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.1825 - accuracy: 0.9287 - fscore: 0.9262 - val_loss: 0.3446 - val_accuracy: 0.8824 - val_fscore: 0.8738\n",
            "Epoch 244/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.1893 - accuracy: 0.9256 - fscore: 0.9259 - val_loss: 0.3415 - val_accuracy: 0.8731 - val_fscore: 0.8619\n",
            "Epoch 245/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.1941 - accuracy: 0.9234 - fscore: 0.9198 - val_loss: 0.3457 - val_accuracy: 0.8824 - val_fscore: 0.8677\n",
            "Epoch 246/700\n",
            "142/142 [==============================] - 1s 11ms/step - loss: 0.1878 - accuracy: 0.9239 - fscore: 0.9254 - val_loss: 0.3937 - val_accuracy: 0.8545 - val_fscore: 0.8508\n",
            "Epoch 247/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1867 - accuracy: 0.9256 - fscore: 0.9228 - val_loss: 0.3393 - val_accuracy: 0.8824 - val_fscore: 0.8694\n",
            "Epoch 248/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1836 - accuracy: 0.9256 - fscore: 0.9240 - val_loss: 0.3425 - val_accuracy: 0.8793 - val_fscore: 0.8642\n",
            "Epoch 249/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1966 - accuracy: 0.9208 - fscore: 0.9215 - val_loss: 0.3528 - val_accuracy: 0.8885 - val_fscore: 0.8710\n",
            "Epoch 250/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1823 - accuracy: 0.9301 - fscore: 0.9277 - val_loss: 0.3560 - val_accuracy: 0.8731 - val_fscore: 0.8729\n",
            "Epoch 251/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2177 - accuracy: 0.9132 - fscore: 0.9134 - val_loss: 0.3440 - val_accuracy: 0.8793 - val_fscore: 0.8642\n",
            "Epoch 252/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1846 - accuracy: 0.9278 - fscore: 0.9250 - val_loss: 0.3486 - val_accuracy: 0.8731 - val_fscore: 0.8611\n",
            "Epoch 253/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1792 - accuracy: 0.9340 - fscore: 0.9280 - val_loss: 0.3237 - val_accuracy: 0.8854 - val_fscore: 0.8738\n",
            "Epoch 254/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1903 - accuracy: 0.9221 - fscore: 0.9235 - val_loss: 0.4059 - val_accuracy: 0.8545 - val_fscore: 0.8532\n",
            "Epoch 255/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1914 - accuracy: 0.9230 - fscore: 0.9237 - val_loss: 0.3784 - val_accuracy: 0.8731 - val_fscore: 0.8710\n",
            "Epoch 256/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1946 - accuracy: 0.9190 - fscore: 0.9194 - val_loss: 0.3471 - val_accuracy: 0.8762 - val_fscore: 0.8634\n",
            "Epoch 257/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1805 - accuracy: 0.9305 - fscore: 0.9290 - val_loss: 0.3381 - val_accuracy: 0.8700 - val_fscore: 0.8647\n",
            "Epoch 258/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1798 - accuracy: 0.9318 - fscore: 0.9285 - val_loss: 0.3736 - val_accuracy: 0.8793 - val_fscore: 0.8686\n",
            "Epoch 259/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1825 - accuracy: 0.9292 - fscore: 0.9298 - val_loss: 0.3732 - val_accuracy: 0.8638 - val_fscore: 0.8603\n",
            "Epoch 260/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1800 - accuracy: 0.9301 - fscore: 0.9250 - val_loss: 0.3683 - val_accuracy: 0.8793 - val_fscore: 0.8646\n",
            "Epoch 261/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1820 - accuracy: 0.9292 - fscore: 0.9271 - val_loss: 0.3750 - val_accuracy: 0.8607 - val_fscore: 0.8585\n",
            "Epoch 262/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1984 - accuracy: 0.9225 - fscore: 0.9214 - val_loss: 0.4189 - val_accuracy: 0.8669 - val_fscore: 0.8573\n",
            "Epoch 263/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1853 - accuracy: 0.9270 - fscore: 0.9276 - val_loss: 0.3538 - val_accuracy: 0.8700 - val_fscore: 0.8725\n",
            "Epoch 264/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2096 - accuracy: 0.9132 - fscore: 0.9161 - val_loss: 0.3412 - val_accuracy: 0.8854 - val_fscore: 0.8769\n",
            "Epoch 265/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2415 - accuracy: 0.9062 - fscore: 0.9064 - val_loss: 0.3312 - val_accuracy: 0.8731 - val_fscore: 0.8722\n",
            "Epoch 266/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.1796 - accuracy: 0.9323 - fscore: 0.9260 - val_loss: 0.3418 - val_accuracy: 0.8916 - val_fscore: 0.8641\n",
            "Epoch 267/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1743 - accuracy: 0.9292 - fscore: 0.9291 - val_loss: 0.3125 - val_accuracy: 0.8854 - val_fscore: 0.8724\n",
            "Epoch 268/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1760 - accuracy: 0.9345 - fscore: 0.9321 - val_loss: 0.4928 - val_accuracy: 0.8576 - val_fscore: 0.8511\n",
            "Epoch 269/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1751 - accuracy: 0.9349 - fscore: 0.9298 - val_loss: 0.3455 - val_accuracy: 0.8762 - val_fscore: 0.8645\n",
            "Epoch 270/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1688 - accuracy: 0.9345 - fscore: 0.9319 - val_loss: 0.3480 - val_accuracy: 0.8854 - val_fscore: 0.8683\n",
            "Epoch 271/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1685 - accuracy: 0.9367 - fscore: 0.9318 - val_loss: 0.3737 - val_accuracy: 0.8669 - val_fscore: 0.8639\n",
            "Epoch 272/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1697 - accuracy: 0.9376 - fscore: 0.9340 - val_loss: 0.3388 - val_accuracy: 0.8885 - val_fscore: 0.8687\n",
            "Epoch 273/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1699 - accuracy: 0.9389 - fscore: 0.9357 - val_loss: 0.3473 - val_accuracy: 0.8854 - val_fscore: 0.8720\n",
            "Epoch 274/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1672 - accuracy: 0.9354 - fscore: 0.9307 - val_loss: 0.3413 - val_accuracy: 0.8854 - val_fscore: 0.8839\n",
            "Epoch 275/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1742 - accuracy: 0.9261 - fscore: 0.9264 - val_loss: 0.3425 - val_accuracy: 0.8607 - val_fscore: 0.8587\n",
            "Epoch 276/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1714 - accuracy: 0.9336 - fscore: 0.9349 - val_loss: 0.3532 - val_accuracy: 0.8885 - val_fscore: 0.8703\n",
            "Epoch 277/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1957 - accuracy: 0.9177 - fscore: 0.9156 - val_loss: 0.3417 - val_accuracy: 0.8576 - val_fscore: 0.8529\n",
            "Epoch 278/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1830 - accuracy: 0.9243 - fscore: 0.9277 - val_loss: 0.3196 - val_accuracy: 0.8762 - val_fscore: 0.8753\n",
            "Epoch 279/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1658 - accuracy: 0.9363 - fscore: 0.9361 - val_loss: 0.3457 - val_accuracy: 0.8762 - val_fscore: 0.8714\n",
            "Epoch 280/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1646 - accuracy: 0.9336 - fscore: 0.9331 - val_loss: 0.3403 - val_accuracy: 0.8947 - val_fscore: 0.8780\n",
            "Epoch 281/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1691 - accuracy: 0.9305 - fscore: 0.9321 - val_loss: 0.3499 - val_accuracy: 0.8700 - val_fscore: 0.8728\n",
            "Epoch 282/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.1793 - accuracy: 0.9318 - fscore: 0.9315 - val_loss: 0.3358 - val_accuracy: 0.8824 - val_fscore: 0.8696\n",
            "Epoch 283/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1670 - accuracy: 0.9332 - fscore: 0.9333 - val_loss: 0.3121 - val_accuracy: 0.8854 - val_fscore: 0.8740\n",
            "Epoch 284/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1713 - accuracy: 0.9363 - fscore: 0.9336 - val_loss: 0.3593 - val_accuracy: 0.8793 - val_fscore: 0.8710\n",
            "Epoch 285/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1619 - accuracy: 0.9385 - fscore: 0.9383 - val_loss: 0.3357 - val_accuracy: 0.8638 - val_fscore: 0.8698\n",
            "Epoch 286/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1703 - accuracy: 0.9327 - fscore: 0.9305 - val_loss: 0.3633 - val_accuracy: 0.8669 - val_fscore: 0.8701\n",
            "Epoch 287/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1674 - accuracy: 0.9376 - fscore: 0.9357 - val_loss: 0.3461 - val_accuracy: 0.8824 - val_fscore: 0.8750\n",
            "Epoch 288/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1664 - accuracy: 0.9336 - fscore: 0.9341 - val_loss: 0.3381 - val_accuracy: 0.8824 - val_fscore: 0.8699\n",
            "Epoch 289/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1735 - accuracy: 0.9332 - fscore: 0.9299 - val_loss: 0.3491 - val_accuracy: 0.8669 - val_fscore: 0.8684\n",
            "Epoch 290/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1638 - accuracy: 0.9340 - fscore: 0.9342 - val_loss: 0.3258 - val_accuracy: 0.8700 - val_fscore: 0.8684\n",
            "Epoch 291/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1623 - accuracy: 0.9358 - fscore: 0.9364 - val_loss: 0.3403 - val_accuracy: 0.8854 - val_fscore: 0.8811\n",
            "Epoch 292/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.2072 - accuracy: 0.9230 - fscore: 0.9231 - val_loss: 0.3446 - val_accuracy: 0.8793 - val_fscore: 0.8699\n",
            "Epoch 293/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1698 - accuracy: 0.9332 - fscore: 0.9338 - val_loss: 0.3290 - val_accuracy: 0.8824 - val_fscore: 0.8789\n",
            "Epoch 294/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1739 - accuracy: 0.9305 - fscore: 0.9316 - val_loss: 0.3327 - val_accuracy: 0.8824 - val_fscore: 0.8756\n",
            "Epoch 295/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1643 - accuracy: 0.9345 - fscore: 0.9340 - val_loss: 0.3382 - val_accuracy: 0.8731 - val_fscore: 0.8722\n",
            "Epoch 296/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1820 - accuracy: 0.9261 - fscore: 0.9289 - val_loss: 0.3501 - val_accuracy: 0.8669 - val_fscore: 0.8578\n",
            "Epoch 297/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1712 - accuracy: 0.9296 - fscore: 0.9315 - val_loss: 0.3646 - val_accuracy: 0.8854 - val_fscore: 0.8761\n",
            "Epoch 298/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1794 - accuracy: 0.9296 - fscore: 0.9282 - val_loss: 0.3662 - val_accuracy: 0.8793 - val_fscore: 0.8718\n",
            "Epoch 299/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1637 - accuracy: 0.9367 - fscore: 0.9356 - val_loss: 0.3377 - val_accuracy: 0.8824 - val_fscore: 0.8747\n",
            "Epoch 300/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1585 - accuracy: 0.9420 - fscore: 0.9411 - val_loss: 0.3602 - val_accuracy: 0.8700 - val_fscore: 0.8636\n",
            "Epoch 301/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1576 - accuracy: 0.9367 - fscore: 0.9373 - val_loss: 0.3447 - val_accuracy: 0.8793 - val_fscore: 0.8681\n",
            "Epoch 302/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1550 - accuracy: 0.9376 - fscore: 0.9384 - val_loss: 0.3890 - val_accuracy: 0.8762 - val_fscore: 0.8683\n",
            "Epoch 303/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2040 - accuracy: 0.9252 - fscore: 0.9218 - val_loss: 0.3972 - val_accuracy: 0.8793 - val_fscore: 0.8808\n",
            "Epoch 304/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1787 - accuracy: 0.9283 - fscore: 0.9297 - val_loss: 0.3297 - val_accuracy: 0.8700 - val_fscore: 0.8634\n",
            "Epoch 305/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1609 - accuracy: 0.9349 - fscore: 0.9364 - val_loss: 0.3516 - val_accuracy: 0.8700 - val_fscore: 0.8591\n",
            "Epoch 306/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1639 - accuracy: 0.9371 - fscore: 0.9375 - val_loss: 0.3604 - val_accuracy: 0.8669 - val_fscore: 0.8607\n",
            "Epoch 307/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1595 - accuracy: 0.9345 - fscore: 0.9388 - val_loss: 0.3365 - val_accuracy: 0.8824 - val_fscore: 0.8657\n",
            "Epoch 308/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1564 - accuracy: 0.9363 - fscore: 0.9359 - val_loss: 0.3231 - val_accuracy: 0.8824 - val_fscore: 0.8728\n",
            "Epoch 309/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1578 - accuracy: 0.9358 - fscore: 0.9367 - val_loss: 0.3387 - val_accuracy: 0.8793 - val_fscore: 0.8740\n",
            "Epoch 310/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2005 - accuracy: 0.9225 - fscore: 0.9249 - val_loss: 0.3489 - val_accuracy: 0.8824 - val_fscore: 0.8769\n",
            "Epoch 311/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1572 - accuracy: 0.9380 - fscore: 0.9380 - val_loss: 0.3467 - val_accuracy: 0.8824 - val_fscore: 0.8742\n",
            "Epoch 312/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1545 - accuracy: 0.9398 - fscore: 0.9390 - val_loss: 0.3456 - val_accuracy: 0.8762 - val_fscore: 0.8775\n",
            "Epoch 313/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1748 - accuracy: 0.9323 - fscore: 0.9336 - val_loss: 0.3394 - val_accuracy: 0.8854 - val_fscore: 0.8826\n",
            "Epoch 314/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1588 - accuracy: 0.9367 - fscore: 0.9314 - val_loss: 0.3438 - val_accuracy: 0.8731 - val_fscore: 0.8690\n",
            "Epoch 315/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1589 - accuracy: 0.9385 - fscore: 0.9386 - val_loss: 0.4279 - val_accuracy: 0.8638 - val_fscore: 0.8562\n",
            "Epoch 316/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1673 - accuracy: 0.9349 - fscore: 0.9360 - val_loss: 0.4279 - val_accuracy: 0.8607 - val_fscore: 0.8543\n",
            "Epoch 317/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1781 - accuracy: 0.9327 - fscore: 0.9322 - val_loss: 0.3591 - val_accuracy: 0.8762 - val_fscore: 0.8672\n",
            "Epoch 318/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1822 - accuracy: 0.9221 - fscore: 0.9247 - val_loss: 0.3571 - val_accuracy: 0.8700 - val_fscore: 0.8762\n",
            "Epoch 319/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1565 - accuracy: 0.9389 - fscore: 0.9385 - val_loss: 0.3165 - val_accuracy: 0.8885 - val_fscore: 0.8870\n",
            "Epoch 320/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2350 - accuracy: 0.9084 - fscore: 0.9101 - val_loss: 0.3306 - val_accuracy: 0.8854 - val_fscore: 0.8703\n",
            "Epoch 321/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.1556 - accuracy: 0.9389 - fscore: 0.9404 - val_loss: 0.3526 - val_accuracy: 0.8762 - val_fscore: 0.8695\n",
            "Epoch 322/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1571 - accuracy: 0.9345 - fscore: 0.9352 - val_loss: 0.3755 - val_accuracy: 0.8762 - val_fscore: 0.8740\n",
            "Epoch 323/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1602 - accuracy: 0.9332 - fscore: 0.9381 - val_loss: 0.3254 - val_accuracy: 0.8793 - val_fscore: 0.8756\n",
            "Epoch 324/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1463 - accuracy: 0.9438 - fscore: 0.9438 - val_loss: 0.3391 - val_accuracy: 0.8669 - val_fscore: 0.8605\n",
            "Epoch 325/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1498 - accuracy: 0.9416 - fscore: 0.9374 - val_loss: 0.3362 - val_accuracy: 0.8793 - val_fscore: 0.8765\n",
            "Epoch 326/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1674 - accuracy: 0.9345 - fscore: 0.9312 - val_loss: 0.3336 - val_accuracy: 0.8885 - val_fscore: 0.8729\n",
            "Epoch 327/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1459 - accuracy: 0.9411 - fscore: 0.9446 - val_loss: 0.3406 - val_accuracy: 0.8762 - val_fscore: 0.8677\n",
            "Epoch 328/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1439 - accuracy: 0.9473 - fscore: 0.9455 - val_loss: 0.3482 - val_accuracy: 0.8793 - val_fscore: 0.8760\n",
            "Epoch 329/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1486 - accuracy: 0.9349 - fscore: 0.9389 - val_loss: 0.3492 - val_accuracy: 0.8854 - val_fscore: 0.8745\n",
            "Epoch 330/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1481 - accuracy: 0.9402 - fscore: 0.9419 - val_loss: 0.3464 - val_accuracy: 0.8854 - val_fscore: 0.8721\n",
            "Epoch 331/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1471 - accuracy: 0.9411 - fscore: 0.9425 - val_loss: 0.3364 - val_accuracy: 0.8731 - val_fscore: 0.8753\n",
            "Epoch 332/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1542 - accuracy: 0.9411 - fscore: 0.9389 - val_loss: 0.4022 - val_accuracy: 0.8700 - val_fscore: 0.8718\n",
            "Epoch 333/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1563 - accuracy: 0.9385 - fscore: 0.9384 - val_loss: 0.3523 - val_accuracy: 0.8762 - val_fscore: 0.8673\n",
            "Epoch 334/700\n",
            "142/142 [==============================] - 1s 11ms/step - loss: 0.1830 - accuracy: 0.9296 - fscore: 0.9294 - val_loss: 0.3667 - val_accuracy: 0.8700 - val_fscore: 0.8677\n",
            "Epoch 335/700\n",
            "142/142 [==============================] - 1s 11ms/step - loss: 0.1517 - accuracy: 0.9407 - fscore: 0.9386 - val_loss: 0.4098 - val_accuracy: 0.8576 - val_fscore: 0.8615\n",
            "Epoch 336/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1498 - accuracy: 0.9416 - fscore: 0.9432 - val_loss: 0.3432 - val_accuracy: 0.8731 - val_fscore: 0.8681\n",
            "Epoch 337/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1576 - accuracy: 0.9358 - fscore: 0.9333 - val_loss: 0.3467 - val_accuracy: 0.8731 - val_fscore: 0.8706\n",
            "Epoch 338/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1548 - accuracy: 0.9376 - fscore: 0.9408 - val_loss: 0.3417 - val_accuracy: 0.8854 - val_fscore: 0.8693\n",
            "Epoch 339/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1436 - accuracy: 0.9438 - fscore: 0.9438 - val_loss: 0.3273 - val_accuracy: 0.8793 - val_fscore: 0.8735\n",
            "Epoch 340/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1559 - accuracy: 0.9376 - fscore: 0.9387 - val_loss: 0.3301 - val_accuracy: 0.8762 - val_fscore: 0.8668\n",
            "Epoch 341/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1407 - accuracy: 0.9464 - fscore: 0.9451 - val_loss: 0.3611 - val_accuracy: 0.8793 - val_fscore: 0.8718\n",
            "Epoch 342/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1387 - accuracy: 0.9442 - fscore: 0.9454 - val_loss: 0.3656 - val_accuracy: 0.8731 - val_fscore: 0.8712\n",
            "Epoch 343/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1407 - accuracy: 0.9447 - fscore: 0.9464 - val_loss: 0.3972 - val_accuracy: 0.8700 - val_fscore: 0.8677\n",
            "Epoch 344/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1937 - accuracy: 0.9270 - fscore: 0.9278 - val_loss: 0.3584 - val_accuracy: 0.8762 - val_fscore: 0.8750\n",
            "Epoch 345/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1498 - accuracy: 0.9402 - fscore: 0.9391 - val_loss: 0.3343 - val_accuracy: 0.8762 - val_fscore: 0.8702\n",
            "Epoch 346/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.1508 - accuracy: 0.9411 - fscore: 0.9405 - val_loss: 0.3684 - val_accuracy: 0.8700 - val_fscore: 0.8641\n",
            "Epoch 347/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1426 - accuracy: 0.9456 - fscore: 0.9434 - val_loss: 0.3518 - val_accuracy: 0.8607 - val_fscore: 0.8549\n",
            "Epoch 348/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1468 - accuracy: 0.9438 - fscore: 0.9440 - val_loss: 0.5408 - val_accuracy: 0.8452 - val_fscore: 0.8388\n",
            "Epoch 349/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1966 - accuracy: 0.9185 - fscore: 0.9202 - val_loss: 0.3349 - val_accuracy: 0.8638 - val_fscore: 0.8708\n",
            "Epoch 350/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1376 - accuracy: 0.9460 - fscore: 0.9433 - val_loss: 0.3246 - val_accuracy: 0.8885 - val_fscore: 0.8784\n",
            "Epoch 351/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1429 - accuracy: 0.9456 - fscore: 0.9395 - val_loss: 0.3560 - val_accuracy: 0.8669 - val_fscore: 0.8667\n",
            "Epoch 352/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1392 - accuracy: 0.9478 - fscore: 0.9479 - val_loss: 0.3628 - val_accuracy: 0.8638 - val_fscore: 0.8623\n",
            "Epoch 353/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1418 - accuracy: 0.9456 - fscore: 0.9436 - val_loss: 0.3483 - val_accuracy: 0.8793 - val_fscore: 0.8765\n",
            "Epoch 354/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2030 - accuracy: 0.9181 - fscore: 0.9164 - val_loss: 0.3625 - val_accuracy: 0.8793 - val_fscore: 0.8740\n",
            "Epoch 355/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.1654 - accuracy: 0.9340 - fscore: 0.9354 - val_loss: 0.3672 - val_accuracy: 0.8700 - val_fscore: 0.8717\n",
            "Epoch 356/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1437 - accuracy: 0.9491 - fscore: 0.9473 - val_loss: 0.3433 - val_accuracy: 0.8731 - val_fscore: 0.8612\n",
            "Epoch 357/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1360 - accuracy: 0.9473 - fscore: 0.9487 - val_loss: 0.3352 - val_accuracy: 0.8793 - val_fscore: 0.8668\n",
            "Epoch 358/700\n",
            "142/142 [==============================] - 1s 11ms/step - loss: 0.1371 - accuracy: 0.9460 - fscore: 0.9479 - val_loss: 0.3484 - val_accuracy: 0.8854 - val_fscore: 0.8748\n",
            "Epoch 359/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.1385 - accuracy: 0.9438 - fscore: 0.9450 - val_loss: 0.3577 - val_accuracy: 0.8669 - val_fscore: 0.8683\n",
            "Epoch 360/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2425 - accuracy: 0.9159 - fscore: 0.9167 - val_loss: 0.3320 - val_accuracy: 0.8885 - val_fscore: 0.8828\n",
            "Epoch 361/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1524 - accuracy: 0.9394 - fscore: 0.9377 - val_loss: 0.3158 - val_accuracy: 0.8824 - val_fscore: 0.8717\n",
            "Epoch 362/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1423 - accuracy: 0.9442 - fscore: 0.9418 - val_loss: 0.3938 - val_accuracy: 0.8607 - val_fscore: 0.8536\n",
            "Epoch 363/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1542 - accuracy: 0.9411 - fscore: 0.9395 - val_loss: 0.3388 - val_accuracy: 0.8762 - val_fscore: 0.8716\n",
            "Epoch 364/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1351 - accuracy: 0.9460 - fscore: 0.9452 - val_loss: 0.3329 - val_accuracy: 0.8824 - val_fscore: 0.8730\n",
            "Epoch 365/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1349 - accuracy: 0.9438 - fscore: 0.9427 - val_loss: 0.3599 - val_accuracy: 0.8793 - val_fscore: 0.8678\n",
            "Epoch 366/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1521 - accuracy: 0.9447 - fscore: 0.9428 - val_loss: 0.3321 - val_accuracy: 0.8731 - val_fscore: 0.8688\n",
            "Epoch 367/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.1509 - accuracy: 0.9358 - fscore: 0.9389 - val_loss: 0.3317 - val_accuracy: 0.8576 - val_fscore: 0.8547\n",
            "Epoch 368/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1356 - accuracy: 0.9469 - fscore: 0.9490 - val_loss: 0.3499 - val_accuracy: 0.8793 - val_fscore: 0.8695\n",
            "Epoch 369/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1355 - accuracy: 0.9451 - fscore: 0.9481 - val_loss: 0.3514 - val_accuracy: 0.8793 - val_fscore: 0.8731\n",
            "Epoch 370/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1333 - accuracy: 0.9469 - fscore: 0.9499 - val_loss: 0.3459 - val_accuracy: 0.8762 - val_fscore: 0.8689\n",
            "Epoch 371/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1362 - accuracy: 0.9451 - fscore: 0.9490 - val_loss: 0.3469 - val_accuracy: 0.8700 - val_fscore: 0.8674\n",
            "Epoch 372/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1342 - accuracy: 0.9469 - fscore: 0.9478 - val_loss: 0.3363 - val_accuracy: 0.8700 - val_fscore: 0.8593\n",
            "Epoch 373/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1366 - accuracy: 0.9447 - fscore: 0.9453 - val_loss: 0.3221 - val_accuracy: 0.8824 - val_fscore: 0.8785\n",
            "Epoch 374/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1464 - accuracy: 0.9425 - fscore: 0.9427 - val_loss: 0.3603 - val_accuracy: 0.8793 - val_fscore: 0.8663\n",
            "Epoch 375/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1429 - accuracy: 0.9402 - fscore: 0.9404 - val_loss: 0.3546 - val_accuracy: 0.8793 - val_fscore: 0.8782\n",
            "Epoch 376/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1521 - accuracy: 0.9385 - fscore: 0.9393 - val_loss: 0.3450 - val_accuracy: 0.8700 - val_fscore: 0.8728\n",
            "Epoch 377/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1354 - accuracy: 0.9486 - fscore: 0.9486 - val_loss: 0.3649 - val_accuracy: 0.8731 - val_fscore: 0.8677\n",
            "Epoch 378/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1350 - accuracy: 0.9464 - fscore: 0.9445 - val_loss: 0.3487 - val_accuracy: 0.8793 - val_fscore: 0.8719\n",
            "Epoch 379/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1602 - accuracy: 0.9367 - fscore: 0.9358 - val_loss: 0.3699 - val_accuracy: 0.8824 - val_fscore: 0.8814\n",
            "Epoch 380/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1339 - accuracy: 0.9464 - fscore: 0.9485 - val_loss: 0.3349 - val_accuracy: 0.8824 - val_fscore: 0.8766\n",
            "Epoch 381/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1793 - accuracy: 0.9309 - fscore: 0.9348 - val_loss: 0.3276 - val_accuracy: 0.8824 - val_fscore: 0.8726\n",
            "Epoch 382/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1319 - accuracy: 0.9491 - fscore: 0.9469 - val_loss: 0.3341 - val_accuracy: 0.8793 - val_fscore: 0.8725\n",
            "Epoch 383/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1260 - accuracy: 0.9504 - fscore: 0.9512 - val_loss: 0.3173 - val_accuracy: 0.8793 - val_fscore: 0.8688\n",
            "Epoch 384/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1403 - accuracy: 0.9460 - fscore: 0.9460 - val_loss: 0.3569 - val_accuracy: 0.8793 - val_fscore: 0.8707\n",
            "Epoch 385/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1259 - accuracy: 0.9504 - fscore: 0.9511 - val_loss: 0.3212 - val_accuracy: 0.8916 - val_fscore: 0.8849\n",
            "Epoch 386/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1332 - accuracy: 0.9451 - fscore: 0.9470 - val_loss: 0.3715 - val_accuracy: 0.8793 - val_fscore: 0.8713\n",
            "Epoch 387/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1276 - accuracy: 0.9509 - fscore: 0.9523 - val_loss: 0.3596 - val_accuracy: 0.8700 - val_fscore: 0.8697\n",
            "Epoch 388/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1395 - accuracy: 0.9425 - fscore: 0.9424 - val_loss: 0.3535 - val_accuracy: 0.8731 - val_fscore: 0.8705\n",
            "Epoch 389/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1244 - accuracy: 0.9522 - fscore: 0.9509 - val_loss: 0.3678 - val_accuracy: 0.8824 - val_fscore: 0.8738\n",
            "Epoch 390/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1294 - accuracy: 0.9522 - fscore: 0.9503 - val_loss: 0.3240 - val_accuracy: 0.8854 - val_fscore: 0.8728\n",
            "Epoch 391/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1746 - accuracy: 0.9287 - fscore: 0.9292 - val_loss: 0.4505 - val_accuracy: 0.8607 - val_fscore: 0.8564\n",
            "Epoch 392/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1592 - accuracy: 0.9429 - fscore: 0.9365 - val_loss: 0.3327 - val_accuracy: 0.8854 - val_fscore: 0.8679\n",
            "Epoch 393/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1437 - accuracy: 0.9442 - fscore: 0.9435 - val_loss: 0.3397 - val_accuracy: 0.8793 - val_fscore: 0.8633\n",
            "Epoch 394/700\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.1361 - accuracy: 0.9442 - fscore: 0.9467 - val_loss: 0.3268 - val_accuracy: 0.8824 - val_fscore: 0.8688\n",
            "Epoch 395/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1267 - accuracy: 0.9517 - fscore: 0.9505 - val_loss: 0.3365 - val_accuracy: 0.8824 - val_fscore: 0.8825\n",
            "Epoch 396/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1249 - accuracy: 0.9513 - fscore: 0.9522 - val_loss: 0.3691 - val_accuracy: 0.8824 - val_fscore: 0.8750\n",
            "Epoch 397/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1466 - accuracy: 0.9451 - fscore: 0.9448 - val_loss: 0.3480 - val_accuracy: 0.8824 - val_fscore: 0.8791\n",
            "Epoch 398/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1600 - accuracy: 0.9380 - fscore: 0.9371 - val_loss: 0.3241 - val_accuracy: 0.8669 - val_fscore: 0.8749\n",
            "Epoch 399/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1600 - accuracy: 0.9385 - fscore: 0.9380 - val_loss: 0.3333 - val_accuracy: 0.8824 - val_fscore: 0.8753\n",
            "Epoch 400/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.2924 - accuracy: 0.9088 - fscore: 0.9129 - val_loss: 0.3263 - val_accuracy: 0.8638 - val_fscore: 0.8634\n",
            "Epoch 401/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1335 - accuracy: 0.9486 - fscore: 0.9506 - val_loss: 0.3266 - val_accuracy: 0.8916 - val_fscore: 0.8816\n",
            "Epoch 402/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1340 - accuracy: 0.9433 - fscore: 0.9472 - val_loss: 0.3364 - val_accuracy: 0.8793 - val_fscore: 0.8741\n",
            "Epoch 403/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1347 - accuracy: 0.9478 - fscore: 0.9484 - val_loss: 0.3849 - val_accuracy: 0.8731 - val_fscore: 0.8711\n",
            "Epoch 404/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1263 - accuracy: 0.9513 - fscore: 0.9508 - val_loss: 0.3110 - val_accuracy: 0.8824 - val_fscore: 0.8773\n",
            "Epoch 405/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1239 - accuracy: 0.9522 - fscore: 0.9517 - val_loss: 0.3749 - val_accuracy: 0.8885 - val_fscore: 0.8733\n",
            "Epoch 406/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1715 - accuracy: 0.9416 - fscore: 0.9419 - val_loss: 0.3604 - val_accuracy: 0.8793 - val_fscore: 0.8733\n",
            "Epoch 407/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1583 - accuracy: 0.9327 - fscore: 0.9336 - val_loss: 0.3335 - val_accuracy: 0.8885 - val_fscore: 0.8779\n",
            "Epoch 408/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1269 - accuracy: 0.9495 - fscore: 0.9512 - val_loss: 0.3399 - val_accuracy: 0.8916 - val_fscore: 0.8721\n",
            "Epoch 409/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1223 - accuracy: 0.9513 - fscore: 0.9533 - val_loss: 0.3445 - val_accuracy: 0.8793 - val_fscore: 0.8702\n",
            "Epoch 410/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1216 - accuracy: 0.9540 - fscore: 0.9550 - val_loss: 0.3590 - val_accuracy: 0.8854 - val_fscore: 0.8713\n",
            "Epoch 411/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1245 - accuracy: 0.9535 - fscore: 0.9535 - val_loss: 0.3353 - val_accuracy: 0.8762 - val_fscore: 0.8664\n",
            "Epoch 412/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1386 - accuracy: 0.9482 - fscore: 0.9477 - val_loss: 0.3362 - val_accuracy: 0.8762 - val_fscore: 0.8723\n",
            "Epoch 413/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1253 - accuracy: 0.9562 - fscore: 0.9547 - val_loss: 0.3448 - val_accuracy: 0.8700 - val_fscore: 0.8672\n",
            "Epoch 414/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1230 - accuracy: 0.9531 - fscore: 0.9532 - val_loss: 0.3235 - val_accuracy: 0.8885 - val_fscore: 0.8832\n",
            "Epoch 415/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1344 - accuracy: 0.9464 - fscore: 0.9483 - val_loss: 0.3363 - val_accuracy: 0.8885 - val_fscore: 0.8716\n",
            "Epoch 416/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1310 - accuracy: 0.9522 - fscore: 0.9536 - val_loss: 0.3145 - val_accuracy: 0.8916 - val_fscore: 0.8779\n",
            "Epoch 417/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1266 - accuracy: 0.9517 - fscore: 0.9487 - val_loss: 0.3342 - val_accuracy: 0.8854 - val_fscore: 0.8741\n",
            "Epoch 418/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1222 - accuracy: 0.9557 - fscore: 0.9551 - val_loss: 0.3535 - val_accuracy: 0.8700 - val_fscore: 0.8653\n",
            "Epoch 419/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1265 - accuracy: 0.9495 - fscore: 0.9503 - val_loss: 0.3702 - val_accuracy: 0.8793 - val_fscore: 0.8730\n",
            "Epoch 420/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1298 - accuracy: 0.9482 - fscore: 0.9493 - val_loss: 0.4213 - val_accuracy: 0.8793 - val_fscore: 0.8684\n",
            "Epoch 421/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1744 - accuracy: 0.9318 - fscore: 0.9319 - val_loss: 0.3813 - val_accuracy: 0.8854 - val_fscore: 0.8785\n",
            "Epoch 422/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1208 - accuracy: 0.9526 - fscore: 0.9523 - val_loss: 0.3858 - val_accuracy: 0.8824 - val_fscore: 0.8763\n",
            "Epoch 423/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1328 - accuracy: 0.9504 - fscore: 0.9491 - val_loss: 0.3826 - val_accuracy: 0.8731 - val_fscore: 0.8687\n",
            "Epoch 424/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1259 - accuracy: 0.9500 - fscore: 0.9509 - val_loss: 0.3198 - val_accuracy: 0.8885 - val_fscore: 0.8768\n",
            "Epoch 425/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1467 - accuracy: 0.9425 - fscore: 0.9424 - val_loss: 0.4435 - val_accuracy: 0.8638 - val_fscore: 0.8573\n",
            "Epoch 426/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1198 - accuracy: 0.9557 - fscore: 0.9561 - val_loss: 0.3543 - val_accuracy: 0.8885 - val_fscore: 0.8794\n",
            "Epoch 427/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1224 - accuracy: 0.9517 - fscore: 0.9525 - val_loss: 0.3545 - val_accuracy: 0.8885 - val_fscore: 0.8828\n",
            "Epoch 428/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1454 - accuracy: 0.9402 - fscore: 0.9418 - val_loss: 0.3405 - val_accuracy: 0.8762 - val_fscore: 0.8708\n",
            "Epoch 429/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1391 - accuracy: 0.9447 - fscore: 0.9446 - val_loss: 0.3679 - val_accuracy: 0.8607 - val_fscore: 0.8630\n",
            "Epoch 430/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1228 - accuracy: 0.9562 - fscore: 0.9547 - val_loss: 0.3352 - val_accuracy: 0.8824 - val_fscore: 0.8726\n",
            "Epoch 431/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1173 - accuracy: 0.9571 - fscore: 0.9549 - val_loss: 0.3640 - val_accuracy: 0.8854 - val_fscore: 0.8769\n",
            "Epoch 432/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1222 - accuracy: 0.9535 - fscore: 0.9497 - val_loss: 0.3382 - val_accuracy: 0.8854 - val_fscore: 0.8747\n",
            "Epoch 433/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1178 - accuracy: 0.9548 - fscore: 0.9552 - val_loss: 0.3216 - val_accuracy: 0.8978 - val_fscore: 0.8891\n",
            "Epoch 434/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1563 - accuracy: 0.9416 - fscore: 0.9441 - val_loss: 0.4667 - val_accuracy: 0.8669 - val_fscore: 0.8616\n",
            "Epoch 435/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1323 - accuracy: 0.9469 - fscore: 0.9475 - val_loss: 0.3400 - val_accuracy: 0.8916 - val_fscore: 0.8763\n",
            "Epoch 436/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1168 - accuracy: 0.9562 - fscore: 0.9570 - val_loss: 0.3435 - val_accuracy: 0.8854 - val_fscore: 0.8741\n",
            "Epoch 437/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1196 - accuracy: 0.9522 - fscore: 0.9542 - val_loss: 0.3205 - val_accuracy: 0.8854 - val_fscore: 0.8803\n",
            "Epoch 438/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1218 - accuracy: 0.9509 - fscore: 0.9528 - val_loss: 0.3666 - val_accuracy: 0.8700 - val_fscore: 0.8644\n",
            "Epoch 439/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1520 - accuracy: 0.9389 - fscore: 0.9426 - val_loss: 0.3206 - val_accuracy: 0.8916 - val_fscore: 0.8909\n",
            "Epoch 440/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1295 - accuracy: 0.9473 - fscore: 0.9478 - val_loss: 0.5052 - val_accuracy: 0.8607 - val_fscore: 0.8568\n",
            "Epoch 441/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1436 - accuracy: 0.9469 - fscore: 0.9433 - val_loss: 0.3483 - val_accuracy: 0.8947 - val_fscore: 0.8796\n",
            "Epoch 442/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1243 - accuracy: 0.9491 - fscore: 0.9486 - val_loss: 0.4267 - val_accuracy: 0.8885 - val_fscore: 0.8784\n",
            "Epoch 443/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1202 - accuracy: 0.9548 - fscore: 0.9528 - val_loss: 0.3578 - val_accuracy: 0.8793 - val_fscore: 0.8759\n",
            "Epoch 444/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1245 - accuracy: 0.9522 - fscore: 0.9537 - val_loss: 0.3777 - val_accuracy: 0.8731 - val_fscore: 0.8684\n",
            "Epoch 445/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1318 - accuracy: 0.9486 - fscore: 0.9506 - val_loss: 0.3676 - val_accuracy: 0.8824 - val_fscore: 0.8811\n",
            "Epoch 446/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1215 - accuracy: 0.9495 - fscore: 0.9517 - val_loss: 0.3442 - val_accuracy: 0.8793 - val_fscore: 0.8723\n",
            "Epoch 447/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1292 - accuracy: 0.9548 - fscore: 0.9547 - val_loss: 0.3477 - val_accuracy: 0.8793 - val_fscore: 0.8690\n",
            "Epoch 448/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1190 - accuracy: 0.9531 - fscore: 0.9541 - val_loss: 0.3248 - val_accuracy: 0.8978 - val_fscore: 0.8834\n",
            "Epoch 449/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1187 - accuracy: 0.9557 - fscore: 0.9567 - val_loss: 0.3443 - val_accuracy: 0.8824 - val_fscore: 0.8683\n",
            "Epoch 450/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1204 - accuracy: 0.9562 - fscore: 0.9542 - val_loss: 0.3108 - val_accuracy: 0.8916 - val_fscore: 0.8819\n",
            "Epoch 451/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1171 - accuracy: 0.9522 - fscore: 0.9543 - val_loss: 0.3632 - val_accuracy: 0.8824 - val_fscore: 0.8782\n",
            "Epoch 452/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1741 - accuracy: 0.9363 - fscore: 0.9389 - val_loss: 0.3643 - val_accuracy: 0.8854 - val_fscore: 0.8689\n",
            "Epoch 453/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1265 - accuracy: 0.9500 - fscore: 0.9528 - val_loss: 0.3276 - val_accuracy: 0.8854 - val_fscore: 0.8718\n",
            "Epoch 454/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1281 - accuracy: 0.9548 - fscore: 0.9505 - val_loss: 0.3428 - val_accuracy: 0.8824 - val_fscore: 0.8749\n",
            "Epoch 455/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1134 - accuracy: 0.9575 - fscore: 0.9573 - val_loss: 0.3327 - val_accuracy: 0.8885 - val_fscore: 0.8819\n",
            "Epoch 456/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1131 - accuracy: 0.9548 - fscore: 0.9526 - val_loss: 0.3127 - val_accuracy: 0.8824 - val_fscore: 0.8724\n",
            "Epoch 457/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1133 - accuracy: 0.9522 - fscore: 0.9527 - val_loss: 0.3476 - val_accuracy: 0.8885 - val_fscore: 0.8772\n",
            "Epoch 458/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1188 - accuracy: 0.9509 - fscore: 0.9533 - val_loss: 0.3342 - val_accuracy: 0.8916 - val_fscore: 0.8850\n",
            "Epoch 459/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1126 - accuracy: 0.9544 - fscore: 0.9546 - val_loss: 0.3249 - val_accuracy: 0.8947 - val_fscore: 0.8847\n",
            "Epoch 460/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1161 - accuracy: 0.9584 - fscore: 0.9526 - val_loss: 0.3396 - val_accuracy: 0.8916 - val_fscore: 0.8772\n",
            "Epoch 461/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1654 - accuracy: 0.9394 - fscore: 0.9391 - val_loss: 0.3655 - val_accuracy: 0.8854 - val_fscore: 0.8795\n",
            "Epoch 462/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1350 - accuracy: 0.9478 - fscore: 0.9479 - val_loss: 0.3244 - val_accuracy: 0.8947 - val_fscore: 0.8827\n",
            "Epoch 463/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1222 - accuracy: 0.9491 - fscore: 0.9486 - val_loss: 0.3309 - val_accuracy: 0.8916 - val_fscore: 0.8830\n",
            "Epoch 464/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1160 - accuracy: 0.9540 - fscore: 0.9532 - val_loss: 0.3342 - val_accuracy: 0.8885 - val_fscore: 0.8773\n",
            "Epoch 465/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1114 - accuracy: 0.9557 - fscore: 0.9536 - val_loss: 0.3346 - val_accuracy: 0.8854 - val_fscore: 0.8760\n",
            "Epoch 466/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1470 - accuracy: 0.9495 - fscore: 0.9480 - val_loss: 0.3313 - val_accuracy: 0.8824 - val_fscore: 0.8715\n",
            "Epoch 467/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1206 - accuracy: 0.9557 - fscore: 0.9547 - val_loss: 0.3082 - val_accuracy: 0.9071 - val_fscore: 0.8879\n",
            "Epoch 468/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1119 - accuracy: 0.9562 - fscore: 0.9577 - val_loss: 0.3444 - val_accuracy: 0.8824 - val_fscore: 0.8756\n",
            "Epoch 469/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1177 - accuracy: 0.9540 - fscore: 0.9546 - val_loss: 0.3132 - val_accuracy: 0.8947 - val_fscore: 0.8863\n",
            "Epoch 470/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1145 - accuracy: 0.9562 - fscore: 0.9564 - val_loss: 0.3155 - val_accuracy: 0.8978 - val_fscore: 0.8915\n",
            "Epoch 471/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1720 - accuracy: 0.9416 - fscore: 0.9409 - val_loss: 0.3824 - val_accuracy: 0.8854 - val_fscore: 0.8753\n",
            "Epoch 472/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1214 - accuracy: 0.9544 - fscore: 0.9549 - val_loss: 0.3133 - val_accuracy: 0.8947 - val_fscore: 0.8847\n",
            "Epoch 473/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1217 - accuracy: 0.9531 - fscore: 0.9536 - val_loss: 0.3352 - val_accuracy: 0.8793 - val_fscore: 0.8663\n",
            "Epoch 474/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1095 - accuracy: 0.9588 - fscore: 0.9584 - val_loss: 0.3625 - val_accuracy: 0.8854 - val_fscore: 0.8735\n",
            "Epoch 475/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1073 - accuracy: 0.9571 - fscore: 0.9609 - val_loss: 0.3680 - val_accuracy: 0.8824 - val_fscore: 0.8727\n",
            "Epoch 476/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1128 - accuracy: 0.9557 - fscore: 0.9551 - val_loss: 0.3466 - val_accuracy: 0.8916 - val_fscore: 0.8853\n",
            "Epoch 477/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1218 - accuracy: 0.9557 - fscore: 0.9526 - val_loss: 0.3616 - val_accuracy: 0.8824 - val_fscore: 0.8690\n",
            "Epoch 478/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1122 - accuracy: 0.9548 - fscore: 0.9571 - val_loss: 0.3095 - val_accuracy: 0.8947 - val_fscore: 0.8859\n",
            "Epoch 479/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1101 - accuracy: 0.9584 - fscore: 0.9593 - val_loss: 0.3242 - val_accuracy: 0.8978 - val_fscore: 0.8753\n",
            "Epoch 480/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1061 - accuracy: 0.9575 - fscore: 0.9608 - val_loss: 0.3630 - val_accuracy: 0.8916 - val_fscore: 0.8741\n",
            "Epoch 481/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1273 - accuracy: 0.9531 - fscore: 0.9517 - val_loss: 0.7996 - val_accuracy: 0.8266 - val_fscore: 0.8247\n",
            "Epoch 482/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1331 - accuracy: 0.9469 - fscore: 0.9458 - val_loss: 0.3382 - val_accuracy: 0.8916 - val_fscore: 0.8814\n",
            "Epoch 483/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1184 - accuracy: 0.9571 - fscore: 0.9537 - val_loss: 0.3443 - val_accuracy: 0.8916 - val_fscore: 0.8784\n",
            "Epoch 484/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1193 - accuracy: 0.9544 - fscore: 0.9550 - val_loss: 0.3528 - val_accuracy: 0.8916 - val_fscore: 0.8681\n",
            "Epoch 485/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1112 - accuracy: 0.9593 - fscore: 0.9593 - val_loss: 0.3249 - val_accuracy: 0.8978 - val_fscore: 0.8854\n",
            "Epoch 486/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1069 - accuracy: 0.9588 - fscore: 0.9580 - val_loss: 0.3633 - val_accuracy: 0.8854 - val_fscore: 0.8783\n",
            "Epoch 487/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1131 - accuracy: 0.9571 - fscore: 0.9578 - val_loss: 0.3396 - val_accuracy: 0.9009 - val_fscore: 0.8867\n",
            "Epoch 488/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1084 - accuracy: 0.9584 - fscore: 0.9599 - val_loss: 0.3499 - val_accuracy: 0.8885 - val_fscore: 0.8720\n",
            "Epoch 489/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1102 - accuracy: 0.9579 - fscore: 0.9572 - val_loss: 0.3727 - val_accuracy: 0.8885 - val_fscore: 0.8767\n",
            "Epoch 490/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1124 - accuracy: 0.9566 - fscore: 0.9565 - val_loss: 0.3387 - val_accuracy: 0.8854 - val_fscore: 0.8768\n",
            "Epoch 491/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1035 - accuracy: 0.9606 - fscore: 0.9615 - val_loss: 0.3904 - val_accuracy: 0.8885 - val_fscore: 0.8757\n",
            "Epoch 492/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1031 - accuracy: 0.9610 - fscore: 0.9615 - val_loss: 0.3767 - val_accuracy: 0.8978 - val_fscore: 0.8823\n",
            "Epoch 493/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1318 - accuracy: 0.9486 - fscore: 0.9485 - val_loss: 0.3309 - val_accuracy: 0.8885 - val_fscore: 0.8744\n",
            "Epoch 494/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1130 - accuracy: 0.9544 - fscore: 0.9579 - val_loss: 0.3614 - val_accuracy: 0.8947 - val_fscore: 0.8851\n",
            "Epoch 495/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1243 - accuracy: 0.9509 - fscore: 0.9514 - val_loss: 0.3816 - val_accuracy: 0.8762 - val_fscore: 0.8700\n",
            "Epoch 496/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1370 - accuracy: 0.9416 - fscore: 0.9416 - val_loss: 0.3282 - val_accuracy: 0.8916 - val_fscore: 0.8857\n",
            "Epoch 497/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1173 - accuracy: 0.9522 - fscore: 0.9516 - val_loss: 0.3980 - val_accuracy: 0.8793 - val_fscore: 0.8719\n",
            "Epoch 498/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1187 - accuracy: 0.9495 - fscore: 0.9506 - val_loss: 0.3471 - val_accuracy: 0.8824 - val_fscore: 0.8788\n",
            "Epoch 499/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1072 - accuracy: 0.9597 - fscore: 0.9591 - val_loss: 0.3196 - val_accuracy: 0.8947 - val_fscore: 0.8893\n",
            "Epoch 500/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1287 - accuracy: 0.9522 - fscore: 0.9488 - val_loss: 0.4354 - val_accuracy: 0.8762 - val_fscore: 0.8625\n",
            "Epoch 501/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1655 - accuracy: 0.9318 - fscore: 0.9298 - val_loss: 0.3863 - val_accuracy: 0.8762 - val_fscore: 0.8630\n",
            "Epoch 502/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1154 - accuracy: 0.9522 - fscore: 0.9509 - val_loss: 0.3651 - val_accuracy: 0.8885 - val_fscore: 0.8715\n",
            "Epoch 503/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1342 - accuracy: 0.9460 - fscore: 0.9450 - val_loss: 0.3508 - val_accuracy: 0.8916 - val_fscore: 0.8773\n",
            "Epoch 504/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1016 - accuracy: 0.9624 - fscore: 0.9638 - val_loss: 0.3598 - val_accuracy: 0.9040 - val_fscore: 0.8833\n",
            "Epoch 505/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1230 - accuracy: 0.9540 - fscore: 0.9537 - val_loss: 0.3451 - val_accuracy: 0.8885 - val_fscore: 0.8786\n",
            "Epoch 506/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1069 - accuracy: 0.9544 - fscore: 0.9569 - val_loss: 0.3959 - val_accuracy: 0.8885 - val_fscore: 0.8695\n",
            "Epoch 507/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1061 - accuracy: 0.9606 - fscore: 0.9621 - val_loss: 0.4114 - val_accuracy: 0.8824 - val_fscore: 0.8789\n",
            "Epoch 508/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1053 - accuracy: 0.9593 - fscore: 0.9597 - val_loss: 0.3712 - val_accuracy: 0.8947 - val_fscore: 0.8846\n",
            "Epoch 509/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1082 - accuracy: 0.9615 - fscore: 0.9619 - val_loss: 0.4034 - val_accuracy: 0.8824 - val_fscore: 0.8742\n",
            "Epoch 510/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1129 - accuracy: 0.9579 - fscore: 0.9578 - val_loss: 0.4125 - val_accuracy: 0.8762 - val_fscore: 0.8705\n",
            "Epoch 511/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1204 - accuracy: 0.9517 - fscore: 0.9500 - val_loss: 0.3627 - val_accuracy: 0.8885 - val_fscore: 0.8808\n",
            "Epoch 512/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1197 - accuracy: 0.9522 - fscore: 0.9531 - val_loss: 0.3586 - val_accuracy: 0.8947 - val_fscore: 0.8929\n",
            "Epoch 513/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1053 - accuracy: 0.9659 - fscore: 0.9635 - val_loss: 0.3576 - val_accuracy: 0.8824 - val_fscore: 0.8771\n",
            "Epoch 514/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1057 - accuracy: 0.9597 - fscore: 0.9581 - val_loss: 0.3419 - val_accuracy: 0.8885 - val_fscore: 0.8850\n",
            "Epoch 515/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1529 - accuracy: 0.9442 - fscore: 0.9450 - val_loss: 0.3770 - val_accuracy: 0.8607 - val_fscore: 0.8585\n",
            "Epoch 516/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1093 - accuracy: 0.9575 - fscore: 0.9581 - val_loss: 0.3555 - val_accuracy: 0.8916 - val_fscore: 0.8808\n",
            "Epoch 517/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1050 - accuracy: 0.9579 - fscore: 0.9589 - val_loss: 0.3795 - val_accuracy: 0.8885 - val_fscore: 0.8822\n",
            "Epoch 518/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1008 - accuracy: 0.9637 - fscore: 0.9648 - val_loss: 0.3988 - val_accuracy: 0.8793 - val_fscore: 0.8736\n",
            "Epoch 519/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1082 - accuracy: 0.9566 - fscore: 0.9583 - val_loss: 0.3340 - val_accuracy: 0.8854 - val_fscore: 0.8750\n",
            "Epoch 520/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0978 - accuracy: 0.9637 - fscore: 0.9632 - val_loss: 0.3288 - val_accuracy: 0.8885 - val_fscore: 0.8818\n",
            "Epoch 521/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1024 - accuracy: 0.9624 - fscore: 0.9625 - val_loss: 0.3469 - val_accuracy: 0.8947 - val_fscore: 0.8822\n",
            "Epoch 522/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1052 - accuracy: 0.9562 - fscore: 0.9565 - val_loss: 0.3347 - val_accuracy: 0.8978 - val_fscore: 0.8872\n",
            "Epoch 523/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1076 - accuracy: 0.9597 - fscore: 0.9592 - val_loss: 0.3865 - val_accuracy: 0.8947 - val_fscore: 0.8809\n",
            "Epoch 524/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1008 - accuracy: 0.9628 - fscore: 0.9594 - val_loss: 0.3253 - val_accuracy: 0.9009 - val_fscore: 0.8887\n",
            "Epoch 525/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1348 - accuracy: 0.9478 - fscore: 0.9492 - val_loss: 0.3556 - val_accuracy: 0.8978 - val_fscore: 0.8818\n",
            "Epoch 526/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1261 - accuracy: 0.9509 - fscore: 0.9513 - val_loss: 0.3168 - val_accuracy: 0.8793 - val_fscore: 0.8747\n",
            "Epoch 527/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1193 - accuracy: 0.9562 - fscore: 0.9571 - val_loss: 0.5527 - val_accuracy: 0.8700 - val_fscore: 0.8626\n",
            "Epoch 528/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1655 - accuracy: 0.9358 - fscore: 0.9367 - val_loss: 0.3736 - val_accuracy: 0.8793 - val_fscore: 0.8730\n",
            "Epoch 529/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1067 - accuracy: 0.9610 - fscore: 0.9575 - val_loss: 0.3851 - val_accuracy: 0.8824 - val_fscore: 0.8740\n",
            "Epoch 530/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1046 - accuracy: 0.9610 - fscore: 0.9595 - val_loss: 0.3158 - val_accuracy: 0.9040 - val_fscore: 0.8860\n",
            "Epoch 531/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1008 - accuracy: 0.9637 - fscore: 0.9609 - val_loss: 0.3631 - val_accuracy: 0.8947 - val_fscore: 0.8802\n",
            "Epoch 532/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1026 - accuracy: 0.9571 - fscore: 0.9582 - val_loss: 0.3398 - val_accuracy: 0.8978 - val_fscore: 0.8856\n",
            "Epoch 533/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1021 - accuracy: 0.9597 - fscore: 0.9580 - val_loss: 0.3420 - val_accuracy: 0.8854 - val_fscore: 0.8745\n",
            "Epoch 534/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1043 - accuracy: 0.9668 - fscore: 0.9658 - val_loss: 0.5254 - val_accuracy: 0.8669 - val_fscore: 0.8559\n",
            "Epoch 535/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1804 - accuracy: 0.9305 - fscore: 0.9305 - val_loss: 0.3506 - val_accuracy: 0.8885 - val_fscore: 0.8822\n",
            "Epoch 536/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1022 - accuracy: 0.9628 - fscore: 0.9621 - val_loss: 0.3703 - val_accuracy: 0.8947 - val_fscore: 0.8865\n",
            "Epoch 537/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0980 - accuracy: 0.9633 - fscore: 0.9636 - val_loss: 0.3343 - val_accuracy: 0.8947 - val_fscore: 0.8805\n",
            "Epoch 538/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1017 - accuracy: 0.9602 - fscore: 0.9577 - val_loss: 0.3371 - val_accuracy: 0.8947 - val_fscore: 0.8878\n",
            "Epoch 539/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1048 - accuracy: 0.9610 - fscore: 0.9595 - val_loss: 0.3423 - val_accuracy: 0.9009 - val_fscore: 0.8898\n",
            "Epoch 540/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1646 - accuracy: 0.9433 - fscore: 0.9452 - val_loss: 0.3744 - val_accuracy: 0.8824 - val_fscore: 0.8715\n",
            "Epoch 541/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1010 - accuracy: 0.9628 - fscore: 0.9624 - val_loss: 0.3556 - val_accuracy: 0.8854 - val_fscore: 0.8718\n",
            "Epoch 542/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0945 - accuracy: 0.9664 - fscore: 0.9640 - val_loss: 0.3644 - val_accuracy: 0.8854 - val_fscore: 0.8818\n",
            "Epoch 543/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1158 - accuracy: 0.9540 - fscore: 0.9550 - val_loss: 0.3415 - val_accuracy: 0.8854 - val_fscore: 0.8783\n",
            "Epoch 544/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1041 - accuracy: 0.9610 - fscore: 0.9620 - val_loss: 0.3660 - val_accuracy: 0.8854 - val_fscore: 0.8706\n",
            "Epoch 545/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1024 - accuracy: 0.9584 - fscore: 0.9606 - val_loss: 0.3519 - val_accuracy: 0.8947 - val_fscore: 0.8828\n",
            "Epoch 546/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1042 - accuracy: 0.9584 - fscore: 0.9594 - val_loss: 0.3454 - val_accuracy: 0.8978 - val_fscore: 0.8820\n",
            "Epoch 547/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1000 - accuracy: 0.9575 - fscore: 0.9579 - val_loss: 0.3505 - val_accuracy: 0.8916 - val_fscore: 0.8738\n",
            "Epoch 548/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.1335 - accuracy: 0.9478 - fscore: 0.9449 - val_loss: 0.4069 - val_accuracy: 0.8885 - val_fscore: 0.8811\n",
            "Epoch 549/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.2679 - accuracy: 0.9216 - fscore: 0.9240 - val_loss: 0.3051 - val_accuracy: 0.8916 - val_fscore: 0.8781\n",
            "Epoch 550/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1257 - accuracy: 0.9522 - fscore: 0.9547 - val_loss: 0.2897 - val_accuracy: 0.8916 - val_fscore: 0.8826\n",
            "Epoch 551/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0993 - accuracy: 0.9637 - fscore: 0.9624 - val_loss: 0.3339 - val_accuracy: 0.8854 - val_fscore: 0.8699\n",
            "Epoch 552/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1320 - accuracy: 0.9478 - fscore: 0.9488 - val_loss: 0.3392 - val_accuracy: 0.8978 - val_fscore: 0.8837\n",
            "Epoch 553/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0950 - accuracy: 0.9646 - fscore: 0.9633 - val_loss: 0.3275 - val_accuracy: 0.8916 - val_fscore: 0.8774\n",
            "Epoch 554/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0949 - accuracy: 0.9637 - fscore: 0.9642 - val_loss: 0.3268 - val_accuracy: 0.9009 - val_fscore: 0.8897\n",
            "Epoch 555/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0989 - accuracy: 0.9633 - fscore: 0.9632 - val_loss: 0.3285 - val_accuracy: 0.8916 - val_fscore: 0.8780\n",
            "Epoch 556/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0962 - accuracy: 0.9659 - fscore: 0.9652 - val_loss: 0.3087 - val_accuracy: 0.8947 - val_fscore: 0.8861\n",
            "Epoch 557/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1026 - accuracy: 0.9606 - fscore: 0.9607 - val_loss: 0.3730 - val_accuracy: 0.8916 - val_fscore: 0.8756\n",
            "Epoch 558/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1042 - accuracy: 0.9593 - fscore: 0.9575 - val_loss: 0.3506 - val_accuracy: 0.8947 - val_fscore: 0.8804\n",
            "Epoch 559/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0957 - accuracy: 0.9650 - fscore: 0.9649 - val_loss: 0.3201 - val_accuracy: 0.8947 - val_fscore: 0.8817\n",
            "Epoch 560/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1016 - accuracy: 0.9624 - fscore: 0.9621 - val_loss: 0.3769 - val_accuracy: 0.8854 - val_fscore: 0.8778\n",
            "Epoch 561/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1327 - accuracy: 0.9504 - fscore: 0.9500 - val_loss: 0.3509 - val_accuracy: 0.8854 - val_fscore: 0.8791\n",
            "Epoch 562/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0987 - accuracy: 0.9655 - fscore: 0.9631 - val_loss: 0.3308 - val_accuracy: 0.8854 - val_fscore: 0.8822\n",
            "Epoch 563/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1174 - accuracy: 0.9579 - fscore: 0.9567 - val_loss: 0.3418 - val_accuracy: 0.8885 - val_fscore: 0.8794\n",
            "Epoch 564/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1015 - accuracy: 0.9602 - fscore: 0.9607 - val_loss: 0.3600 - val_accuracy: 0.8762 - val_fscore: 0.8774\n",
            "Epoch 565/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0965 - accuracy: 0.9650 - fscore: 0.9644 - val_loss: 0.3468 - val_accuracy: 0.8947 - val_fscore: 0.8800\n",
            "Epoch 566/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0953 - accuracy: 0.9655 - fscore: 0.9650 - val_loss: 0.3639 - val_accuracy: 0.8824 - val_fscore: 0.8749\n",
            "Epoch 567/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0930 - accuracy: 0.9655 - fscore: 0.9651 - val_loss: 0.3219 - val_accuracy: 0.8978 - val_fscore: 0.8878\n",
            "Epoch 568/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1168 - accuracy: 0.9566 - fscore: 0.9556 - val_loss: 0.2946 - val_accuracy: 0.8978 - val_fscore: 0.8931\n",
            "Epoch 569/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1044 - accuracy: 0.9633 - fscore: 0.9605 - val_loss: 0.3714 - val_accuracy: 0.8885 - val_fscore: 0.8718\n",
            "Epoch 570/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1104 - accuracy: 0.9575 - fscore: 0.9551 - val_loss: 0.3530 - val_accuracy: 0.8885 - val_fscore: 0.8817\n",
            "Epoch 571/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1182 - accuracy: 0.9540 - fscore: 0.9540 - val_loss: 0.3108 - val_accuracy: 0.9040 - val_fscore: 0.8935\n",
            "Epoch 572/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1961 - accuracy: 0.9425 - fscore: 0.9441 - val_loss: 0.2979 - val_accuracy: 0.8762 - val_fscore: 0.8762\n",
            "Epoch 573/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1010 - accuracy: 0.9633 - fscore: 0.9623 - val_loss: 0.3011 - val_accuracy: 0.8978 - val_fscore: 0.8879\n",
            "Epoch 574/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.0972 - accuracy: 0.9628 - fscore: 0.9647 - val_loss: 0.3118 - val_accuracy: 0.9009 - val_fscore: 0.8834\n",
            "Epoch 575/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1042 - accuracy: 0.9593 - fscore: 0.9571 - val_loss: 0.3050 - val_accuracy: 0.9009 - val_fscore: 0.8912\n",
            "Epoch 576/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0945 - accuracy: 0.9686 - fscore: 0.9663 - val_loss: 0.3208 - val_accuracy: 0.9009 - val_fscore: 0.8900\n",
            "Epoch 577/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0960 - accuracy: 0.9650 - fscore: 0.9622 - val_loss: 0.3180 - val_accuracy: 0.9040 - val_fscore: 0.8878\n",
            "Epoch 578/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0929 - accuracy: 0.9664 - fscore: 0.9653 - val_loss: 0.3516 - val_accuracy: 0.9009 - val_fscore: 0.8868\n",
            "Epoch 579/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1505 - accuracy: 0.9456 - fscore: 0.9463 - val_loss: 0.3415 - val_accuracy: 0.8916 - val_fscore: 0.8793\n",
            "Epoch 580/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1459 - accuracy: 0.9464 - fscore: 0.9466 - val_loss: 0.2790 - val_accuracy: 0.9009 - val_fscore: 0.8857\n",
            "Epoch 581/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0984 - accuracy: 0.9619 - fscore: 0.9629 - val_loss: 0.3254 - val_accuracy: 0.8978 - val_fscore: 0.8811\n",
            "Epoch 582/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0910 - accuracy: 0.9690 - fscore: 0.9694 - val_loss: 0.3239 - val_accuracy: 0.8978 - val_fscore: 0.8835\n",
            "Epoch 583/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0891 - accuracy: 0.9677 - fscore: 0.9669 - val_loss: 0.3559 - val_accuracy: 0.8978 - val_fscore: 0.8838\n",
            "Epoch 584/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0910 - accuracy: 0.9659 - fscore: 0.9674 - val_loss: 0.3797 - val_accuracy: 0.8947 - val_fscore: 0.8812\n",
            "Epoch 585/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.0914 - accuracy: 0.9699 - fscore: 0.9681 - val_loss: 0.3670 - val_accuracy: 0.8916 - val_fscore: 0.8764\n",
            "Epoch 586/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0889 - accuracy: 0.9659 - fscore: 0.9661 - val_loss: 0.3781 - val_accuracy: 0.8885 - val_fscore: 0.8765\n",
            "Epoch 587/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.0918 - accuracy: 0.9655 - fscore: 0.9649 - val_loss: 0.3773 - val_accuracy: 0.8885 - val_fscore: 0.8716\n",
            "Epoch 588/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.0926 - accuracy: 0.9668 - fscore: 0.9672 - val_loss: 0.3430 - val_accuracy: 0.8947 - val_fscore: 0.8837\n",
            "Epoch 589/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.1032 - accuracy: 0.9619 - fscore: 0.9620 - val_loss: 0.3491 - val_accuracy: 0.8916 - val_fscore: 0.8747\n",
            "Epoch 590/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0903 - accuracy: 0.9677 - fscore: 0.9671 - val_loss: 0.3634 - val_accuracy: 0.8947 - val_fscore: 0.8820\n",
            "Epoch 591/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.0943 - accuracy: 0.9641 - fscore: 0.9635 - val_loss: 0.3422 - val_accuracy: 0.9009 - val_fscore: 0.8941\n",
            "Epoch 592/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0970 - accuracy: 0.9633 - fscore: 0.9642 - val_loss: 0.3616 - val_accuracy: 0.9009 - val_fscore: 0.8864\n",
            "Epoch 593/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0931 - accuracy: 0.9650 - fscore: 0.9623 - val_loss: 0.3490 - val_accuracy: 0.8885 - val_fscore: 0.8822\n",
            "Epoch 594/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1034 - accuracy: 0.9633 - fscore: 0.9624 - val_loss: 0.3678 - val_accuracy: 0.8854 - val_fscore: 0.8780\n",
            "Epoch 595/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1204 - accuracy: 0.9544 - fscore: 0.9529 - val_loss: 0.3391 - val_accuracy: 0.8854 - val_fscore: 0.8801\n",
            "Epoch 596/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.2119 - accuracy: 0.9225 - fscore: 0.9235 - val_loss: 0.3599 - val_accuracy: 0.8762 - val_fscore: 0.8740\n",
            "Epoch 597/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1109 - accuracy: 0.9610 - fscore: 0.9592 - val_loss: 0.3173 - val_accuracy: 0.8947 - val_fscore: 0.8834\n",
            "Epoch 598/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0911 - accuracy: 0.9659 - fscore: 0.9691 - val_loss: 0.3178 - val_accuracy: 0.8916 - val_fscore: 0.8883\n",
            "Epoch 599/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0892 - accuracy: 0.9690 - fscore: 0.9682 - val_loss: 0.3139 - val_accuracy: 0.9071 - val_fscore: 0.8862\n",
            "Epoch 600/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0901 - accuracy: 0.9690 - fscore: 0.9678 - val_loss: 0.3207 - val_accuracy: 0.9040 - val_fscore: 0.8912\n",
            "Epoch 601/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0941 - accuracy: 0.9633 - fscore: 0.9626 - val_loss: 0.3304 - val_accuracy: 0.8947 - val_fscore: 0.8892\n",
            "Epoch 602/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0910 - accuracy: 0.9659 - fscore: 0.9663 - val_loss: 0.3328 - val_accuracy: 0.8947 - val_fscore: 0.8865\n",
            "Epoch 603/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0935 - accuracy: 0.9677 - fscore: 0.9679 - val_loss: 0.3219 - val_accuracy: 0.9040 - val_fscore: 0.8976\n",
            "Epoch 604/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0960 - accuracy: 0.9615 - fscore: 0.9603 - val_loss: 0.3509 - val_accuracy: 0.8916 - val_fscore: 0.8868\n",
            "Epoch 605/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0960 - accuracy: 0.9650 - fscore: 0.9657 - val_loss: 0.3632 - val_accuracy: 0.8762 - val_fscore: 0.8721\n",
            "Epoch 606/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1374 - accuracy: 0.9482 - fscore: 0.9483 - val_loss: 0.3603 - val_accuracy: 0.8947 - val_fscore: 0.8899\n",
            "Epoch 607/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0996 - accuracy: 0.9628 - fscore: 0.9620 - val_loss: 0.3168 - val_accuracy: 0.9040 - val_fscore: 0.8883\n",
            "Epoch 608/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0916 - accuracy: 0.9677 - fscore: 0.9670 - val_loss: 0.3545 - val_accuracy: 0.9040 - val_fscore: 0.8948\n",
            "Epoch 609/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0906 - accuracy: 0.9681 - fscore: 0.9669 - val_loss: 0.3223 - val_accuracy: 0.8978 - val_fscore: 0.8869\n",
            "Epoch 610/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0931 - accuracy: 0.9655 - fscore: 0.9639 - val_loss: 0.3294 - val_accuracy: 0.9040 - val_fscore: 0.8957\n",
            "Epoch 611/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1055 - accuracy: 0.9584 - fscore: 0.9583 - val_loss: 0.3677 - val_accuracy: 0.8916 - val_fscore: 0.8877\n",
            "Epoch 612/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0952 - accuracy: 0.9637 - fscore: 0.9629 - val_loss: 0.3601 - val_accuracy: 0.8947 - val_fscore: 0.8784\n",
            "Epoch 613/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0863 - accuracy: 0.9690 - fscore: 0.9681 - val_loss: 0.3803 - val_accuracy: 0.8947 - val_fscore: 0.8788\n",
            "Epoch 614/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1027 - accuracy: 0.9637 - fscore: 0.9617 - val_loss: 0.3724 - val_accuracy: 0.8916 - val_fscore: 0.8807\n",
            "Epoch 615/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0860 - accuracy: 0.9690 - fscore: 0.9701 - val_loss: 0.4411 - val_accuracy: 0.8731 - val_fscore: 0.8705\n",
            "Epoch 616/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.2084 - accuracy: 0.9318 - fscore: 0.9318 - val_loss: 0.4347 - val_accuracy: 0.8824 - val_fscore: 0.8733\n",
            "Epoch 617/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0968 - accuracy: 0.9655 - fscore: 0.9650 - val_loss: 0.3520 - val_accuracy: 0.9009 - val_fscore: 0.8933\n",
            "Epoch 618/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1045 - accuracy: 0.9548 - fscore: 0.9571 - val_loss: 0.3808 - val_accuracy: 0.8916 - val_fscore: 0.8825\n",
            "Epoch 619/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0968 - accuracy: 0.9650 - fscore: 0.9644 - val_loss: 0.3469 - val_accuracy: 0.8978 - val_fscore: 0.8868\n",
            "Epoch 620/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0880 - accuracy: 0.9708 - fscore: 0.9691 - val_loss: 0.3141 - val_accuracy: 0.8916 - val_fscore: 0.8813\n",
            "Epoch 621/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0859 - accuracy: 0.9708 - fscore: 0.9699 - val_loss: 0.2976 - val_accuracy: 0.9009 - val_fscore: 0.8950\n",
            "Epoch 622/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0878 - accuracy: 0.9708 - fscore: 0.9671 - val_loss: 0.3523 - val_accuracy: 0.9040 - val_fscore: 0.8950\n",
            "Epoch 623/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0860 - accuracy: 0.9681 - fscore: 0.9674 - val_loss: 0.3841 - val_accuracy: 0.8824 - val_fscore: 0.8778\n",
            "Epoch 624/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0936 - accuracy: 0.9637 - fscore: 0.9639 - val_loss: 0.3444 - val_accuracy: 0.8978 - val_fscore: 0.8870\n",
            "Epoch 625/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0954 - accuracy: 0.9624 - fscore: 0.9628 - val_loss: 0.3137 - val_accuracy: 0.8885 - val_fscore: 0.8841\n",
            "Epoch 626/700\n",
            "142/142 [==============================] - 2s 14ms/step - loss: 0.0927 - accuracy: 0.9695 - fscore: 0.9672 - val_loss: 0.3102 - val_accuracy: 0.8947 - val_fscore: 0.8795\n",
            "Epoch 627/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1345 - accuracy: 0.9482 - fscore: 0.9478 - val_loss: 0.3425 - val_accuracy: 0.8885 - val_fscore: 0.8824\n",
            "Epoch 628/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1105 - accuracy: 0.9579 - fscore: 0.9590 - val_loss: 0.3561 - val_accuracy: 0.9040 - val_fscore: 0.8857\n",
            "Epoch 629/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1016 - accuracy: 0.9633 - fscore: 0.9636 - val_loss: 0.3186 - val_accuracy: 0.8978 - val_fscore: 0.8943\n",
            "Epoch 630/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0850 - accuracy: 0.9695 - fscore: 0.9699 - val_loss: 0.3358 - val_accuracy: 0.9040 - val_fscore: 0.8951\n",
            "Epoch 631/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1538 - accuracy: 0.9433 - fscore: 0.9427 - val_loss: 0.3459 - val_accuracy: 0.8947 - val_fscore: 0.8806\n",
            "Epoch 632/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0841 - accuracy: 0.9712 - fscore: 0.9701 - val_loss: 0.3876 - val_accuracy: 0.8978 - val_fscore: 0.8886\n",
            "Epoch 633/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0848 - accuracy: 0.9712 - fscore: 0.9713 - val_loss: 0.3841 - val_accuracy: 0.9009 - val_fscore: 0.8925\n",
            "Epoch 634/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0841 - accuracy: 0.9681 - fscore: 0.9682 - val_loss: 0.3805 - val_accuracy: 0.8916 - val_fscore: 0.8824\n",
            "Epoch 635/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0897 - accuracy: 0.9664 - fscore: 0.9658 - val_loss: 0.3608 - val_accuracy: 0.9040 - val_fscore: 0.8868\n",
            "Epoch 636/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0826 - accuracy: 0.9708 - fscore: 0.9703 - val_loss: 0.3799 - val_accuracy: 0.8947 - val_fscore: 0.8840\n",
            "Epoch 637/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0845 - accuracy: 0.9686 - fscore: 0.9688 - val_loss: 0.3812 - val_accuracy: 0.8978 - val_fscore: 0.8850\n",
            "Epoch 638/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0947 - accuracy: 0.9641 - fscore: 0.9640 - val_loss: 0.3546 - val_accuracy: 0.9102 - val_fscore: 0.8924\n",
            "Epoch 639/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0895 - accuracy: 0.9672 - fscore: 0.9656 - val_loss: 0.3753 - val_accuracy: 0.9009 - val_fscore: 0.8913\n",
            "Epoch 640/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1512 - accuracy: 0.9486 - fscore: 0.9496 - val_loss: 0.3249 - val_accuracy: 0.9102 - val_fscore: 0.9004\n",
            "Epoch 641/700\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.0905 - accuracy: 0.9668 - fscore: 0.9662 - val_loss: 0.3576 - val_accuracy: 0.9071 - val_fscore: 0.8888\n",
            "Epoch 642/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0866 - accuracy: 0.9690 - fscore: 0.9689 - val_loss: 0.3755 - val_accuracy: 0.8947 - val_fscore: 0.8880\n",
            "Epoch 643/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0861 - accuracy: 0.9672 - fscore: 0.9677 - val_loss: 0.3878 - val_accuracy: 0.9009 - val_fscore: 0.8890\n",
            "Epoch 644/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.2119 - accuracy: 0.9305 - fscore: 0.9329 - val_loss: 0.2975 - val_accuracy: 0.9040 - val_fscore: 0.8930\n",
            "Epoch 645/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1875 - accuracy: 0.9407 - fscore: 0.9418 - val_loss: 0.3224 - val_accuracy: 0.9040 - val_fscore: 0.8925\n",
            "Epoch 646/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0905 - accuracy: 0.9677 - fscore: 0.9666 - val_loss: 0.3184 - val_accuracy: 0.8947 - val_fscore: 0.8860\n",
            "Epoch 647/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0852 - accuracy: 0.9699 - fscore: 0.9691 - val_loss: 0.3648 - val_accuracy: 0.8947 - val_fscore: 0.8901\n",
            "Epoch 648/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0875 - accuracy: 0.9699 - fscore: 0.9687 - val_loss: 0.3344 - val_accuracy: 0.9071 - val_fscore: 0.8948\n",
            "Epoch 649/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0842 - accuracy: 0.9690 - fscore: 0.9704 - val_loss: 0.3482 - val_accuracy: 0.8947 - val_fscore: 0.8870\n",
            "Epoch 650/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0855 - accuracy: 0.9721 - fscore: 0.9730 - val_loss: 0.3283 - val_accuracy: 0.9040 - val_fscore: 0.8918\n",
            "Epoch 651/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0927 - accuracy: 0.9646 - fscore: 0.9636 - val_loss: 0.3312 - val_accuracy: 0.9071 - val_fscore: 0.8940\n",
            "Epoch 652/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0861 - accuracy: 0.9690 - fscore: 0.9691 - val_loss: 0.3566 - val_accuracy: 0.8978 - val_fscore: 0.8834\n",
            "Epoch 653/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0949 - accuracy: 0.9637 - fscore: 0.9656 - val_loss: 0.3362 - val_accuracy: 0.8978 - val_fscore: 0.8883\n",
            "Epoch 654/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0937 - accuracy: 0.9659 - fscore: 0.9647 - val_loss: 0.4026 - val_accuracy: 0.8824 - val_fscore: 0.8770\n",
            "Epoch 655/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0842 - accuracy: 0.9690 - fscore: 0.9690 - val_loss: 0.4129 - val_accuracy: 0.8947 - val_fscore: 0.8821\n",
            "Epoch 656/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0828 - accuracy: 0.9721 - fscore: 0.9720 - val_loss: 0.3561 - val_accuracy: 0.9009 - val_fscore: 0.8895\n",
            "Epoch 657/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1010 - accuracy: 0.9588 - fscore: 0.9598 - val_loss: 0.3878 - val_accuracy: 0.8916 - val_fscore: 0.8836\n",
            "Epoch 658/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1096 - accuracy: 0.9602 - fscore: 0.9583 - val_loss: 0.3553 - val_accuracy: 0.8854 - val_fscore: 0.8757\n",
            "Epoch 659/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1306 - accuracy: 0.9495 - fscore: 0.9500 - val_loss: 0.4224 - val_accuracy: 0.8824 - val_fscore: 0.8787\n",
            "Epoch 660/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0858 - accuracy: 0.9686 - fscore: 0.9684 - val_loss: 0.3542 - val_accuracy: 0.9009 - val_fscore: 0.8867\n",
            "Epoch 661/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0853 - accuracy: 0.9695 - fscore: 0.9712 - val_loss: 0.3782 - val_accuracy: 0.8916 - val_fscore: 0.8839\n",
            "Epoch 662/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0816 - accuracy: 0.9721 - fscore: 0.9719 - val_loss: 0.4102 - val_accuracy: 0.9009 - val_fscore: 0.8882\n",
            "Epoch 663/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1013 - accuracy: 0.9624 - fscore: 0.9619 - val_loss: 0.3816 - val_accuracy: 0.8978 - val_fscore: 0.8865\n",
            "Epoch 664/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0907 - accuracy: 0.9641 - fscore: 0.9648 - val_loss: 0.3992 - val_accuracy: 0.8885 - val_fscore: 0.8808\n",
            "Epoch 665/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0855 - accuracy: 0.9699 - fscore: 0.9703 - val_loss: 0.3352 - val_accuracy: 0.8916 - val_fscore: 0.8796\n",
            "Epoch 666/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0860 - accuracy: 0.9681 - fscore: 0.9686 - val_loss: 0.3338 - val_accuracy: 0.8947 - val_fscore: 0.8883\n",
            "Epoch 667/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1137 - accuracy: 0.9588 - fscore: 0.9567 - val_loss: 0.3697 - val_accuracy: 0.8885 - val_fscore: 0.8846\n",
            "Epoch 668/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0857 - accuracy: 0.9712 - fscore: 0.9703 - val_loss: 0.3698 - val_accuracy: 0.8916 - val_fscore: 0.8758\n",
            "Epoch 669/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0797 - accuracy: 0.9695 - fscore: 0.9692 - val_loss: 0.3672 - val_accuracy: 0.8916 - val_fscore: 0.8836\n",
            "Epoch 670/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1464 - accuracy: 0.9447 - fscore: 0.9445 - val_loss: 0.3537 - val_accuracy: 0.8947 - val_fscore: 0.8861\n",
            "Epoch 671/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0835 - accuracy: 0.9690 - fscore: 0.9699 - val_loss: 0.3420 - val_accuracy: 0.9009 - val_fscore: 0.8967\n",
            "Epoch 672/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0779 - accuracy: 0.9748 - fscore: 0.9739 - val_loss: 0.3481 - val_accuracy: 0.9009 - val_fscore: 0.8916\n",
            "Epoch 673/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0800 - accuracy: 0.9726 - fscore: 0.9739 - val_loss: 0.3673 - val_accuracy: 0.9009 - val_fscore: 0.8902\n",
            "Epoch 674/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0772 - accuracy: 0.9757 - fscore: 0.9741 - val_loss: 0.3591 - val_accuracy: 0.9009 - val_fscore: 0.8949\n",
            "Epoch 675/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0783 - accuracy: 0.9734 - fscore: 0.9731 - val_loss: 0.3585 - val_accuracy: 0.9071 - val_fscore: 0.8930\n",
            "Epoch 676/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0927 - accuracy: 0.9664 - fscore: 0.9677 - val_loss: 0.3264 - val_accuracy: 0.9071 - val_fscore: 0.8975\n",
            "Epoch 677/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1070 - accuracy: 0.9619 - fscore: 0.9614 - val_loss: 0.4120 - val_accuracy: 0.8854 - val_fscore: 0.8778\n",
            "Epoch 678/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0816 - accuracy: 0.9699 - fscore: 0.9702 - val_loss: 0.3655 - val_accuracy: 0.8978 - val_fscore: 0.8902\n",
            "Epoch 679/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0808 - accuracy: 0.9717 - fscore: 0.9722 - val_loss: 0.3637 - val_accuracy: 0.8916 - val_fscore: 0.8859\n",
            "Epoch 680/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0826 - accuracy: 0.9708 - fscore: 0.9683 - val_loss: 0.3474 - val_accuracy: 0.9040 - val_fscore: 0.8952\n",
            "Epoch 681/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0872 - accuracy: 0.9712 - fscore: 0.9704 - val_loss: 0.4186 - val_accuracy: 0.8916 - val_fscore: 0.8749\n",
            "Epoch 682/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1044 - accuracy: 0.9619 - fscore: 0.9608 - val_loss: 0.3443 - val_accuracy: 0.8947 - val_fscore: 0.8867\n",
            "Epoch 683/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0837 - accuracy: 0.9672 - fscore: 0.9662 - val_loss: 0.3492 - val_accuracy: 0.8947 - val_fscore: 0.8839\n",
            "Epoch 684/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0784 - accuracy: 0.9717 - fscore: 0.9729 - val_loss: 0.3820 - val_accuracy: 0.8885 - val_fscore: 0.8793\n",
            "Epoch 685/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1040 - accuracy: 0.9650 - fscore: 0.9651 - val_loss: 0.4104 - val_accuracy: 0.8978 - val_fscore: 0.8860\n",
            "Epoch 686/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1180 - accuracy: 0.9606 - fscore: 0.9612 - val_loss: 0.3427 - val_accuracy: 0.9009 - val_fscore: 0.8871\n",
            "Epoch 687/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0843 - accuracy: 0.9695 - fscore: 0.9682 - val_loss: 0.3779 - val_accuracy: 0.8824 - val_fscore: 0.8720\n",
            "Epoch 688/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0857 - accuracy: 0.9690 - fscore: 0.9675 - val_loss: 0.3516 - val_accuracy: 0.9040 - val_fscore: 0.8983\n",
            "Epoch 689/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0813 - accuracy: 0.9726 - fscore: 0.9725 - val_loss: 0.3354 - val_accuracy: 0.8978 - val_fscore: 0.8931\n",
            "Epoch 690/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0790 - accuracy: 0.9730 - fscore: 0.9701 - val_loss: 0.3427 - val_accuracy: 0.8947 - val_fscore: 0.8863\n",
            "Epoch 691/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.1723 - accuracy: 0.9376 - fscore: 0.9395 - val_loss: 0.3286 - val_accuracy: 0.8793 - val_fscore: 0.8765\n",
            "Epoch 692/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1008 - accuracy: 0.9619 - fscore: 0.9634 - val_loss: 0.3714 - val_accuracy: 0.8978 - val_fscore: 0.8822\n",
            "Epoch 693/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0798 - accuracy: 0.9721 - fscore: 0.9725 - val_loss: 0.3324 - val_accuracy: 0.9040 - val_fscore: 0.8932\n",
            "Epoch 694/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0762 - accuracy: 0.9739 - fscore: 0.9743 - val_loss: 0.3536 - val_accuracy: 0.9133 - val_fscore: 0.9004\n",
            "Epoch 695/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0788 - accuracy: 0.9721 - fscore: 0.9718 - val_loss: 0.3552 - val_accuracy: 0.9009 - val_fscore: 0.8851\n",
            "Epoch 696/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0812 - accuracy: 0.9721 - fscore: 0.9710 - val_loss: 0.3389 - val_accuracy: 0.8916 - val_fscore: 0.8900\n",
            "Epoch 697/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.1074 - accuracy: 0.9597 - fscore: 0.9606 - val_loss: 0.3187 - val_accuracy: 0.8947 - val_fscore: 0.8937\n",
            "Epoch 698/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0915 - accuracy: 0.9624 - fscore: 0.9630 - val_loss: 0.3554 - val_accuracy: 0.9071 - val_fscore: 0.8942\n",
            "Epoch 699/700\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0745 - accuracy: 0.9757 - fscore: 0.9739 - val_loss: 0.3346 - val_accuracy: 0.9009 - val_fscore: 0.8986\n",
            "Epoch 700/700\n",
            "142/142 [==============================] - 2s 13ms/step - loss: 0.0886 - accuracy: 0.9695 - fscore: 0.9701 - val_loss: 0.3191 - val_accuracy: 0.9040 - val_fscore: 0.8890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predicted2 = model2.predict(x_testrnn)"
      ],
      "metadata": {
        "id": "hrloJ79fQLcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c2 = confusion_matrix(y_test.argmax(axis=1), test_predicted2.argmax(axis=1))\n",
        "print_confusion_matrix(c2, observed_emotions)"
      ],
      "metadata": {
        "id": "328hMSQtQRxq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "3ee53f37-f1de-49dd-efe6-fdf828076cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(rnn_hist2.history['loss'])\n",
        "plt.plot(rnn_hist2.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "3ZutdJvitWeh",
        "outputId": "876ac993-6793-4551-f309-931883ef8db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3wb9fnA8c/jbccjw84eTkgIWZCQEEIgEKAFEgqBsltoobRAoQVaaAu0ZbS0pbTlV2jYJaxCoAXCDCsQZgYkIXvveCTee0r6/v74nizZlhPbsSzZet6vl1863Z3uHsnSPfcd9z0xxqCUUipyRYU6AKWUUqGliUAppSKcJgKllIpwmgiUUirCaSJQSqkIp4lAKaUinCYCpVpJRJ4RkXtbue5uEfnW4W5Hqc6giUAppSKcJgKllIpwmghUt+JUyfxKRNaKSKWIPCUi/UTkXREpF5FFItLLb/1zRWSDiJSIyCciMsZv2SQRWeW87mUgocm+viMiq53XLhGRo9sZ809EZLuIFInImyIy0JkvIvJ/IpInImUisk5ExjvLZovIRie2bBG5tV0fmFJoIlDd0wXAt4EjgXOAd4E7gAzsd/5GABE5EpgP3OwsWwi8JSJxIhIHvA48D/QG/udsF+e1k4B5wLVAH+Bx4E0RiW9LoCJyGvAX4GJgALAHeMlZfAZwsvM+0px1Cp1lTwHXGmNSgPHAx23Zr1L+NBGo7uhfxpgDxphs4HNguTHmG2NMDbAAmOSsdwnwjjHmQ2NMPfB3IBGYDkwDYoF/GmPqjTGvAF/77eMa4HFjzHJjjNsY8yxQ67yuLb4PzDPGrDLG1AK3AyeISCZQD6QARwFijNlkjMl1XlcPjBWRVGNMsTFmVRv3q1QDTQSqOzrgN10d4HmyMz0QewYOgDHGA+wDBjnLsk3jURn3+E0PA25xqoVKRKQEGOK8ri2axlCBPesfZIz5GJgLPAzkicgTIpLqrHoBMBvYIyKfisgJbdyvUg00EahIloM9oAO2Th57MM8GcoFBzjyvoX7T+4A/GWN6+v0lGWPmH2YMPbBVTdkAxpiHjDGTgbHYKqJfOfO/NsbMAfpiq7D+28b9KtVAE4GKZP8FzhaR00UkFrgFW72zBFgKuIAbRSRWRL4LTPV77ZPAdSJyvNOo20NEzhaRlDbGMB+4SkQmOu0Lf8ZWZe0WkeOc7ccClUAN4HHaML4vImlOlVYZ4DmMz0FFOE0EKmIZY7YAlwP/AgqwDcvnGGPqjDF1wHeBK4EibHvCa36vXQH8BFt1Uwxsd9ZtawyLgN8Dr2JLIUcAlzqLU7EJpxhbfVQI/M1ZdgWwW0TKgOuwbQ1KtYvojWmUUiqyaYlAKaUinCYCpZSKcJoIlFIqwmkiUEqpCBcT6gDaKj093WRmZoY6DKWU6lJWrlxZYIzJCLSsyyWCzMxMVqxYEeowlFKqSxGRPS0t06ohpZSKcJoIlFIqwmkiUEqpCNfl2ggCqa+vJysri5qamlCHEnQJCQkMHjyY2NjYUIeilOomukUiyMrKIiUlhczMTBoPFtm9GGMoLCwkKyuL4cOHhzocpVQ30S2qhmpqaujTp0+3TgIAIkKfPn0iouSjlOo83SIRAN0+CXhFyvtUSnWebpMIDqWm3s3+0hpcbh22XSml/EVUIsgrr8Hl6fhht0tKSnjkkUfa/LrZs2dTUlLS4fEopVRbREwi8FapBOP2Cy0lApfLddDXLVy4kJ49e3Z8QEop1QbdotdQa3hr1g0dnwluu+02duzYwcSJE4mNjSUhIYFevXqxefNmtm7dynnnnce+ffuoqanhpptu4pprrgF8w2VUVFQwa9YsTjrpJJYsWcKgQYN44403SExM7PBYlVKqqW6XCO55awMbc8qazXd7DDX1bhLjoolqY4Pr2IGp3HXOuBaX33fffaxfv57Vq1fzySefcPbZZ7N+/fqGLp7z5s2jd+/eVFdXc9xxx3HBBRfQp0+fRtvYtm0b8+fP58knn+Tiiy/m1Vdf5fLLL29TnEop1R7dLhGEg6lTpzbq5//QQw+xYMECAPbt28e2bduaJYLhw4czceJEACZPnszu3bs7LV6lVGTrdomgpTP3ipp6dhZUMiIjmeT44L7tHj16NEx/8sknLFq0iKVLl5KUlMTMmTMDXgcQHx/fMB0dHU11dXVQY1RKKa+IaSzGWx0UhNbilJQUysvLAy4rLS2lV69eJCUlsXnzZpYtW9bh+1dKqcPR7UoELfE1Fne8Pn36cOKJJzJ+/HgSExPp169fw7KzzjqLxx57jDFjxjB69GimTZsWhAiUUqr9xASjP2UQTZkyxTS9Mc2mTZsYM2bMQV9XVedie14FmX16kJrYtQdsa837VUopfyKy0hgzJdCyiKka0oEZlFIqsIhJBN5U0LXKP0opFXwRkwh8bcWaCpRSyl/EJAKllFKBRUwiCGLvUaWU6tIiJxE4j5oHlFKqsaAlAhEZIiKLRWSjiGwQkZsCrDNTREpFZLXzd2fQ4gmjVJCcnBzqEJRSqkEwLyhzAbcYY1aJSAqwUkQ+NMZsbLLe58aY7wQxDkurhpRSKqCgJQJjTC6Q60yXi8gmYBDQNBF0imCWB2677TaGDBnCDTfcAMDdd99NTEwMixcvpri4mPr6eu69917mzJkThL0rpdTh6ZQhJkQkE5gELA+w+AQRWQPkALcaYzYc1s7evQ32r2s2OxrDiFo3cTFREN3GGrH+E2DWfS0uvuSSS7j55psbEsF///tf3n//fW688UZSU1MpKChg2rRpnHvuuXrPYaVU2Al6IhCRZOBV4GZjTNMbBawChhljKkRkNvA6MCrANq4BrgEYOnRokCNuu0mTJpGXl0dOTg75+fn06tWL/v3784tf/ILPPvuMqKgosrOzOXDgAP379w91uEop1UhQE4GIxGKTwAvGmNeaLvdPDMaYhSLyiIikG2MKmqz3BPAE2LGGDrrTFs7cjcewM6eU/mkJ9E1JaPN7OZSLLrqIV155hf3793PJJZfwwgsvkJ+fz8qVK4mNjSUzMzPg8NNKKRVqwew1JMBTwCZjzAMtrNPfWQ8RmerEUxiceJyJIDUWX3LJJbz00ku88sorXHTRRZSWltK3b19iY2NZvHgxe/bsCc6OlVLqMAWzRHAicAWwTkRWO/PuAIYCGGMeAy4EfioiLqAauNQEawyI+moGSiHG9Dv0uu0wbtw4ysvLGTRoEAMGDOD73/8+55xzDhMmTGDKlCkcddRRQdmvUkodrmD2GvqCQwz6aYyZC8wNVgz+xF1LupRR4EkP2j7WrfM1Uqenp7N06dKA61VUVAQtBqWUaquIubLYl5M8IY1CKaXCTeQkAh1sSCmlAuo2ieDQTQvdIxHoMNpKqY7WLRJBQkIChYWFBz9IBrvbUCcwxlBYWEhCQsd3f1VKRa5ucfP6wYMHk5WVRX5+fssruWqhIo+KGBf5eQdZL8wlJCQwePDgUIehlOpGukUiiI2NZfjw4QdfKWslvHoxTw/7K1dddV3nBKaUUl1At6gaapVom/OMuz7EgSilVHiJnEQQFQtoIlBKqaYiJxFEayJQSqlAIi4RoIlAKaUaiZxE4K0a8mgiUEopf5GTCLREoJRSAUVOIohyesq6XaGNQymlwkzkJAJviUCrhpRSqpHISQROG4Fo1ZBSSjUSOYnAKRGI0USglFL+IicRREXjQRBtI1BKqUYiJxEAbolFjCYCpZTyF1GJwCMxiEcTgVJK+Yu4RBCliUAppRqJrEQQFUOUqde7fCmllJ8ISwSxxOKm3q2JQCmlvCIsEcQRJ/XUuT2hDkUppcJGRCUCExVLPPXUuTQRKKWUV0QlAk90PHGaCJRSqpGISgQmOp44XJoIlFLKT4QlgjjitY1AKaUaibBEEK9tBEop1UTQEoGIDBGRxSKyUUQ2iMhNAdYREXlIRLaLyFoROTZY8QAQ41QNaYlAKaUaxARx2y7gFmPMKhFJAVaKyIfGmI1+68wCRjl/xwOPOo9BITFxxFNHhZYIlFKqQdBKBMaYXGPMKme6HNgEDGqy2hzgOWMtA3qKyIBgxYTTWFyvJQKllGrQKW0EIpIJTAKWN1k0CNjn9zyL5smi48Qm2AvKtESglFINgp4IRCQZeBW42RhT1s5tXCMiK0RkRX5+frtjiYqxjcW1mgiUUqpBUBOBiMRik8ALxpjXAqySDQzxez7YmdeIMeYJY8wUY8yUjIyM9sejjcVKKdVMMHsNCfAUsMkY80ALq70J/MDpPTQNKDXG5AYrpqjYBL2yWCmlmghmr6ETgSuAdSKy2pl3BzAUwBjzGLAQmA1sB6qAq4IYD1GxCcSIB1d9XTB3o5RSXUrQEoEx5gtADrGOAW4IVgxNRcclAOCuq+msXSqlVNiLqCuLo+OTAPDUVYU4EqWUCh8Rlgh6AJoIlFLKX0QlghinRFBfWxniSJRSKnxEVCIg1iYCd62WCJRSyivCEkEiAG4tESilVIMISwTaWKyUUk1FWCKwJQKjiUAppRpEWCKwJQLqq0Mbh1JKhZEISwS2RKCJQCmlfCIyEYhLE4FSSnlFWCKwF5TFuLSNQCmlvCIrEcTEUS9xxLkrQh2JUkqFjchKBEBdTDKJbr2OQCmlvCIwEaSQQqXek0AppRwRlwjq41JJoYqqOleoQ1FKqbAQcYnAE5tCqlRRWecOdShKKRUWIi4RuONTSaWSai0RKKUUEIGJgIQ0WyKo1RKBUkpBBCYCSUgjhSoqtUSglFJAJCaCxDQSpJ6aKr2oTCmlIAITQUxSTwDqKotDHIlSSoWHiEsECSm9Aagu10SglFIQgYkgKaUXALUVmgiUUgoiMBFEJ9lEUK9VQ0opBURgIiAhDQBPlSYCpZSCSEwEPTIAiKouDHEgSikVHiIvEST2xk0U8bUFoY5EKaXCQuQlgqgoymN6k1SnJQKllIIgJgIRmScieSKyvoXlM0WkVERWO393BiuWpqpi+5DqKuqs3SmlVFgLZongGeCsQ6zzuTFmovP3hyDG0khNQjo9PcW4PaazdqmUUmEraInAGPMZEJan3a7EDDKklNLq+lCHopRSIRfqNoITRGSNiLwrIuM6a6emR1/SKaWksqazdqmUUmGrVYlARG4SkVSxnhKRVSJyxmHuexUwzBhzDPAv4PWD7P8aEVkhIivy8/MPc7cQldqPWHFTWpR32NtSSqmurrUlgh8ZY8qAM4BewBXAfYezY2NMmTGmwpleCMSKSHoL6z5hjJlijJmSkZFxOLsFoEefQQCU5GUd9raUUqqra20iEOdxNvC8MWaD37x2EZH+IiLO9FQnlk7p09mz7xAAqgr2dsbulFIqrMW0cr2VIvIBMBy4XURSAM/BXiAi84GZQLqIZAF3AbEAxpjHgAuBn4qIC6gGLjXGdEo3nqSM4QB4ivd0xu6UUiqstTYRXA1MBHYaY6pEpDdw1cFeYIy57BDL5wJzW7n/jpXSHxfRRJdlh2T3SikVTlpbNXQCsMUYUyIilwO/A0qDF1aQRUVTHJNBYnVOqCNRSqmQa20ieBSoEpFjgFuAHcBzQYuqE1TE96dn3f5Qh6GUUiHX2kTgcurv5wBzjTEPAynBCyv4apMH0c/kU6U3sVdKRbjWJoJyEbkd2230HRGJwmn47bLShtKPYnIKy0MdiVJKhVRrE8ElQC32eoL9wGDgb0GLqhPEpQ8jWgyFubtDHYpSSoVUqxKBc/B/AUgTke8ANcaYLt1GkNI3E4CKAztDG4hSSoVYa4eYuBj4CrgIuBhYLiIXBjOwYOs58AgA6gr1WgKlVGRr7XUEvwWOM8bkAYhIBrAIeCVYgQVbbK+hAJiSfSGORCmlQqu1bQRR3iTgKGzDa8NTbAIlUb2Iq9RrCZRSka21JYL3ROR9YL7z/BJgYXBC6jxl8f1IrskNdRhKKRVSrUoExphficgFwInOrCeMMQuCF1bnqO0xiIzKjdTUu0mIjQ51OEopFRKtLRFgjHkVeDWIsXS+tCEMyv+MrKJKRvZLDXU0SikVEget5xeRchEpC/BXLiJlnRVksMSnDyNB6tmfq/clUEpFroOWCIwxXXoYiUNJ7T8CgJLcnTBxbIijUUqp0OjaPX8OU1p/e1+CmvzdoQ1EKaVCKKITgfTKtBMlelGZUipyRXQiICGN8qg0elRoIlBKRa7ITgRAceIQetdm0Ul3yVRKqbAT8YmgNmUYg9lPSVV9qENRSqmQiPhEIH1GMEgKycovCnUoSikVEhGfCBL7jQKgMGtriCNRSqnQiPhE0GvoOABqczeHOBKllAqNiE8ESQPH4kaIzt8Y6lCUUiokIj4REJdEbvQgUku3hDoSpZQKCU0EQHHyKPrX7MDj0S6kSqnIo4kAMH3HMlQOkHUgP9ShKKVUp9NEAKRmTgJg35ZVIY5EKaU6nyYCYMCRkwHot/pfIY5EKaU6X9ASgYjME5E8EVnfwnIRkYdEZLuIrBWRY4MVy6HE98kEYGTJF1BXFaowlFIqJIJZIngGOOsgy2cBo5y/a4BHgxjLwUVF8X7fqwEw5ftDFoZSSoVC0BKBMeYz4GDjNswBnjPWMqCniAwIVjyHEj3EVg8VHtgbqhCUUiokQtlGMAjY5/c8y5nXjIhcIyIrRGRFfn5wevYMGGxvUpO9b3dQtq+UUuGqSzQWG2OeMMZMMcZMycjICMo+ho+wYw6V5O4MyvaVUipchTIRZAND/J4PduaFRFJaBnmSTkL+2lCFoJRSIRHKRPAm8AOn99A0oNQYkxvCeMhJHs/gyg16kxqlVEQJZvfR+cBSYLSIZInI1SJynYhc56yyENgJbAeeBK4PViyt5R40hUHksW/v7lCHopRSnSYmWBs2xlx2iOUGuCFY+2+PfuNmwOa/k7PyLYYOuzHU4SilVKfoEo3FnWXQuBlsZyh9t70c6lCUUqrTaCLwI1HR7Ok1jUHVWzCu2lCHo5RSnUITQRMxw6YSTz37t64MdShKKdUpNBE0MWzCDAByNnwe4kiUUqpzaCJoYtjwIzlAb9J2LQTtRqqUigCaCJqQqCi+SL+YkVWrMXmbQh2OUkoFnSaCAMy47wJQuvYdcNVB7poQR6SUUsGjiSCACWPGst6TSf2mhfD+HfD4yVC8J9RhKaVUUGgiCGBU32Q+jzuJjKJV8PWTdmZ1cWiDUirUXHWweWGoo1BBoIkggKgoofbYH1Nmknwza8tDF5BS4eCTP8NLl8HOT0IdiepgmghacPSIgcxz+91gTUsEKtIV77aPVYUhDUN1PE0ELZg8tDf/9pzrm6GJQEU67U7dbWkiaEFaUiyTjhjIpih7wxreuhEObAhtUEopFQSaCA5i9oQBzKq62zfj9ZCPlK2UUh1OE8FBnDmuP9FRfh9RXWXoglEqbEioA1AdTBPBQfTuEces8f153v1tO6OuIrQBKRVS2kbQXWkiOIRbzxjNnfU/5Msh10J5LlQVhTokpZTqUJoIDiEzvQezJgzkyV297YycVaENSKmQ0Sqh7koTQSvccsZolrmOpC66B6z9X6jDUSpEtGqou9JE0ApHZCRz7BEDeZ2ZsPYluKc3/PcH8PgpWlWklOryNBG00uXThvGnyjm4YnqAccPGNyB3NWx9P9Shha8NC+CdW0MdhVLqEDQRtNK3x/YjPqUPd6c/0HhBbGJoAuoK/nelb9A+1X2IthV0N5oIWik2OorvHz+MF3f3wETF+BbUV4UuKKU6k3eICeMJbRyqw2kiaIPLjh9CdHQ0T456zDczb5Mdh2jBT3U8IhUZPJoIuhtNBG3QNyWB7xw9kLmbk6k9+bd25pKH4LO/w5oX4cuHQhugUp3B4wp1BKqDaSJooyunZ1JW6+G+yrN9M/cutY8VBwK/yOOByggeuldHrexejDvUEagOpomgjY4Z0pPLpg7h6S93+2Zmr7SPlfmBX/TJX+BvI6CyIOjxhSV3fagjUB3J04GJQLtfhwVNBO3wm7OOIjk+hlsHv4j5zoO+Bds+gH9/q3kd6jrnIrRIvaGHJwISQe7ayCn5dFTV0IYFcP9wyFrRMdtT7RbURCAiZ4nIFhHZLiK3BVh+pYjki8hq5+/HwYyno/RMiuPG00fyynZ4zT2j8cKsr+HAusbzvD+cSB20rruXCDa+CY/PgHWvhDqSztFRvYZ2fmofc1fbx5rSjtmuarOgJQIRiQYeBmYBY4HLRGRsgFVfNsZMdP7+Hax4OtqPTxrBcZm9+PMHO3GnDWu8cPcXvrNDjxtctXY6Ur/o3b1xMX+L87gptHEEnd93uiOIc/gxBnYshvuG6v2QQySYJYKpwHZjzE5jTB3wEjAniPvrVFFRwh/PG09lnYsz6u6n4tYsuLMYktLh/Tvg+fNhzUswdwpU5tkXPX++PXvM3xra4Dtbdy8RNIzBE6YXWrnr4f3fdlx9fEc1FkdF20eP29fhYs/Sjtm2apNgJoJBwD6/51nOvKYuEJG1IvKKiAwJtCERuUZEVojIivz8FhpkQ+Co/qnMu/I4dpW4OfvRFXy8NR96DrULdy6GBddC0c7GL/rvFfDwcfB1lyn8HL5glAg8Hnj7l5C3ueO33Vbe0l+4XnG78Q1YOhc+/H3HbK+j/p8NJQL/qqYIaWcJM6FuLH4LyDTGHA18CDwbaCVjzBPGmCnGmCkZGRmdGuChTD8inbnfO5Y9hVX8+pW1lJ/xAAyacugXvnML1FVBTZkdwG7X53Z+ZQHs+8q3XlmOHeRu7/K2B1dXZQ8CoRaMxuKinbDiKXj5+x2/7e7Ge6Ctr+mY7XV01ZAe/EMumIkgG/A/wx/szGtgjCk0xjgV6PwbmBzEeIJm9oQBLLh+OiVV9Zw5v4j8OS/CWX+F6748+AuzV8B9Q+zB+sVL7Lxnz4Gnvg0F2+3znZ/aoviyh21bw9r/wZJ/gbsVZ2ULf2WTTO6aw3uDrbV3Obx3e/P5rYm1rbxn3x3ZlbHdwrRqaPFfYNmj+OLqoANuR1UNNSoRhNlnF2GCmQi+BkaJyHARiQMuBd70X0FEBvg9PRfosq1tk4b24rkfTaW4qp6fvrqD3DE/pD5jLMy4xa5w2u/hhJ/Z6RTnbT97jm8D9ZXw8Z8gb6N9PncyPPMdeP06+3zjG3BvX3jtx/DB7+Cpbx06qAKnEbOuk8ZDmncGLHsEXHWN5wejROCtngiHi5s6smoofwt81c6B+jyexonx0/vgvdt8cXVUb58OKxH4xdUwraWDUIg59CrtY4xxicjPgPeBaGCeMWaDiPwBWGGMeRO4UUTOBVxAEXBlsOLpDNNHpnP/hUfz8/nfcMJfPgbg61uuJcNVCyfcAC6naD75Knj0BHA3OWB+dn/j57s/b3lnOd8cOiDvwbK9A+NteguqS+DYK9r2uvpKiInzPQ9GY7H3swyLA0cHxvDETPv/mvIjX2Nqaz063VYl3r438PLD/axMK3oNrXsFRsyEHumH3p63RBAWpbomnj4bjpgJJ/8q1JF0iqC2ERhjFhpjjjTGHGGM+ZMz704nCWCMud0YM84Yc4wx5lRjTBi0/B2ec44ZyPs3n0xCrP1oj39gBX/xXE6txEFiLzjzT5A+En57AK58B27dBt7RTFMHN99gYq+Wd+aqhdpyeOVqWP9a8+XeKpmakva9mZcvhzd/1rp1ty/yTddVNl7WkY3FlYX2YOftktuRiWDpw/CXoZCzum2vMx1YNeRN2k0/w4PZ/YVtM8nfBLUBuih7SwIbXz+8oU68B+yWSmFVRfDq1fDixa3coPN5uevo8Oqrw1FXCXu+gI/v7Zjv146PIbsVt7gt2Hb4+2qnoJUIItno/ils+sNZfLatgB/O+4rHP93J45/u5J5zx3HaUX0Z0jsJoqIg8yT7gtuz7QE9NhG2vgf11b4D8Bn3Qr9x9kyxqXv7QuYMW3LY/bk9iPQcCrE9YPBkX5VM9UESQe5ae8XzEace3pv+zwW+6aYHsaYlgvoaqNgPCWkHT3ReWSth4CT7mf3jSJtYfuDUMnZk1dCGBfZAmrsGBk4MvM7qFyF9tP18vbyJriOrwOoqICG1des+c/bBl7v8Gok3vwWTr2xfTA3vs4XP3HvBZM5qW031/u1QmgX9j4aZv2l5e64aiIptedvbP7Lfc/9SZjD5DxVTXwVxPdq3ndXzYddndkBKsL/l6T9vvt67v7Eng0vnwim3QUw8zPhl+/bZTqHuNdRtiQinHJnBy9dMY2jvJNKT47nrzQ3MuH8xuwsquerpr1i6wzk7i02A5AyIT4YJF9qqmBNvssv6jLIHwd+2MKCdt/qo4gC8cYNtd/j3abDoHsh3Clj+JYKdn9jRUr0enwHPn3fwN+M9sNeW2/rrQw1D3PQK6qYHyNd+Ag8eA3/NDHw1btEuX9VXzmr7fj79q7Mt78HDWyJoZ733krmweWHjeeJUxQQaMyp/C9ydBq//1MYDULgDPvi97yzeG5O/zQvb11untSWCQO0/Tc9i/eM6nGoYb9L1L+FVFdmSZ/EeeyMi73p7l8Dyx2Dz2/DJn+38ygJ48VIoy7XPvScI9TW+ZNW0unTPEvjPd33//87gPyZYe4eW93hs+543CYBt23v9hsbruWrt57R0rn3+6X3w0T2d167n0EQQZMeP6MNnvz6VBddPb5g38++fsHhLPj+Yd5Auoaf+Fr73Pxh6vH0emwCXv2arks5qxY/iC787qZVm2eLp0ofhuTnw8R9h3iyo8DvgrXoO5h5nf9QHNtoeR15lOfbg8tEfYeGtvmqgFU/Dvf1sF1h/LZUIlj5ib125ya/PwOZ3msf+0ERfCcibxDa/3TgBeZNNe4ru2Svhg9/ag7o/V7V9rCyw2/Xf9p4APcBe+ZEdhjx3rfP6JokgayW8dFn7+u/Xlvumyw/Yg2zTzxmgLLv5vLrKxg32/iWCtlQ/7FkKW971PW9ooHf+Dx6PHSvoxYvgwaN9gy+CPYD7q6+xPcq2vgurX4AnTvX975c/6vvO1Fc3fl3xHvtY0qTdo7qkeaeEQKqLbTLOWtH678qmt3zTW9617+vDu3yv//op+NcUezKx8lk7/6kz7UV7/vsNZPV/mr+PQPavCzw/SLRqqJMM6Z3Etj/N4uPNedz00jfU1Huodxsyb3uHCycP5s5zxpKaEOt7Qf3u7TIAACAASURBVEw8HHlG442MPN0+TrsO+o6B9FH2IFRbZs+yh063DYz+jcxxybBinv3zt3eJTQpebzpF1vmXwvYPG687dwqMng1bnDPo8hz7RX/7Zvvc/wAAgdsIinbaqoKmvGeZOz+FAcdAYk+/13l8w3IcWA9/8KtGKsuxj5V5NmnN/lvzbVfkQXJf33N3vf1hF++yz6XJeZD3x1uZD2/dBKuehbud/UuAhlvvwWmvc9Bz1dg6+O2LYNz59v8CcGBD89dWFcHKp6HnMFsKXPW8fY9epfvsdk76BSy+11ZbbVgAt2yBlP5+62U13/aq56CX37An/sl2+aNwzKX2s96/DvqMhLgkuyxntf1OeatCnj7LPn73SRg02ZeIPW57ErHQ6RG34+PmMTStE3/5ct/3qqoIcpos3+8k0xVP2SrS9a/CnIeh0OlG7Y2pfD88/13I2wBHnGZPjkr22hOfoy+BYdMbb/fd38Dal+30eY/B2Dmw7r8w9rzG37XyA5DSz3aB/vKfvvkLb7VVrfWVtsNHcl/7eRZusycTAG/daB/3LYNjf2g/e+9oAoG8+mMYdqL9H7TUtXveGfCTxfbzOOehtnccaCMxYdHrovWmTJliVqzo+qMV1tS7uezJZXyz154RREcJV0wbxvQj+nDGuP6HeHUAuWucH3UP+4ONioLSbFvP/NZN9oc17nx7tnuw3kitkdATML6DdExC47POlAHQI8P34z7jT7Djo8AHDLA9Mz77GyT3h1s2wz3OD3TylVBbAesDVB9NvRa+etz3/Jeb7cFz8HH2QP/QsTbG8x+HCRfZH9KiexqXlMBWu131LiDw91H24C1RvrPeO3JsEvjkL40PENd+Bo+f3PJnNPH7sOltX+PtzDvsgWvA0bYx1X9MnavehadnNX592lAo3QsXzrPb2eB0Bphyte1i/N0noecQWPxn+9md8DNbOmmNKVfbA+arV9vXnfkn+7342xH2YPrdJ+x6d6e1sAGh1Y26w05sXpoadpJtjG0Lb5yrnvOdtATiTdw530DfcfDkac0HgfS6eZ1tU1s931bjDJx08N54FzxlB8jb9LbvZMJfXArUlcOEi2114ea3Gy8fNLn5SVNrjD3Ptif2HeNrV2wHEVlpjAl4tasmghAyxrA9r4K31+by4Ee+Ivvw9B58d9IgYmOiuPqk4cRGR2GMQQ6nn7oxjfu571hsGz6nXAVDT4C/DrMH9l7DfV/ym9bYOs2WfrQZY9o30NoRp9vEEEh8WuCeL14/XWq73rbVlB/ZZBho4L/oOKf6ykB0PLj9qnhOv8sOB9K0Csb7ow+26T+31Tlb32u+7Ox/2DabpD4w/gJ4p50NjP0n+KoiemXC9cvteFkrnmp32IBtAP2dU3JoWiJtq/FO21nxHt8ZeCB3lUB5Ljwwxn7P9n0FR18c+L2c+Rc44Xp48nR7cae/X2yE/ws0RqZj6rX2wOwtFbfGd/7ZtvUDufsgv41D0ETQBewvreHpJbt48rOdeAL8S5Lionn3phkM69POHgxtsfJZW7rIPNGWLpY/ag8MU66G/uNt4nDVQp8jbPVS9ko4/jpbnfXlg4G3Oe0Gu350nK0KefXHcNyP7Zmx/5k2QHyqPTNvegZ1zGVw/mP2ng9ZX9t5hzqLayplgD1QNJXQ01Z5XPCkrR7zF5fsa5P40ft28MD6KvtektJtVZnXsT+0vbCang021XuE3ad/FcnAY5tXmbTGmX+xyWDBNfbg21J33Ru+hrIsG39bHCo5N/WzlbYaa9gJ9gzW47FDgUy4yB4IWxqF98izfAnvrPvs9zDzxLaNy3XLVnvW7t+Fdc4jttpv/Su2Daxgi22UPumX9ruzc3HjbZz5Z1sNlLcZHjk+8H5+9IFtv8ta6es8EMhvdvt6xnnXTR0Ep/watrxn20wALvmP/cwGHmurmPzbKfz9fJX9HbWDJoIupLS6noTYKN5ek8udb6ynsq5xL48BaQmcelRf/nTe+GYlhIpaF8nxQWr2cdW1rvuex2OvZt39ua0uuvw1myBSB7a83fuGwNSfwDHfs/XVvTJ9y+ceBwVb4ba9tgoqJt72KnrI6d75+wJ7Nh+X1Lwq48cfwbYPbU+MQZNtsho7x7ZhlO+Hz/9uu/dV5sPvCwFjD6T3+NUdDzwWZv3VJsbaMhtbaTY8M9smxgkX2vh2f2kvCPzFRnsxVfZKX3XPiTfZqpcpP7JVG6uetWfdvYbB30f7DrLH/9QmXbDVU5kzYNenjd/TRc/Y7qv/u9J35fhNa6Fohz3AT7kaTvudLR1sWND4td6zycdm+KrtWmPCRb6bK13wlO3ptfVdO9qu94r4A+t9VY6/y7P/p0C2vGursnK+ad7j6+5S21aUkNa4+25L8Q6eatuGnjjFN2/23229vr+mB0+Px3ZDbumOgj9dYrtsG9P4u9A0VvBVqXlPXsCWlFMHwMzbYcjUxvtd+xJkjLbfR4CVz9iq29uzba9Br+I9sOA6e8KR1NtXrfqtu227UTtoIuiiPB5DVJSwt7CKuYu38d8VvobBHnHRHD24Jyv3FvOtMX35yYwRnP/IEmaOzuDU0X35/vFDiYnuIp3C3PX2AByo6quu0v75N/qC7ba55KHGReW9y2xJZeMbtirgLqdHhscN0S0kyKoi+2NL87uY75P77IF/zDktH9ACqSyEHn18z9e/ZmOa7XfFuNsFWV/5GjWNgUV3QWwSnHizfa/xyba04XFDVQEk9oZ7M2DARLjWSQz1NfDRH2yj5AX/tttZ9aytIopPsc+3f2RLcBsW2NcOc6rUXLX2GpS+42wJ6/EZcMXr9qDlqm2eRH6y2Da6Zn1lD/ISbc+ovY3MXqVZtrfQ0a24oMzjgW+et//zvcttQm3pWpaHj7ddoWfdD+/+2s6b8whM/J59fYttGdg2ox8vaj5/+RN2/K7xF9pSR0Ka7QU045e2qszLu+2h022ngPEX2pOWodN869SW2//FV09Aj77wqw6+MKymzA7dUnEARp0Jo89q12Y0EXQTBRW1ZBVX878V+1ifXcqarJaL66eOzmDelcdR6/KQU1LNiIzkFtftkpq2eTRdZjxB72nRGR76aBsfbjzAW9dOssmyLYnpYGrL7fZiE5svq6uyVVT+DZPVxbbhvmfAkeKD6/nz7RnxRc/aA3BdZeMz/Oe/a9uchhwP+5bbkuXAiTZpTLoC5sxt/76/+KdN1L/cbEu4vTIDf+/WvGSHnb/uS5t8w5Amgm7q691FfL41n1V7S/hiu+8imBmj0vl8WwHRUYLbaXC4fuYRXDfzCCpqXOwtqmLaiD4tbbbd1meXsmjTAW7+1pEdvu1IlXmb7fq5+75DXD3cjbmKs4j66C6ivvOAPXNvqq7S9pobNNmeAMQm+noCzbwj8FXNbVFVZKtnDsYYmywPtV4IHSwR6HUEXdhxmb05LtN+8YwxuD2GnQWV9EtJ4Ox/fU5Wse/inEc+2cFn2/JZn23rMY/qn8KZ4/ozqGciBZW1LNtZxNzvTWp0LcPm/WWM6ptCdFTreitd8OgSal0erjl5BElx+tVSHePUJ7dSVHERGy5soQoorkfz6wcmXGRLPZN/ePgBtObgLhLWSeBQ9NfaTYgIMdHCkf1SAFh860zq3R7qXB7cHsMX2wu4/70t9IiLprLOzeb95Wze37j749F3f8CxQ3sydXgfal1unv5yN7/89pHcePoowLZZfLBxPyMykhv246/WZRv/8spqyUyPoabezY78Csb0TyWqlcmkNYwxlFTV06tHJ4090045JdX0SY4jPubwq6i87UWRaF9R9aFXaio6Bo6/puOD6aY0EXRTsdFRxEZHkeQcK+dMHMScifZOoQfKavhsaz7/WbaHIzKSSYyL5oXl9irZVXtLWLXXd9n7Ax9u5evdReSW1rA9z3ah7BEXzYY/nMX67FKufX4l2SXVPPVDX4kzv6KWzPQe3PbqWl5fncNjlx/LWeP9bz1xeJ78fCd/XriZpbefxoC0AHXch2lXQSUvf72PX585ut0H33q3h+n3fcw5xwzkX5dNOuyYal0eEuO6fpuHCk+aCCJQv9QELpoyhIum+Br+fn3mUewsqODjzXnsK6oiLTGWlIRY5i7ezufbChq9vrLOzTXPreCTrfnUOaWAq5/1tdu8tiqbo/qn8PZa219/fXYZZ47rz9trczlldAZJsdEN1U0Hu0iupKqOjTllTB/ZeGz7/yyzSSunpCYoieDa51ew9UAF35s6lKF9kg79ggAqamxf/nfX5UIHJILqercmAhU0mggUAGlJsUwa2otJQxsPC/2D6cMwBlbvK2HGqHTqXB7ue3czL329j6P6pzBmQCoLvml81e38r/Yy/yvfIGFzF29n7mI7ZkzvHnHERgsDeyaSW1LDAxcfw78+3s7YgamccmQGJx/puyf1DS+u4svthay+89v0TPJVAxVU2Ct/CysCjPYZwNe7i9hVUMnFfolvU24ZyfExDOmdRE29GxEaqnCqnGs3Kuvafh+Foso6yqrriXISnKeDOmPU1IfhzVu6qE25Zcx68HPev/lkRvdvXsUJsGJ3EV9sL2h1x4evdhVx8eNLWXLbaQzs2fEnJ8GmiUAdVN+UBADOdMY/SoqD+y44mnvmjGs4cN573ni+2l1EaoL9Oj3+6U4WbTrAMUN6kpYYyydbfBfuFFXaESMPlNmD+Pf+bUdgXbqzkKe+2MWC66fz1ppcBvZM4Mvtdpjuv763BY/HcMfZY/jHB1saDtT5fomgotbFL19eza1njm7WfnHRY0vt4+TBDSWQWQ/ai59233c2U+5dRN+UeD6+dWaj1xVXHXp0y6e+2MX0I/rw+jfZZKTEM++LXeSU1vDOjbbrZaCrxNujWhPBIYdZeW7pbkqr6vm506bVkneckup76/e3mAgudL4zN50+qlVDu7y5Jtt5zOG6U9p35W8oaSJQ7eLfANojPoZTR/su+HriB73JLqmmZ2IstS4P+eW1rNlXQnW9myiB848dTEWNi/XZpdz5xnpySms4ZnAaa7JKOf+RJc325S1dLFyXS3mt7yz99W+ymTEyg6F9knhtVRYfbDzAtrwKrpyeybQRfRjdP4Uqv7P6a55fSWFFLf+8xFdV4/YYKmpdVNS62FdURUWtq6G3VUlV4/sobM+r4K431/Po5ZNJTYilpt7NH9/eSEJsFDX1ja+SzS1p3T0I3lufy6CeSUwYbHvE1LrcFFfW0z8todF6BysRuNweiirr6Jua0OI6gZRU1ZEUF0NcTHhcePjG6mx6JsVxil+p0F+d23PQhvc737CjvB4qEXhLaa1p/ql1eUiIPXSV3LDeduiXrQc6YfypINBEoIJikFM87hFvq4Oannklx8fQPy2Bb43t1zCvoKKWRxbvYMLgVIor63l/w36q692kJ8cztHcSH20+wIi+yZwyKp3Ptxfw9e5iTv7bYvr0iKPQKWnsKqjkrjcDDPsMfLjR3tznsieXNcy7603f0M8z7l9Mkl89/M78Cp5fupv05HhmTRjAve9s5MvthXy6JZ9zjhlIbqk92DdNAgBrsw59e9DqOjfX/ceOLeS9TuCPb2/kP8v2subOM0hJiGm07ml//4TzJw1qdqC7951NPLNkN+vvObPVQ4wYY5j4hw85c1w/Hr/CNvT/d8U+ZoxKb2h3ue75lWzNK+fjW2a2apsAG3PKyCquavUIuh9tOkC/1ATGD0rjppfsLUIX/fIUCipqmTaiT0MbFEBN3cETQWs13Fi0FYmgotbVqkTgTdS1rubfhfYaecdCZk8YwEMd0MZ0KJoIVNhIT47nznN8Iz7+6KThjZbffe64humfzhzJyj3FvLkmm6o6N7sLKzlrXH9eWL634QDdkuwSX3dEb8OzV5Xf2E5//2Brw/SDl05sqOL6+fxv+Pn8b5g0tIVxaIDP/S7wu/+9zURHCZdPG0a/1ATKa+qZ/9Ve/ryw+S26lzh3rXtzTTbFfiWS7JJqdhZU8o8Pt/Kz00Y2qq54daUdemR3QSUjMnqQEBNNVJRw/3ub6REfwylHZrC3qIrZE3w9t7wlq/c32ORYWFHLr19Zy6i+ybx6/XTioqN4b8P+Ft9fS2Y/5Kty87dlfznLdhbyw+mZjeZ7Oxn4r/+tBz5tmFft9/+oqneRRiytsaewkv2lNRwf4MJJb4mgNVU+FTUu0pN9V3MbY/jnom2cNb4/YwbYW4m+sTqb3DLnpKCudVV4VXWuhv9TS1wew5trcjQRKNWSxLhoThqVzkmjGvco+tlp9my51uWmzuUhJSGWvLIa0pPjEbE/rpe/3se6rFKuPDGTFXuK2VNQyf6yGpLjY7hw8mBySmt4c3U2izb5bi5y00urSYyNpsblbrhR1Td7Wz7r91/2yCc7AHhjdQ4/nXkEt7/WfHz8v763mf6pCezMtzf1eX7ZHgorfG0Ub672jXC6PruML3cU8O2x/RjUM5E6tz0L/c6/7HDhibHRPH/11Ib9/u19OzjdZVOHcu9544mOEg40SZY5TlXWtrwKjr77AyYM8l28VVPvbjgrrqpzNXRN9jLG8M2+kkalqZyS6kaNphc+uoTyWhcXTRnccLHhyj1FDctd7uZn0h6PoareV7VXWetutKzO7au28R8hoc7l4TevrmXZziLeuOFEjhnSOGF7SxmVftWMS7YXMKhXYrPRfSv81imsqKW8xsWDH23juaW7+ebOM9ieV9FQkgEoqzn0fatr6t2MvfN9rj1lBLfPGhNwHXdHNS61kiYC1S3Fx0Q3VCP4153HRtszcy/vWV1T5x4zkNzSagrK61i1t5g+yXEcO7QXA9ISqKh18X8fbmPRpgNkpvfggmMH8e66/by3YT+j+6Uw86gMHv90J0N6J5KRHN9wXcbeoqqASQDgUeegDdAzKZatB+w1GzedPooHP9rGR5t9SemcufaAf9+7m0lJiGlWHVFd7+b6F5oPZ+3fm+uCY32D7H2zt5i9RY3vkbsu2zeO1ao9xfRyenvNevBzTh3dl8cun0xUlFBcWcekPza5ox0w/b6P+fzXpzKkdxK7CiobSiD7iqoZ3T+FrQfKueDRpQ3rl1Y3P4CWVtdTVu07EH/rgU8bepDd995mnvhsJ1vvnUVcTFSjA3Z5TX3DxZKbcsuaJQLvNsudLr7GGL737+VECez8S+OSjP92j//zR7icA7Q3KTWN27tNf5c9sYwJg9O4Y7Y96HurMV9YtjdgIjDGUN6KhNKRNBEo1YIBaYkMSEtsaMj1SkmI5c5zxjaqxvJerOd1/SkjSU2MQUTYmV9BRko8e4uqKK2qZ2TfZHomxZFVXEVRZR33vbuZFXvsbTKT42N49qqpvLt+P4s2HeCKE4Zx8pEZ/OODLezIryA+JrrRQdvtMfRKim1UjQSQV37wrrWvrvKNZBuogd6ft2eX1wcbDzD+7veZNX4A67NbHvhwxv2L+dmpIxu6DgMs21lIrx6xvLi8cZWctzdZ09f/4tuNu29uy6tgyrBePPHZTgCm3Psh/7h4Ij95zncdS1mNq6HE4j/Mild2if38vAdb74HZY5qXTPwP7K4AZ+n5TT7nsiaJoaSqjqU7C1m6s5A7Zo8hp6Saq5+x99LwlmL2l9bQq0cs8THRFFTUMuXeRfzqzNEN2zDGsCO/gpF9A/dw6gg66JxSXUidy8P+0hqG9E7E5TENVQgFFbX0S01gbVYpYwakMP+rfbg9HvqnJRIXHcWZ4/qxu7CKlIQYiirrWL6zkKS4GNwew7NLd7Mhp4yfnTqSUf2SeeijbUSJkBAbzeRhvXhmye6G/Q/rk8TIjORGJRSAORMH8t76/W1uLD3nmIG8tSbn0Cv6iYuJatSIfDBnTxjAn787gVV7irljwTqmZPZu2N/4Qan8+fwJvLUmhyc/t3flO354b5bvKmq0jc1/PIs1+0q45AlfJ4PYaGHbn2Zz1xvreXbpnob5KfExrLvnTHJKqm27yK5CHv/UJq1vj+3HuqxS9jvtCYmx0Sy57TQm/fFDLps6lE25ZazeZ0uP3qFgAP512SR+Pv8b5n5vEt85uoX7erSCjj6qlGq3XQWV9EuNp7CijtjoKPqlxrP1QAX9UuNZvCUPl9tw0ZQh1LttkuoRH8NDH23juMzepCTEMHlYLxZtOkBGSjy/+t9aDpTVcPqYvowfmMZ1M49g3he72JBTRmpiDCt2FzOkd1JDD69zjhlIZp8k6tyehgMq2K6f/ifo6cnxvHztNH4476uApQB/cdFRXHzc4GYdBVqSmhBDWYAqn55Jsc26GIMd0LHpOF4tuXJ6ZqNEG8iEQWkNVXW/Pms0188c2aptN6WJQCnVpXgHS/QfVqO0qh6PMaQmxuL2GOJionB7DJtyyxjSK4m0JNujqKCilj2FVYxI78Hzy/bgMYb4mGj6JMfRKymOI/sl0y81gcc/3UlVnYvJw3px4sh0vtpVRHFVHeuzy3h6yS6e/9HxbMsr543VOWSkxPODE4bhchuueuZrYqKkoaronGMGUlhRy6ShPVmyo5A9hbbKL7NPElnF1dx0+iieWbKbwso6xg5IZWNuWbs/l8MpFWgiUEqpDub2GAQO2gXUO2qsx2MaBg6sqXezp7CKzfvLKK6s46zxAyivqWdonyS2HahgcK9EoqKEbQcqcHsMW/bbBu931uZy65mjG/XYagtNBEopFeEOlgiCem25iJwlIltEZLuI3BZgebyIvOwsXy4imcGMRymlVHNBSwQiEg08DMwCxgKXicjYJqtdDRQbY0YC/wf8NVjxKKWUCiyYJYKpwHZjzE5jTB3wEjCnyTpzgGed6VeA06U1130rpZTqMMFMBIOAfX7Ps5x5AdcxxriAUqDZ4CAico2IrBCRFfn5+U0XK6WUOgzhMf7sIRhjnjDGTDHGTMnICDxErVJKqfYJZiLIBob4PR/szAu4jojEAGlAYRBjUkop1UQwE8HXwCgRGS4iccClwJtN1nkT+KEzfSHwselq/VmVUqqLC9qgc8YYl4j8DHgfiAbmGWM2iMgfgBXGmDeBp4DnRWQ7UIRNFkoppTpRl7ugTETygT2HXDGwdKDgkGuFD403eLpSrNC14u1KsULXivdwYh1mjAnYyNrlEsHhEJEVLV1ZF4403uDpSrFC14q3K8UKXSveYMXaJXoNKaWUCh5NBEopFeEiLRE8EeoA2kjjDZ6uFCt0rXi7UqzQteINSqwR1UaglFKquUgrESillGpCE4FSSkW4iEkEh7o3QiiIyDwRyROR9X7zeovIhyKyzXns5cwXEXnIiX+tiBzbybEOEZHFIrJRRDaIyE3hGq+IJIjIVyKyxon1Hmf+cOe+F9ud+2DEOfPD4r4YIhItIt+IyNvhHq+I7BaRdSKyWkRWOPPC7rvg7L+niLwiIptFZJOInBDGsY52PlPvX5mI3Bz0eI0x3f4Pe2XzDmAEEAesAcaGQVwnA8cC6/3m3Q/c5kzfBvzVmZ4NvAsIMA1Y3smxDgCOdaZTgK3Y+0yEXbzOPpOd6VhguRPDf4FLnfmPAT91pq8HHnOmLwVeDtH34ZfAi8DbzvOwjRfYDaQ3mRd23wVn/88CP3am44Ce4Rprk7ijgf3AsGDHG5I3GIIP9ATgfb/ntwO3hzouJ5bMJolgCzDAmR4AbHGmHwcuC7ReiOJ+A/h2uMcLJAGrgOOxV2TGNP1OYIdBOcGZjnHWk06OczDwEXAa8Lbzww7neAMlgrD7LmAHstzV9PMJx1gDxH4G8GVnxBspVUOtuTdCuOhnjMl1pvcD/ZzpsHkPTlXEJOyZdljG61SzrAbygA+xJcISY+970TSeVt0XI8j+Cfwa8DjP+xDe8RrgAxFZKSLXOPPC8bswHMgHnnaq3f4tIj3CNNamLgXmO9NBjTdSEkGXZGyKD6v+vSKSDLwK3GyMKfNfFk7xGmPcxpiJ2DPtqcBRIQ6pRSLyHSDPGLMy1LG0wUnGmGOxt6K9QURO9l8YRt+FGGz166PGmElAJbZqpUEYxdrAaQ86F/hf02XBiDdSEkFr7o0QLg6IyAAA5zHPmR/y9yAisdgk8IIx5jVndtjGC2CMKQEWY6tWeoq970XTeEJ9X4wTgXNFZDf2lq6nAQ+GcbwYY7KdxzxgATbZhuN3IQvIMsYsd56/gk0M4Rirv1nAKmPMAed5UOONlETQmnsjhAv/ezT8EFsX753/A6eXwDSg1K+oGHQiIthhwzcZYx4I53hFJENEejrTidi2jE3YhHBhC7GG7L4YxpjbjTGDjTGZ2O/mx8aY74drvCLSQ0RSvNPYuuz1hOF3wRizH9gnIqOdWacDG8Mx1iYuw1ct5I0rePGGohEkRA0vs7E9XXYAvw11PE5M84FcoB575nI1tq73I2AbsAjo7awrwMNO/OuAKZ0c60nY4uhaYLXzNzsc4wWOBr5xYl0P3OnMHwF8BWzHFrnjnfkJzvPtzvIRIfxOzMTXaygs43XiWuP8bfD+nsLxu+DsfyKwwvk+vA70CtdYnRh6YEt4aX7zghqvDjGhlFIRLlKqhpRSSrVAE4FSSkU4TQRKKRXhNBEopVSE00SglFIRThOBUp1IRGaKM7qoUuFCE4FSSkU4TQRKBSAil4u9p8FqEXncGcSuQkT+T+w9Dj4SkQxn3YkisswZD36B31jxI0Vkkdj7IqwSkSOczSf7jY//gnPVtlIho4lAqSZEZAxwCXCisQPXuYHvY6/4XGGMGQd8CtzlvOQ54DfGmKOxV3d6578APGyMOQaYjr2KHOzIrTdj7+cwAjvWkFIhE3PoVZSKOKcDk4GvnZP1ROwgXx7gZWed/wCviUga0NMY86kz/1ngf85YPIOMMQsAjDE1AM72vjLGZDnPV2PvSfFF8N+WUoFpIlCqOQGeNcbc3mimyO+brNfe8Vlq/abd6O9QhZhWDSnV3EfAhSLSFxruxTsM+3vxjgb6PeALY0wpUCwiM5z5VwCfGmPKgSwROc/ZzUlTQgAAAIZJREFURryIJHXqu1CqlfRMRKkmjDEbReR32DtwRWFHh70Be1OTqc6yPGw7AthhgR9zDvQ7gauc+VcAj4vIH5xtXNSJb0OpVtPRR5VqJRGpMMYkhzoOpTqaVg0ppVSE0xKBUkpFOC0RKKVUhNNEoJRSEU4TgVJKRThNBEopFeE0ESilVIT7f3mae/Jl3ZX3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score2 = model2.evaluate(x_testrnn, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model2.metrics_names[1], score2[1]*100))\n",
        "print(precision(test_predicted2, y_test))\n",
        "print(recall(test_predicted2, y_test))\n",
        "print(fscore(test_predicted2, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZfFdlJNq8v_",
        "outputId": "589a3282-ad63-4dd2-c800-83a18b156f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 91.18%\n",
            "tf.Tensor(0.9040248, shape=(), dtype=float32)\n",
            "tf.Tensor(0.918239, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9110764, shape=(), dtype=float32)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "rnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}